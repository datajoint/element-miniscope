{"config": {"lang": ["en"], "separator": "[\\s\\-]+", "pipeline": ["stopWordFilter"]}, "docs": [{"location": "", "title": "Element Miniscope Calcium Imaging", "text": "<p>DataJoint Element for functional calcium imaging data acquired with the UCLA Miniscope and Miniscope DAQ acquisition  system, and analyzed with CaImAn.  DataJoint Elements collectively standardize and automate data collection and analysis  for neuroscience experiments. Each Element is a modular pipeline for data storage and  processing with corresponding database tables that can be combined with other Elements  to assemble a fully functional pipeline.</p>"}, {"location": "#experiment-flowchart", "title": "Experiment Flowchart", "text": ""}, {"location": "#data-pipeline-diagram", "title": "Data Pipeline Diagram", "text": ""}, {"location": "#getting-started", "title": "Getting Started", "text": "<ul> <li>Install from PyPI<pre><code>pip install element-miniscope\n</code></pre> </li> </ul> <ul> <li>Data Pipeline - Pipeline and table descriptions</li> </ul> <ul> <li>Tutorials - Start building your data pipeline</li> </ul> <ul> <li>Code Repository</li> </ul>"}, {"location": "#support", "title": "Support", "text": "<ul> <li>If you need help getting started or run into any errors, please contact our team by email at support@datajoint.com.</li> </ul>"}, {"location": "changelog/", "title": "Changelog", "text": "<p>Observes Semantic Versioning standard and Keep a Changelog convention.</p>"}, {"location": "changelog/#032-2023-07-20", "title": "0.3.2 - 2023-07-20", "text": "<ul> <li>Add <code>opencv-python</code> to requirements</li> </ul>"}, {"location": "changelog/#031-2023-05-22", "title": "0.3.1 - 2023-05-22", "text": "<ul> <li>Add - CaImAn citation</li> </ul>"}, {"location": "changelog/#030-2023-05-17", "title": "0.3.0 - 2023-05-17", "text": "<ul> <li>Add - Quality metrics</li> <li>Update - README and docs to reflect new structure across all Elements</li> </ul>"}, {"location": "changelog/#021-2023-05-11", "title": "0.2.1 - 2023-05-11", "text": "<ul> <li>Fix - <code>.ipynb</code> dark mode output for all notebooks.</li> <li>Fix - Remove <code>GOOGLE_ANALYTICS_KEY</code> from <code>u24_element_release_call.yml</code>.</li> </ul>"}, {"location": "changelog/#020-2023-04-28", "title": "0.2.0 - 2023-04-28", "text": "<ul> <li>Update - Attribute names relative to issues #20, #22, #26</li> <li>Add - Tutorial pages</li> <li>Add - Quality Control plotting tool and report schema</li> <li>Fix - <code>.ipynb</code> output in tutorials is not visible in dark mode.</li> </ul>"}, {"location": "changelog/#014-2022-10-21", "title": "0.1.4 - 2022-10-21", "text": "<ul> <li>Add - mkdocs deployment with workflow API docs</li> <li>Update - processing_method: char(16) -&gt; varchar(16)</li> </ul>"}, {"location": "changelog/#013-2022-10-11", "title": "0.1.3 - 2022-10-11", "text": "<ul> <li>Update - CICD workflows for PyPI release</li> </ul>"}, {"location": "changelog/#012-2022-05-10", "title": "0.1.2 - 2022-05-10", "text": "<ul> <li>Add - Load data acquired with Miniscope-DAQ-V4</li> <li>Add - Load data analyzed with CaImAn</li> <li>Add - Trigger CaImAn analysis</li> <li>Remove - Load data analyzed with MiniscopeAnalysis</li> <li>Add - Adopted black formatting into code base</li> </ul>"}, {"location": "changelog/#011-2021-04-01", "title": "0.1.1 - 2021-04-01", "text": "<ul> <li>Add - Load data acquired with Miniscope-DAQ-V3</li> <li>Add - Load data analyzed with MiniscopeAnalysis</li> </ul>"}, {"location": "citation/", "title": "Citation", "text": "<p>If your work uses the following resources, please cite the respective manuscript and/or Research Resource Identifier (RRID):</p> <ul> <li> <p>DataJoint Element Miniscope - Version 0.3.2</p> <ul> <li>Yatsenko D, Nguyen T, Shen S, Gunalan K, Turner CA, Guzman R, Sasaki M, Sitonic D,   Reimer J, Walker EY, Tolias AS. DataJoint Elements: Data Workflows for   Neurophysiology. bioRxiv. 2021 Jan 1. doi: https://doi.org/10.1101/2021.03.30.437358</li> </ul> <ul> <li>RRID:SCR_021894</li> </ul> </li> </ul> <ul> <li>CaImAn<ul> <li>Manuscripts</li> </ul> </li> </ul>"}, {"location": "concepts/", "title": "Concepts", "text": ""}, {"location": "concepts/#concepts", "title": "Concepts", "text": ""}, {"location": "concepts/#miniscopes-in-neuroscience-research", "title": "Miniscopes in Neuroscience Research", "text": "<p>Miniature fluorescence microscopes (miniscopes) are a head-mounted calcium imaging full-frame video modality first introduced in 2005 by Mark Schnitzer's lab1. Due to their light weight, these miniscopes allow measuring the dynamic activity of populations of cortical neurons in freely behaving animals. In 2011, Inscopix Inc. was founded to support one-photon miniscopes as a commercial neuroscience research platform, providing proprietary hardware, acquisition software, and analysis software. Today, they estimate their active user base is 491 labs with a total of 1179 installs.</p> <p>An open-source alternative was launched by a UCLA team led by Drs. Daniel Aharoni and Peyman Golshani23. In our conversation with Dr. Aharoni, he estimated about 700 labs currently using the UCLA system alone. The Inscopix user base is smaller but more established. Several two-photon miniscopes have been developed but lack widespread adoption likely due to the expensive hardware required for the two-photon excitation345. Due to the low costs and ability to record during natural behaviors, one-photon miniscope imaging appears to be the fastest growing calcium imaging modality in the field today.</p> <p>The DataJoint team focused efforts on supporting the UCLA platform due rapid growth and limited standardization in acquisition and processing pipelines. In the future, we will reach out to Inscopix to support their platform as well.</p>"}, {"location": "concepts/#acquisition-tools", "title": "Acquisition Tools", "text": "<p>Dr. Daniel Aharoni's lab has developed iterations of the UCLA Miniscope platform. Based on interviews, we have found labs using the two most recent versions including Miniscope DAQ V3 and Miniscope DAQ V4. Labs also use the Bonsai OpenEphys tool for data acquisition with the UCLA miniscope. Inscopix provides the Inscopix Data Acquisition Software (IDAS) for the nVista and nVoke systems.</p>"}, {"location": "concepts/#preprocessing-tools", "title": "Preprocessing Tools", "text": "<p>The preprocessing workflow for miniscope imaging includes denoising, motion correction, cell segmentation, and calcium event extraction (sometimes described as \"deconvolution\" or \"spike inference\"). For the UCLA Miniscopes, the following analysis packages are commonly used:</p> <ul> <li>Miniscope Denoising,   Daniel Aharoni (UCLA), Python</li> <li>NoRMCorre, Flatiron Institute, MATLAB</li> <li>CNMF-E, Pengcheng Zhou (Liam Paninski's Lab, Columbia   University), MATLAB</li> <li>CaImAn, Flatiron Institute, Python</li> <li>miniscoPy, Guillaume Viejo (Adrien Peyrache's   Lab, McGill University), Python</li> <li>MIN1PIPE, Jinghao Lu (Fan Wang's Lab, MIT), MATLAB</li> <li>CIAtah, Biafra Ahanonu, MATLAB</li> <li>MiniAn, Phil Dong (Denise Cai's Lab, Mount Sinai),   Python</li> <li>MiniscopeAnalysis, Guillaume Etter   (Sylvain Williams' Lab, McGill University), MATLAB</li> <li>PIMPN, Guillaume Etter (Sylvain Williams's Lab,   McGill University), Python</li> <li>CellReg, Liron Sheintuch (Yaniv Ziv's Lab, Weizmann   Institute of Science), MATLAB</li> <li>Inscopix Data Processing Software (IDPS)</li> <li>Inscopix Multimodal Image Registration and Analysis (MIRA)</li> </ul> <p>Based on interviews with UCLA and Inscopix miniscope users and developers, each research lab uses a different preprocessing workflow. These custom workflows are often closed source and not tracked with version control software. For the preprocessing tools that are open source, they are often developed by an individual during their training period and lack funding for long term maintenance. These factors result in a lack of standardization for miniscope preprocessing tools, which is a major obstacle to adoption for new labs.</p> <ol> <li> <p>Flusberg BA, Jung JC, Cocker ED, Anderson EP, Schnitzer MJ. In vivo brain imaging using a portable 3.9 gram two-photon fluorescence microendoscope. Opt Lett. 2005 Sep 1;30(17):2272-4. doi: 10.1364/ol.30.002272. PMID: 16190441.\u00a0\u21a9</p> </li> <li> <p>Cai DJ, Aharoni D, Shuman T, Shobe J, Biane J, Song W, Wei B, Veshkini M, La-Vu M, Lou J, Flores SE, Kim I, Sano Y, Zhou M, Baumgaertel K, Lavi A, Kamata M, Tuszynski M, Mayford M, Golshani P, Silva AJ. A shared neural ensemble links distinct contextual memories encoded close in time. Nature. 2016 Jun 2;534(7605):115-8. doi: 10.1038/nature17955. Epub 2016 May 23. PMID: 27251287; PMCID: PMC5063500.\u00a0\u21a9</p> </li> <li> <p>Aharoni D, Hoogland TM. Circuit Investigations With Open-Source Miniaturized Microscopes: Past, Present and Future. Front Cell Neurosci. 2019 Apr 5;13:141. doi: 10.3389/fncel.2019.00141. PMID: 31024265; PMCID: PMC6461004.\u00a0\u21a9\u21a9</p> </li> <li> <p>Helmchen F, Fee MS, Tank DW, Denk W. A miniature head-mounted two-photon microscope. high-resolution brain imaging in freely moving animals. Neuron. 2001 Sep 27;31(6):903-12. doi: 10.1016/s0896-6273(01)00421-4. PMID: 11580892.\u00a0\u21a9</p> </li> <li> <p>Zong W, Wu R, Li M, Hu Y, Li Y, Li J, Rong H, Wu H, Xu Y, Lu Y, Jia H, Fan M, Zhou Z, Zhang Y, Wang A, Chen L, Cheng H. Fast high-resolution miniature two-photon microscopy for brain imaging in freely behaving mice. Nat Methods. 2017 Jul;14(7):713-719. doi: 10.1038/nmeth.4305. Epub 2017 May 29. PMID: 28553965.\u00a0\u21a9</p> </li> </ol>"}, {"location": "partnerships/", "title": "Key Partnerships", "text": "<p>Several labs have developed data management and processing pipelines for miniscope calcium imaging. Our team interviewed these teams to understand their experiment workflow, pipeline design, associated tools, and interfaces.</p> <p>These teams include:</p> <ul> <li>Adrien Peyrache Lab, McGill University</li> <li>Peyman Golshani Lab, UCLA</li> <li>Daniel Aharoni Lab, UCLA</li> <li>Anne Churchland Lab, UCLA</li> <li>Fan Wang Lab, MIT</li> <li>Antoine Adamantidis Lab, University of Bern</li> <li>Manolis Froudaraki Lab, FORTH</li> <li>Allan Basbaum Lab, UCSF</li> </ul>"}, {"location": "pipeline/", "title": "Data Pipeline", "text": "<p>Each node in the following diagram represents the analysis code in the workflow and the corresponding table in the database.  Within the workflow, Element Miniscope connects to upstream Elements including Lab, Animal, Session, and Event. For more  detailed documentation on each table, see the API docs for the respective schemas.</p> <p></p>"}, {"location": "pipeline/#table-descriptions", "title": "Table descriptions", "text": ""}, {"location": "pipeline/#reference-schema", "title": "<code>reference</code> schema", "text": "<ul> <li>For further details see the reference schema API docs</li> </ul> Table Description Equipment Scanner metadata"}, {"location": "pipeline/#subject-schema", "title": "<code>subject</code> schema", "text": "<ul> <li>Although not required, most choose to connect the <code>Session</code> table to a <code>Subject</code> table.</li> </ul> <ul> <li>For further details see the subject schema API docs</li> </ul> Table Description Subject Basic information of the research subject."}, {"location": "pipeline/#session-schema", "title": "<code>session</code> schema", "text": "<ul> <li>For further details see the session schema API docs</li> </ul> Table Description Session Unique experimental session identifier."}, {"location": "pipeline/#miniscope-schema", "title": "<code>miniscope</code> schema", "text": "<ul> <li>Tables related to importing and analyzing miniscope data.</li> </ul> <ul> <li>For further details see the miniscope schema API docs</li> </ul> Table Description AcquisitionSoftware Software used for miniscope acquisition Channel Number of channels in the miniscope recording Recording Information about the equipment used (e.g. the acquisition hardware information). RecordingLocation Brain location of the miniscope recording RecordingInfo Metadata about this recording from the Miniscope DAQ software (e.g. frame rate, number of channels, frames, etc.) RecordingInfo.File Relative file paths for the recording files ProcessingMethod Available analysis suites that can be used in processing of the miniscope datasets ProcessingParamSet All parameters required to process a miniscope dataset MaskType All possible classifications of a segmented mask ProcessingTask Task defined by a combination of Recording and ProcessingParamSet Processing The core table that executes a ProcessingTask Curation Curated results MotionCorrection Results of the motion correction procedure MotionCorrection.RigidMotionCorrection Details of the rigid motion correction performed on the miniscope data MotionCorrection.NonRigidMotionCorrection Details of nonrigid motion correction performed on the miniscope data MotionCorrection.NonRigidMotionCorrection.Block Results of non-rigid motion correction for each block MotionCorrection.Summary Summary images for each field and channel after motion correction Segmentation Results of the segmentation Segmentation.Mask Masks identified in the segmentation procedure MaskClassificationMethod Method used in the mask classification procedure MaskClassification Result of the mask classification procedure MaskClassification.MaskType Classification type assigned to each mask (e.g. soma, axon, dendrite, artifact, etc.) Fluorescence Fluorescence measurements Fluorescence.Trace Fluorescence trace for each region of interest ActivityExtractionMethod Method used in activity extraction Activity Inferred neural activity Activity.Trace Inferred neural activity for each fluorescence trace ProcessingQualityMetrics Quality metrics used to evaluate the results of the calcium imaging analysis pipeline ProcessingQualityMetrics.Mask Quality metrics used to evaluate the masks ProcessingQualityMetrics.Trace Quality metrics used to evaluate the fluorescence traces"}, {"location": "pipeline/#miniscope_report-schema", "title": "<code>miniscope_report</code> schema", "text": "<ul> <li>Tables that provide summary reports of the processed miniscope data.</li> </ul> <ul> <li>For further details see the miniscope_report API docs</li> </ul> Table Description QualityMetrics A table containing information about CaImAn estimates:  + <code>r_values</code>: Space correlation  + <code>snr</code>: Trace SNR  + <code>cnn_preds</code>: CNN predictions"}, {"location": "roadmap/", "title": "Roadmap", "text": "<p>Through our interviews and direct collaboration on key projects, we identified the common motifs to create Element Miniscope. Major features include:</p> <ul> <li> Ingestion of data acquired with the UCLA Miniscope DAQ acquisition system</li> <li> Ingestion of data processed with CaImAn</li> <li> Image processing with CaImAn<ul> <li> Motion correction</li> <li> Cell segmentation </li> <li> Fluorescence trace extraction</li> <li> Spike inference</li> <li> Cell classification</li> </ul> </li> <li> Store curations of the processed results</li> <li> Example data</li> <li> Pytests for quality assurance</li> <li> Quality metrics</li> <li> Data export to NWB</li> <li> Data publishing to DANDI</li> </ul> <p>Further development of this Element is community driven. Upon user requests and based on guidance from the Scientific Steering Group we will continue adding features to this  Element.</p>"}, {"location": "api/element_miniscope/miniscope/", "title": "miniscope.py", "text": ""}, {"location": "api/element_miniscope/miniscope/#element_miniscope.miniscope.activate", "title": "<code>activate(miniscope_schema_name, *, create_schema=True, create_tables=True, linking_module=None)</code>", "text": "<p>Activate this schema.</p> <p>Parameters:</p> Name Type Description Default <code>miniscope_schema_name</code> <code>str</code> <p>schema name on the database server</p> required <code>create_schema</code> <code>bool</code> <p>when True (default), create schema in the database if it does not yet exist.</p> <code>True</code> <code>create_tables</code> <code>str</code> <p>when True (default), create schema takes in the database if they do not yet exist.</p> <code>True</code> <code>linking_module</code> <code>str</code> <p>a module (or name) containing the required dependencies.</p> <code>None</code> <p>Dependencies:</p> Upstream tables <p>Session: parent table to Recording, identifying a recording session. Device: Reference table for Recording, specifying the acquisition device. AnatomicalLocation: Reference table for anatomical region for recording acquisition.</p> Functions <p>get_miniscope_root_data_dir(): Returns absolute path for root data director(y/ies)     with all subject/sessions data, as (list of) string(s). get_session_directory(session_key: dict) Returns the session directory with all     data for the session in session_key, as a string. get_processed_root_data_dir(): Returns absolute path for all processed data as     a string.</p> Source code in <code>element_miniscope/miniscope.py</code> <pre><code>def activate(\n    miniscope_schema_name: str,\n    *,\n    create_schema: bool = True,\n    create_tables: bool = True,\n    linking_module: str = None,\n):\n\"\"\"Activate this schema.\n\n    Args:\n        miniscope_schema_name (str): schema name on the database server\n        create_schema (bool): when True (default), create schema in the database if it\n            does not yet exist.\n        create_tables (str): when True (default), create schema takes in the database\n            if they do not yet exist.\n        linking_module (str): a module (or name) containing the required dependencies.\n\n    Dependencies:\n\n    Upstream tables:\n        Session: parent table to Recording, identifying a recording session.\n        Device: Reference table for Recording, specifying the acquisition device.\n        AnatomicalLocation: Reference table for anatomical region for recording acquisition.\n\n    Functions:\n        get_miniscope_root_data_dir(): Returns absolute path for root data director(y/ies)\n            with all subject/sessions data, as (list of) string(s).\n        get_session_directory(session_key: dict) Returns the session directory with all\n            data for the session in session_key, as a string.\n        get_processed_root_data_dir(): Returns absolute path for all processed data as\n            a string.\n    \"\"\"\n\n    if isinstance(linking_module, str):\n        linking_module = importlib.import_module(linking_module)\n    assert inspect.ismodule(\n        linking_module\n    ), \"The argument 'dependency' must be a module's name or a module\"\n\n    global _linking_module\n    _linking_module = linking_module\n\n    schema.activate(\n        miniscope_schema_name,\n        create_schema=create_schema,\n        create_tables=create_tables,\n        add_objects=_linking_module.__dict__,\n    )\n    miniscope_report.activate(f\"{miniscope_schema_name}_report\", miniscope_schema_name)\n</code></pre>"}, {"location": "api/element_miniscope/miniscope/#element_miniscope.miniscope.get_miniscope_root_data_dir", "title": "<code>get_miniscope_root_data_dir()</code>", "text": "<p>Fetches absolute data path to miniscope data directory.</p> <p>The absolute path here is used as a reference for all downstream relative paths used in DataJoint.</p> <p>Returns:</p> Type Description <code>list</code> <p>A list of the absolute path to miniscope data directory.</p> Source code in <code>element_miniscope/miniscope.py</code> <pre><code>def get_miniscope_root_data_dir() -&gt; list:\n\"\"\"Fetches absolute data path to miniscope data directory.\n\n    The absolute path here is used as a reference for all downstream relative paths used in DataJoint.\n\n    Returns:\n        A list of the absolute path to miniscope data directory.\n    \"\"\"\n\n    root_directories = _linking_module.get_miniscope_root_data_dir()\n    if isinstance(root_directories, (str, pathlib.Path)):\n        root_directories = [root_directories]\n\n    if hasattr(_linking_module, \"get_processed_root_data_dir\"):\n        root_directories.append(_linking_module.get_processed_root_data_dir())\n\n    return root_directories\n</code></pre>"}, {"location": "api/element_miniscope/miniscope/#element_miniscope.miniscope.get_session_directory", "title": "<code>get_session_directory(session_key)</code>", "text": "<p>Pulls session directory information from database.</p> <p>Parameters:</p> Name Type Description Default <code>session_key</code> <code>dict</code> <p>a dictionary containing session information.</p> required <p>Returns:</p> Type Description <code>str</code> <p>Session directory as a string.</p> Source code in <code>element_miniscope/miniscope.py</code> <pre><code>def get_session_directory(session_key: dict) -&gt; str:\n\"\"\"Pulls session directory information from database.\n\n    Args:\n        session_key (dict): a dictionary containing session information.\n\n    Returns:\n        Session directory as a string.\n    \"\"\"\n    return _linking_module.get_session_directory(session_key)\n</code></pre>"}, {"location": "api/element_miniscope/miniscope/#element_miniscope.miniscope.AcquisitionSoftware", "title": "<code>AcquisitionSoftware</code>", "text": "<p>             Bases: <code>dj.Lookup</code></p> <p>Software used for miniscope acquisition.</p> <p>Attributes:</p> Name Type Description <code>acq_software</code> <code>varchar(24)</code> <p>Name of the miniscope acquisition software.</p> Source code in <code>element_miniscope/miniscope.py</code> <pre><code>@schema\nclass AcquisitionSoftware(dj.Lookup):\n\"\"\"Software used for miniscope acquisition.\n\n    Attributes:\n        acq_software (varchar(24) ): Name of the miniscope acquisition software.\"\"\"\n\n    definition = \"\"\"\n    acq_software: varchar(24)\n    \"\"\"\n    contents = zip([\"Miniscope-DAQ-V3\", \"Miniscope-DAQ-V4\"])\n</code></pre>"}, {"location": "api/element_miniscope/miniscope/#element_miniscope.miniscope.Channel", "title": "<code>Channel</code>", "text": "<p>             Bases: <code>dj.Lookup</code></p> <p>Number of channels in the miniscope recording.</p> <p>Attributes:</p> Name Type Description <code>channel</code> <code>tinyint</code> <p>Number of channels in the miniscope acquisition starting at zero.</p> Source code in <code>element_miniscope/miniscope.py</code> <pre><code>@schema\nclass Channel(dj.Lookup):\n\"\"\"Number of channels in the miniscope recording.\n\n    Attributes:\n        channel (tinyint): Number of channels in the miniscope acquisition starting at zero.\"\"\"\n\n    definition = \"\"\"\n    channel     : tinyint  # 0-based indexing\n    \"\"\"\n    contents = zip(range(5))\n</code></pre>"}, {"location": "api/element_miniscope/miniscope/#element_miniscope.miniscope.Recording", "title": "<code>Recording</code>", "text": "<p>             Bases: <code>dj.Manual</code></p> <p>Table for discrete recording sessions with the miniscope.</p> <p>Attributes:</p> Name Type Description <code>Session</code> <code>foreign key</code> <p>Session primary key.</p> <code>recording_id</code> <code>foreign key, int</code> <p>Unique recording ID.</p> <code>Device</code> <code>foreign key, int</code> <p>Lookup table for miniscope device information.</p> <code>AcquisitionSoftware</code> <code>foreign key, int</code> <p>Lookup table for miniscope acquisition software.</p> <code>recording_notes</code> <code>varchar(4095)</code> <p>notes about the recording session.</p> Source code in <code>element_miniscope/miniscope.py</code> <pre><code>@schema\nclass Recording(dj.Manual):\n\"\"\"Table for discrete recording sessions with the miniscope.\n\n    Attributes:\n        Session (foreign key): Session primary key.\n        recording_id (foreign key, int): Unique recording ID.\n        Device: Lookup table for miniscope device information.\n        AcquisitionSoftware: Lookup table for miniscope acquisition software.\n        recording_notes (varchar(4095) ): notes about the recording session.\n    \"\"\"\n\n    definition = \"\"\"\n    -&gt; Session\n    recording_id: int\n    ---\n    -&gt; Device\n    -&gt; AcquisitionSoftware\n    recording_notes='' : varchar(4095) # free-notes\n    \"\"\"\n</code></pre>"}, {"location": "api/element_miniscope/miniscope/#element_miniscope.miniscope.RecordingLocation", "title": "<code>RecordingLocation</code>", "text": "<p>             Bases: <code>dj.Manual</code></p> <p>Brain location where the miniscope recording is acquired.</p> <p>Attributes:</p> Name Type Description <code>Recording</code> <code>foreign key</code> <p>Recording primary key.</p> <code>Anatomical</code> <code>Location</code> <p>Select the anatomical region where recording was acquired.</p> Source code in <code>element_miniscope/miniscope.py</code> <pre><code>@schema\nclass RecordingLocation(dj.Manual):\n\"\"\"Brain location where the miniscope recording is acquired.\n\n    Attributes:\n        Recording (foreign key): Recording primary key.\n        Anatomical Location: Select the anatomical region where recording was acquired.\n    \"\"\"\n\n    definition = \"\"\"\n    # Brain location where this miniscope recording is acquired\n    -&gt; Recording\n    ---\n    -&gt; AnatomicalLocation\n    \"\"\"\n</code></pre>"}, {"location": "api/element_miniscope/miniscope/#element_miniscope.miniscope.RecordingInfo", "title": "<code>RecordingInfo</code>", "text": "<p>             Bases: <code>dj.Imported</code></p> <p>Automated table with recording metadata.</p> <p>Attributes:</p> Name Type Description <code>Recording</code> <code>foreign key</code> <p>Recording primary key.</p> <code>nchannels</code> <code>tinyint</code> <p>Number of recording channels.</p> <code>nframes</code> <code>int</code> <p>Number of recorded frames.</p> <code>px_height</code> <code>smallint</code> <p>Height in pixels.</p> <code>px_width</code> <code>smallint</code> <p>Width in pixels.</p> <code>um_height</code> <code>float</code> <p>Height in microns.</p> <code>um_width</code> <code>float</code> <p>Width in microns.</p> <code>fps</code> <code>float</code> <p>Frames per second, (Hz).</p> <code>gain</code> <code>float</code> <p>Recording gain.</p> <code>spatial_downsample</code> <code>tinyint</code> <p>Amount of downsampling applied.</p> <code>led_power</code> <code>float</code> <p>LED power used for the recording.</p> <code>time_stamps</code> <code>longblob</code> <p>Time stamps for each frame.</p> <code>recording_datetime</code> <code>datetime</code> <p>Datetime of the recording.</p> <code>recording_duration</code> <code>float</code> <p>Total recording duration (seconds).</p> Source code in <code>element_miniscope/miniscope.py</code> <pre><code>@schema\nclass RecordingInfo(dj.Imported):\n\"\"\"Automated table with recording metadata.\n\n    Attributes:\n        Recording (foreign key): Recording primary key.\n        nchannels (tinyint): Number of recording channels.\n        nframes (int): Number of recorded frames.\n        px_height (smallint): Height in pixels.\n        px_width (smallint): Width in pixels.\n        um_height (float): Height in microns.\n        um_width (float): Width in microns.\n        fps (float): Frames per second, (Hz).\n        gain (float): Recording gain.\n        spatial_downsample (tinyint): Amount of downsampling applied.\n        led_power (float): LED power used for the recording.\n        time_stamps (longblob): Time stamps for each frame.\n        recording_datetime (datetime): Datetime of the recording.\n        recording_duration (float): Total recording duration (seconds).\n    \"\"\"\n\n    definition = \"\"\"\n    # Store metadata about recording\n    -&gt; Recording\n    ---\n    nchannels            : tinyint   # number of channels\n    nframes              : int       # number of recorded frames\n    px_height=null       : smallint  # height in pixels\n    px_width=null        : smallint  # width in pixels\n    um_height=null       : float     # height in microns\n    um_width=null        : float     # width in microns\n    fps                  : float     # (Hz) frames per second\n    gain=null            : float     # recording gain\n    spatial_downsample=1 : tinyint   # e.g. 1, 2, 4, 8. 1 for no downsampling\n    led_power            : float     # LED power used in the given recording\n    time_stamps          : longblob  # time stamps of each frame\n    recording_datetime=null   : datetime  # datetime of the recording\n    recording_duration=null   : float     # (seconds) duration of the recording\n    \"\"\"\n\n    class File(dj.Part):\n\"\"\"File path to recording file relative to root data directory.\n\n        Attributes:\n            Recording (foreign key): Recording primary key.\n            file_id (foreign key, smallint): Unique file ID.\n            path_path (varchar(255) ): Relative file path to recording file.\n        \"\"\"\n\n        definition = \"\"\"\n        -&gt; master\n        file_id : smallint unsigned\n        ---\n        file_path: varchar(255)      # relative to root data directory\n        \"\"\"\n\n    def make(self, key):\n\"\"\"Populate table with recording file metadata.\"\"\"\n\n        # Search recording directory for miniscope raw files\n        acq_software = (Recording &amp; key).fetch1(\"acq_software\")\n        recording_directory = get_session_directory(key)\n\n        recording_path = find_full_path(\n            get_miniscope_root_data_dir(), recording_directory\n        )\n\n        recording_filepaths = [\n            file_path.as_posix() for file_path in recording_path.glob(\"*.avi\")\n        ]\n\n        if not recording_filepaths:\n            raise FileNotFoundError(f\"No .avi files found in \" f\"{recording_directory}\")\n\n        if acq_software == \"Miniscope-DAQ-V3\":\n            recording_timestamps = recording_path / \"timestamp.dat\"\n            if not recording_timestamps.exists():\n                raise FileNotFoundError(\n                    f\"No timestamp file found in \" f\"{recording_directory}\"\n                )\n\n            nchannels = 1  # Assumes a single channel\n\n            # Parse number of frames from timestamp.dat file\n            with open(recording_timestamps) as f:\n                next(f)\n                nframes = sum(1 for line in f if int(line[0]) == 0)\n\n            # Parse image dimension and frame rate\n            video = cv2.VideoCapture(recording_filepaths[0])\n            _, frame = video.read()\n            frame_size = np.shape(frame)\n            px_height = frame_size[0]\n            px_width = frame_size[1]\n\n            fps = video.get(cv2.CAP_PROP_FPS)\n\n        elif acq_software == \"Miniscope-DAQ-V4\":\n            recording_metadata = list(recording_path.glob(\"metaData.json\"))[0]\n            recording_timestamps = list(recording_path.glob(\"timeStamps.csv\"))[0]\n\n            if not recording_metadata.exists():\n                raise FileNotFoundError(\n                    f\"No .json file found in \" f\"{recording_directory}\"\n                )\n            if not recording_timestamps.exists():\n                raise FileNotFoundError(\n                    f\"No timestamp (*.csv) file found in \" f\"{recording_directory}\"\n                )\n\n            with open(recording_metadata.as_posix()) as f:\n                metadata = json.loads(f.read())\n\n            with open(recording_timestamps, newline=\"\") as f:\n                time_stamps = list(csv.reader(f, delimiter=\",\"))\n\n            nchannels = 1  # Assumes a single channel\n            nframes = len(time_stamps) - 1\n            px_height = metadata[\"ROI\"][\"height\"]\n            px_width = metadata[\"ROI\"][\"width\"]\n            fps = int(metadata[\"frameRate\"].replace(\"FPS\", \"\"))\n            gain = metadata[\"gain\"]\n            spatial_downsample = 1  # Assumes no spatial downsampling\n            led_power = metadata[\"led0\"]\n            time_stamps = np.array(\n                [list(map(int, time_stamps[i])) for i in range(1, len(time_stamps))]\n            )\n        else:\n            raise NotImplementedError(\n                f\"Loading routine not implemented for {acq_software}\"\n                \" acquisition software\"\n            )\n\n        # Insert in RecordingInfo\n        self.insert1(\n            dict(\n                key,\n                nchannels=nchannels,\n                nframes=nframes,\n                px_height=px_height,\n                px_width=px_width,\n                fps=fps,\n                gain=gain,\n                spatial_downsample=spatial_downsample,\n                led_power=led_power,\n                time_stamps=time_stamps,\n                recording_duration=nframes / fps,\n            )\n        )\n\n        # Insert file(s)\n        recording_files = [\n            pathlib.Path(f)\n            .relative_to(find_root_directory(get_miniscope_root_data_dir(), f))\n            .as_posix()\n            for f in recording_filepaths\n        ]\n\n        self.File.insert(\n            [\n                {**key, \"file_id\": i, \"file_path\": f}\n                for i, f in enumerate(recording_files)\n            ]\n        )\n</code></pre>"}, {"location": "api/element_miniscope/miniscope/#element_miniscope.miniscope.RecordingInfo.File", "title": "<code>File</code>", "text": "<p>             Bases: <code>dj.Part</code></p> <p>File path to recording file relative to root data directory.</p> <p>Attributes:</p> Name Type Description <code>Recording</code> <code>foreign key</code> <p>Recording primary key.</p> <code>file_id</code> <code>foreign key, smallint</code> <p>Unique file ID.</p> <code>path_path</code> <code>varchar(255)</code> <p>Relative file path to recording file.</p> Source code in <code>element_miniscope/miniscope.py</code> <pre><code>class File(dj.Part):\n\"\"\"File path to recording file relative to root data directory.\n\n    Attributes:\n        Recording (foreign key): Recording primary key.\n        file_id (foreign key, smallint): Unique file ID.\n        path_path (varchar(255) ): Relative file path to recording file.\n    \"\"\"\n\n    definition = \"\"\"\n    -&gt; master\n    file_id : smallint unsigned\n    ---\n    file_path: varchar(255)      # relative to root data directory\n    \"\"\"\n</code></pre>"}, {"location": "api/element_miniscope/miniscope/#element_miniscope.miniscope.RecordingInfo.make", "title": "<code>make(key)</code>", "text": "<p>Populate table with recording file metadata.</p> Source code in <code>element_miniscope/miniscope.py</code> <pre><code>def make(self, key):\n\"\"\"Populate table with recording file metadata.\"\"\"\n\n    # Search recording directory for miniscope raw files\n    acq_software = (Recording &amp; key).fetch1(\"acq_software\")\n    recording_directory = get_session_directory(key)\n\n    recording_path = find_full_path(\n        get_miniscope_root_data_dir(), recording_directory\n    )\n\n    recording_filepaths = [\n        file_path.as_posix() for file_path in recording_path.glob(\"*.avi\")\n    ]\n\n    if not recording_filepaths:\n        raise FileNotFoundError(f\"No .avi files found in \" f\"{recording_directory}\")\n\n    if acq_software == \"Miniscope-DAQ-V3\":\n        recording_timestamps = recording_path / \"timestamp.dat\"\n        if not recording_timestamps.exists():\n            raise FileNotFoundError(\n                f\"No timestamp file found in \" f\"{recording_directory}\"\n            )\n\n        nchannels = 1  # Assumes a single channel\n\n        # Parse number of frames from timestamp.dat file\n        with open(recording_timestamps) as f:\n            next(f)\n            nframes = sum(1 for line in f if int(line[0]) == 0)\n\n        # Parse image dimension and frame rate\n        video = cv2.VideoCapture(recording_filepaths[0])\n        _, frame = video.read()\n        frame_size = np.shape(frame)\n        px_height = frame_size[0]\n        px_width = frame_size[1]\n\n        fps = video.get(cv2.CAP_PROP_FPS)\n\n    elif acq_software == \"Miniscope-DAQ-V4\":\n        recording_metadata = list(recording_path.glob(\"metaData.json\"))[0]\n        recording_timestamps = list(recording_path.glob(\"timeStamps.csv\"))[0]\n\n        if not recording_metadata.exists():\n            raise FileNotFoundError(\n                f\"No .json file found in \" f\"{recording_directory}\"\n            )\n        if not recording_timestamps.exists():\n            raise FileNotFoundError(\n                f\"No timestamp (*.csv) file found in \" f\"{recording_directory}\"\n            )\n\n        with open(recording_metadata.as_posix()) as f:\n            metadata = json.loads(f.read())\n\n        with open(recording_timestamps, newline=\"\") as f:\n            time_stamps = list(csv.reader(f, delimiter=\",\"))\n\n        nchannels = 1  # Assumes a single channel\n        nframes = len(time_stamps) - 1\n        px_height = metadata[\"ROI\"][\"height\"]\n        px_width = metadata[\"ROI\"][\"width\"]\n        fps = int(metadata[\"frameRate\"].replace(\"FPS\", \"\"))\n        gain = metadata[\"gain\"]\n        spatial_downsample = 1  # Assumes no spatial downsampling\n        led_power = metadata[\"led0\"]\n        time_stamps = np.array(\n            [list(map(int, time_stamps[i])) for i in range(1, len(time_stamps))]\n        )\n    else:\n        raise NotImplementedError(\n            f\"Loading routine not implemented for {acq_software}\"\n            \" acquisition software\"\n        )\n\n    # Insert in RecordingInfo\n    self.insert1(\n        dict(\n            key,\n            nchannels=nchannels,\n            nframes=nframes,\n            px_height=px_height,\n            px_width=px_width,\n            fps=fps,\n            gain=gain,\n            spatial_downsample=spatial_downsample,\n            led_power=led_power,\n            time_stamps=time_stamps,\n            recording_duration=nframes / fps,\n        )\n    )\n\n    # Insert file(s)\n    recording_files = [\n        pathlib.Path(f)\n        .relative_to(find_root_directory(get_miniscope_root_data_dir(), f))\n        .as_posix()\n        for f in recording_filepaths\n    ]\n\n    self.File.insert(\n        [\n            {**key, \"file_id\": i, \"file_path\": f}\n            for i, f in enumerate(recording_files)\n        ]\n    )\n</code></pre>"}, {"location": "api/element_miniscope/miniscope/#element_miniscope.miniscope.ProcessingMethod", "title": "<code>ProcessingMethod</code>", "text": "<p>             Bases: <code>dj.Lookup</code></p> <p>Method or analysis software to process miniscope acquisition.</p> <p>Attributes:</p> Name Type Description <code>processing_method</code> <code>foreign key, varchar16</code> <p>Recording processing method (e.g. CaImAn).</p> <code>processing_method_desc</code> <code>varchar(1000)</code> <p>Additional information about the processing method.</p> Source code in <code>element_miniscope/miniscope.py</code> <pre><code>@schema\nclass ProcessingMethod(dj.Lookup):\n\"\"\"Method or analysis software to process miniscope acquisition.\n\n    Attributes:\n        processing_method (foreign key, varchar16): Recording processing method (e.g. CaImAn).\n        processing_method_desc (varchar(1000) ): Additional information about the processing method.\n    \"\"\"\n\n    definition = \"\"\"\n    # Method, package, analysis software used for processing of miniscope data\n    # (e.g. CaImAn, etc.)\n    processing_method: varchar(16)\n    ---\n    processing_method_desc='': varchar(1000)\n    \"\"\"\n\n    contents = [(\"caiman\", \"caiman analysis suite\")]\n</code></pre>"}, {"location": "api/element_miniscope/miniscope/#element_miniscope.miniscope.ProcessingParamSet", "title": "<code>ProcessingParamSet</code>", "text": "<p>             Bases: <code>dj.Lookup</code></p> <p>Parameters of the processing method.</p> <p>Attributes:</p> Name Type Description <code>paramset_idx</code> <code>foreign key, smallint</code> <p>Unique parameter set ID.</p> <code>ProcessingMethod</code> <code>varchar(16)</code> <p>ProcessingMethod from the lookup table.</p> <code>paramset_desc</code> <code>varchar(128)</code> <p>Description of the parameter set.</p> <code>paramset_set_hash</code> <code>uuid</code> <p>UUID hash for parameter set.</p> <code>params</code> <code>longblob</code> <p>Dictionary of all parameters for the processing method.</p> Source code in <code>element_miniscope/miniscope.py</code> <pre><code>@schema\nclass ProcessingParamSet(dj.Lookup):\n\"\"\"Parameters of the processing method.\n\n    Attributes:\n        paramset_idx (foreign key, smallint): Unique parameter set ID.\n        ProcessingMethod (varchar(16) ): ProcessingMethod from the lookup table.\n        paramset_desc (varchar(128) ): Description of the parameter set.\n        paramset_set_hash (uuid): UUID hash for parameter set.\n        params (longblob): Dictionary of all parameters for the processing method.\n    \"\"\"\n\n    definition = \"\"\"\n    # Parameter set used for processing of miniscope data\n    paramset_id:  smallint\n    ---\n    -&gt; ProcessingMethod\n    paramset_desc: varchar(128)\n    param_set_hash: uuid\n    unique index (param_set_hash)\n    params: longblob  # dictionary of all applicable parameters\n    \"\"\"\n\n    @classmethod\n    def insert_new_params(\n        cls,\n        processing_method: str,\n        paramset_id: int,\n        paramset_desc: str,\n        params: dict,\n        processing_method_desc: str = \"\",\n    ):\n\"\"\"Insert new parameter set.\n\n        Args:\n            processing_method (str): Name of the processing method or software.\n            paramset_id (int): Unique number for the set of processing parameters.\n            paramset_desc (str): Description of the processing parameter set.\n            params (dict): Dictionary of processing parameters for the selected processing_method.\n            processing_method_desc (str, optional): Description of the processing method. Defaults to \"\".\n\n        Raises:\n            dj.DataJointError: A parameter set with arguments in this function already exists in the database.\n        \"\"\"\n\n        ProcessingMethod.insert1(\n            {\"processing_method\": processing_method}, skip_duplicates=True\n        )\n        param_dict = {\n            \"processing_method\": processing_method,\n            \"paramset_id\": paramset_id,\n            \"paramset_desc\": paramset_desc,\n            \"params\": params,\n            \"param_set_hash\": dict_to_uuid(params),\n        }\n        q_param = cls &amp; {\"param_set_hash\": param_dict[\"param_set_hash\"]}\n\n        if q_param:  # If the specified param-set already exists\n            pname = q_param.fetch1(\"paramset_id\")\n            if pname == paramset_id:  # If the existed set has the same name: job done\n                return\n            else:  # If not same name: human error, try adding with different name\n                raise dj.DataJointError(\n                    \"The specified param-set already exists - name: {}\".format(pname)\n                )\n        else:\n            cls.insert1(param_dict)\n</code></pre>"}, {"location": "api/element_miniscope/miniscope/#element_miniscope.miniscope.ProcessingParamSet.insert_new_params", "title": "<code>insert_new_params(processing_method, paramset_id, paramset_desc, params, processing_method_desc='')</code>  <code>classmethod</code>", "text": "<p>Insert new parameter set.</p> <p>Parameters:</p> Name Type Description Default <code>processing_method</code> <code>str</code> <p>Name of the processing method or software.</p> required <code>paramset_id</code> <code>int</code> <p>Unique number for the set of processing parameters.</p> required <code>paramset_desc</code> <code>str</code> <p>Description of the processing parameter set.</p> required <code>params</code> <code>dict</code> <p>Dictionary of processing parameters for the selected processing_method.</p> required <code>processing_method_desc</code> <code>str</code> <p>Description of the processing method. Defaults to \"\".</p> <code>''</code> <p>Raises:</p> Type Description <code>dj.DataJointError</code> <p>A parameter set with arguments in this function already exists in the database.</p> Source code in <code>element_miniscope/miniscope.py</code> <pre><code>@classmethod\ndef insert_new_params(\n    cls,\n    processing_method: str,\n    paramset_id: int,\n    paramset_desc: str,\n    params: dict,\n    processing_method_desc: str = \"\",\n):\n\"\"\"Insert new parameter set.\n\n    Args:\n        processing_method (str): Name of the processing method or software.\n        paramset_id (int): Unique number for the set of processing parameters.\n        paramset_desc (str): Description of the processing parameter set.\n        params (dict): Dictionary of processing parameters for the selected processing_method.\n        processing_method_desc (str, optional): Description of the processing method. Defaults to \"\".\n\n    Raises:\n        dj.DataJointError: A parameter set with arguments in this function already exists in the database.\n    \"\"\"\n\n    ProcessingMethod.insert1(\n        {\"processing_method\": processing_method}, skip_duplicates=True\n    )\n    param_dict = {\n        \"processing_method\": processing_method,\n        \"paramset_id\": paramset_id,\n        \"paramset_desc\": paramset_desc,\n        \"params\": params,\n        \"param_set_hash\": dict_to_uuid(params),\n    }\n    q_param = cls &amp; {\"param_set_hash\": param_dict[\"param_set_hash\"]}\n\n    if q_param:  # If the specified param-set already exists\n        pname = q_param.fetch1(\"paramset_id\")\n        if pname == paramset_id:  # If the existed set has the same name: job done\n            return\n        else:  # If not same name: human error, try adding with different name\n            raise dj.DataJointError(\n                \"The specified param-set already exists - name: {}\".format(pname)\n            )\n    else:\n        cls.insert1(param_dict)\n</code></pre>"}, {"location": "api/element_miniscope/miniscope/#element_miniscope.miniscope.MaskType", "title": "<code>MaskType</code>", "text": "<p>             Bases: <code>dj.Lookup</code></p> <p>Possible classifications of a segmented mask.</p> <p>Attributes:</p> Name Type Description <code>mask_type</code> <code>foreign key, varchar(16) </code> <p>Type of segmented mask.</p> Source code in <code>element_miniscope/miniscope.py</code> <pre><code>@schema\nclass MaskType(dj.Lookup):\n\"\"\"Possible classifications of a segmented mask.\n\n    Attributes:\n        mask_type (foreign key, varchar(16) ): Type of segmented mask.\n    \"\"\"\n\n    definition = \"\"\" # Possible classifications for a segmented mask\n    mask_type        : varchar(16)\n    \"\"\"\n\n    contents = zip([\"soma\", \"axon\", \"dendrite\", \"neuropil\", \"artefact\", \"unknown\"])\n</code></pre>"}, {"location": "api/element_miniscope/miniscope/#element_miniscope.miniscope.ProcessingTask", "title": "<code>ProcessingTask</code>", "text": "<p>             Bases: <code>dj.Manual</code></p> <p>Table marking manual or automatic processing task.</p> <p>Attributes:</p> Name Type Description <code>RecordingInfo</code> <code>foreign key</code> <p>Recording info primary key.</p> <code>ProcessingParamSet</code> <code>foreign key</code> <p>Processing param set primary key.</p> <code>processing_output_dir</code> <code>varchar(255)</code> <p>relative output data directory for processed files.</p> <code>task_mode</code> <code>enum</code> <p><code>Load</code> existing results or <code>trigger</code> new processing task.</p> Source code in <code>element_miniscope/miniscope.py</code> <pre><code>@schema\nclass ProcessingTask(dj.Manual):\n\"\"\"Table marking manual or automatic processing task.\n\n    Attributes:\n        RecordingInfo (foreign key): Recording info primary key.\n        ProcessingParamSet (foreign key): Processing param set primary key.\n        processing_output_dir (varchar(255) ): relative output data directory for processed files.\n        task_mode (enum): `Load` existing results or `trigger` new processing task.\n    \"\"\"\n\n    definition = \"\"\"\n    # Manual table marking a processing task to be triggered or manually processed\n    -&gt; RecordingInfo\n    -&gt; ProcessingParamSet\n    ---\n    processing_output_dir : varchar(255)    # relative to the root data directory\n    task_mode='load'      : enum('load', 'trigger') # 'load': load existing results\n                                                    # 'trigger': trigger procedure\n    \"\"\"\n</code></pre>"}, {"location": "api/element_miniscope/miniscope/#element_miniscope.miniscope.Processing", "title": "<code>Processing</code>", "text": "<p>             Bases: <code>dj.Computed</code></p> <p>Automatic table that beings the miniscope processing pipeline.</p> <p>Attributes:</p> Name Type Description <code>ProcessingTask</code> <code>foreign key</code> <p>Processing task primary key.</p> <code>processing_time</code> <code>datetime</code> <p>Generates time of the processed results.</p> <code>package_version</code> <code>varchar(16)</code> <p>Package version information.</p> Source code in <code>element_miniscope/miniscope.py</code> <pre><code>@schema\nclass Processing(dj.Computed):\n\"\"\"Automatic table that beings the miniscope processing pipeline.\n\n    Attributes:\n        ProcessingTask (foreign key): Processing task primary key.\n        processing_time (datetime): Generates time of the processed results.\n        package_version (varchar(16) ): Package version information.\n    \"\"\"\n\n    definition = \"\"\"\n    -&gt; ProcessingTask\n    ---\n    processing_time     : datetime  # generation time of processed, segmented results\n    package_version=''  : varchar(16)\n    \"\"\"\n\n    def make(self, key):\n\"\"\"Triggers processing and populates Processing table.\"\"\"\n        task_mode = (ProcessingTask &amp; key).fetch1(\"task_mode\")\n\n        output_dir = (ProcessingTask &amp; key).fetch1(\"processing_output_dir\")\n        output_dir = find_full_path(get_miniscope_root_data_dir(), output_dir)\n\n        if task_mode == \"load\":\n            method, loaded_result = get_loader_result(key, ProcessingTask)\n            if method == \"caiman\":\n                loaded_caiman = loaded_result\n                key = {**key, \"processing_time\": loaded_caiman.creation_time}\n            else:\n                raise NotImplementedError(\n                    f\"Loading of {method} data is not yet supported\"\n                )\n        elif task_mode == \"trigger\":\n            method = (\n                ProcessingTask * ProcessingParamSet * ProcessingMethod * Recording &amp; key\n            ).fetch1(\"processing_method\")\n\n            if method == \"caiman\":\n                import caiman\n                from element_interface.run_caiman import run_caiman\n\n                avi_files = (\n                    Recording * RecordingInfo * RecordingInfo.File &amp; key\n                ).fetch(\"file_path\")\n                avi_files = [\n                    find_full_path(get_miniscope_root_data_dir(), avi_file).as_posix()\n                    for avi_file in avi_files\n                ]\n\n                params = (ProcessingTask * ProcessingParamSet &amp; key).fetch1(\"params\")\n                sampling_rate = (\n                    ProcessingTask * Recording * RecordingInfo &amp; key\n                ).fetch1(\"fps\")\n\n                input_hash = dict_to_uuid(dict(**key, **params))\n                input_hash_fp = output_dir / f\".{input_hash }.json\"\n\n                if not input_hash_fp.exists():\n                    start_time = datetime.utcnow()\n                    run_caiman(\n                        file_paths=avi_files,\n                        parameters=params,\n                        sampling_rate=sampling_rate,\n                        output_dir=output_dir.as_posix(),\n                        is3D=False,\n                    )\n                    completion_time = datetime.utcnow()\n                    with open(input_hash_fp, \"w\") as f:\n                        json.dump(\n                            {\n                                \"start_time\": start_time,\n                                \"completion_time\": completion_time,\n                                \"duration\": (\n                                    completion_time - start_time\n                                ).total_seconds(),\n                            },\n                            f,\n                            default=str,\n                        )\n\n                _, imaging_dataset = get_loader_result(key, ProcessingTask)\n                caiman_dataset = imaging_dataset\n                key[\"processing_time\"] = caiman_dataset.creation_time\n                key[\"package_version\"] = caiman.__version__\n            else:\n                raise NotImplementedError(\n                    f\"Automatic triggering of {method} analysis\"\n                    f\" is not yet supported\"\n                )\n        else:\n            raise ValueError(f\"Unknown task mode: {task_mode}\")\n\n        self.insert1(key)\n</code></pre>"}, {"location": "api/element_miniscope/miniscope/#element_miniscope.miniscope.Processing.make", "title": "<code>make(key)</code>", "text": "<p>Triggers processing and populates Processing table.</p> Source code in <code>element_miniscope/miniscope.py</code> <pre><code>def make(self, key):\n\"\"\"Triggers processing and populates Processing table.\"\"\"\n    task_mode = (ProcessingTask &amp; key).fetch1(\"task_mode\")\n\n    output_dir = (ProcessingTask &amp; key).fetch1(\"processing_output_dir\")\n    output_dir = find_full_path(get_miniscope_root_data_dir(), output_dir)\n\n    if task_mode == \"load\":\n        method, loaded_result = get_loader_result(key, ProcessingTask)\n        if method == \"caiman\":\n            loaded_caiman = loaded_result\n            key = {**key, \"processing_time\": loaded_caiman.creation_time}\n        else:\n            raise NotImplementedError(\n                f\"Loading of {method} data is not yet supported\"\n            )\n    elif task_mode == \"trigger\":\n        method = (\n            ProcessingTask * ProcessingParamSet * ProcessingMethod * Recording &amp; key\n        ).fetch1(\"processing_method\")\n\n        if method == \"caiman\":\n            import caiman\n            from element_interface.run_caiman import run_caiman\n\n            avi_files = (\n                Recording * RecordingInfo * RecordingInfo.File &amp; key\n            ).fetch(\"file_path\")\n            avi_files = [\n                find_full_path(get_miniscope_root_data_dir(), avi_file).as_posix()\n                for avi_file in avi_files\n            ]\n\n            params = (ProcessingTask * ProcessingParamSet &amp; key).fetch1(\"params\")\n            sampling_rate = (\n                ProcessingTask * Recording * RecordingInfo &amp; key\n            ).fetch1(\"fps\")\n\n            input_hash = dict_to_uuid(dict(**key, **params))\n            input_hash_fp = output_dir / f\".{input_hash }.json\"\n\n            if not input_hash_fp.exists():\n                start_time = datetime.utcnow()\n                run_caiman(\n                    file_paths=avi_files,\n                    parameters=params,\n                    sampling_rate=sampling_rate,\n                    output_dir=output_dir.as_posix(),\n                    is3D=False,\n                )\n                completion_time = datetime.utcnow()\n                with open(input_hash_fp, \"w\") as f:\n                    json.dump(\n                        {\n                            \"start_time\": start_time,\n                            \"completion_time\": completion_time,\n                            \"duration\": (\n                                completion_time - start_time\n                            ).total_seconds(),\n                        },\n                        f,\n                        default=str,\n                    )\n\n            _, imaging_dataset = get_loader_result(key, ProcessingTask)\n            caiman_dataset = imaging_dataset\n            key[\"processing_time\"] = caiman_dataset.creation_time\n            key[\"package_version\"] = caiman.__version__\n        else:\n            raise NotImplementedError(\n                f\"Automatic triggering of {method} analysis\"\n                f\" is not yet supported\"\n            )\n    else:\n        raise ValueError(f\"Unknown task mode: {task_mode}\")\n\n    self.insert1(key)\n</code></pre>"}, {"location": "api/element_miniscope/miniscope/#element_miniscope.miniscope.Curation", "title": "<code>Curation</code>", "text": "<p>             Bases: <code>dj.Manual</code></p> <p>Defines whether and how the results should be curated.</p> <p>Attributes:</p> Name Type Description <code>Processing</code> <code>foreign key</code> <p>Processing primary key.</p> <code>curation_id</code> <code>foreign key, int</code> <p>Unique curation ID.</p> <code>curation_time</code> <code>datetime</code> <p>Time of generation of curated results.</p> <code>curation_output_dir</code> <code>varchar(255)</code> <p>Output directory for curated results.</p> <code>manual_curation</code> <code>bool</code> <p>If True, manual curation has been performed.</p> <code>curation_note</code> <code>varchar(2000)</code> <p>Optional description of the curation procedure.</p> Source code in <code>element_miniscope/miniscope.py</code> <pre><code>@schema\nclass Curation(dj.Manual):\n\"\"\"Defines whether and how the results should be curated.\n\n    Attributes:\n        Processing (foreign key): Processing primary key.\n        curation_id (foreign key, int): Unique curation ID.\n        curation_time (datetime): Time of generation of curated results.\n        curation_output_dir (varchar(255) ): Output directory for curated results.\n        manual_curation (bool): If True, manual curation has been performed.\n        curation_note (varchar(2000) ): Optional description of the curation procedure.\n    \"\"\"\n\n    definition = \"\"\"\n    # Different rounds of curation performed on the processing results of the data\n    # (no-curation can also be included here)\n    -&gt; Processing\n    curation_id: int\n    ---\n    curation_time: datetime             # time of generation of these curated results\n    curation_output_dir: varchar(255)   # output directory of the curated results,\n                                        # relative to root data directory\n    manual_curation: bool               # has manual curation been performed?\n    curation_note='': varchar(2000)\n    \"\"\"\n\n    @classmethod\n    def create1_from_processing_task(self, key, is_curated=False, curation_note=\"\"):\n\"\"\"Given a \"ProcessingTask\", create a new corresponding \"Curation\" \"\"\"\n        if key not in Processing():\n            raise ValueError(\n                f\"No corresponding entry in Processing available for: \"\n                f\"{key}; run `Processing.populate(key)`\"\n            )\n\n        output_dir = (ProcessingTask &amp; key).fetch1(\"processing_output_dir\")\n        method, imaging_dataset = get_loader_result(key, ProcessingTask)\n\n        if method == \"caiman\":\n            caiman_dataset = imaging_dataset\n            curation_time = caiman_dataset.creation_time\n        else:\n            raise NotImplementedError(\"Unknown method: {}\".format(method))\n\n        # Synthesize curation_id\n        curation_id = (\n            dj.U().aggr(self &amp; key, n=\"ifnull(max(curation_id)+1,1)\").fetch1(\"n\")\n        )\n        self.insert1(\n            {\n                **key,\n                \"curation_id\": curation_id,\n                \"curation_time\": curation_time,\n                \"curation_output_dir\": output_dir,\n                \"manual_curation\": is_curated,\n                \"curation_note\": curation_note,\n            }\n        )\n</code></pre>"}, {"location": "api/element_miniscope/miniscope/#element_miniscope.miniscope.Curation.create1_from_processing_task", "title": "<code>create1_from_processing_task(key, is_curated=False, curation_note='')</code>  <code>classmethod</code>", "text": "<p>Given a \"ProcessingTask\", create a new corresponding \"Curation\"</p> Source code in <code>element_miniscope/miniscope.py</code> <pre><code>@classmethod\ndef create1_from_processing_task(self, key, is_curated=False, curation_note=\"\"):\n\"\"\"Given a \"ProcessingTask\", create a new corresponding \"Curation\" \"\"\"\n    if key not in Processing():\n        raise ValueError(\n            f\"No corresponding entry in Processing available for: \"\n            f\"{key}; run `Processing.populate(key)`\"\n        )\n\n    output_dir = (ProcessingTask &amp; key).fetch1(\"processing_output_dir\")\n    method, imaging_dataset = get_loader_result(key, ProcessingTask)\n\n    if method == \"caiman\":\n        caiman_dataset = imaging_dataset\n        curation_time = caiman_dataset.creation_time\n    else:\n        raise NotImplementedError(\"Unknown method: {}\".format(method))\n\n    # Synthesize curation_id\n    curation_id = (\n        dj.U().aggr(self &amp; key, n=\"ifnull(max(curation_id)+1,1)\").fetch1(\"n\")\n    )\n    self.insert1(\n        {\n            **key,\n            \"curation_id\": curation_id,\n            \"curation_time\": curation_time,\n            \"curation_output_dir\": output_dir,\n            \"manual_curation\": is_curated,\n            \"curation_note\": curation_note,\n        }\n    )\n</code></pre>"}, {"location": "api/element_miniscope/miniscope/#element_miniscope.miniscope.MotionCorrection", "title": "<code>MotionCorrection</code>", "text": "<p>             Bases: <code>dj.Imported</code></p> <p>Automated table performing motion correction analysis.</p> <p>Attributes:</p> Name Type Description <code>Curation</code> <code>foreign key</code> <p>Curation primary key.</p> <code>Channel.proj(motion_correct_channel='channel')</code> <code>foreign key</code> <p>Channel used for motion correction.</p> Source code in <code>element_miniscope/miniscope.py</code> <pre><code>@schema\nclass MotionCorrection(dj.Imported):\n\"\"\"Automated table performing motion correction analysis.\n\n    Attributes:\n        Curation (foreign key): Curation primary key.\n        Channel.proj(motion_correct_channel='channel'): Channel used for motion correction.\n    \"\"\"\n\n    definition = \"\"\"\n    -&gt; Curation\n    ---\n    -&gt; Channel.proj(motion_correct_channel='channel') # channel used for\n                                                      # motion correction\n    \"\"\"\n\n    class RigidMotionCorrection(dj.Part):\n\"\"\"Automated table with ridge motion correction data.\n\n        Attributes:\n            MotionCorrection (foreign key): MotionCorrection primary key.\n            outlier_frames (longblob): Mask with true for frames with outlier shifts.\n            y_shifts (longblob): y motion correction shifts, pixels.\n            x_shifts (longblob): x motion correction shifts, pixels.\n            y_std (float): Standard deviation of y shifts across all frames, pixels.\n            x_std (float): Standard deviation of x shifts across all frames, pixels.\n        \"\"\"\n\n        definition = \"\"\"\n        -&gt; master\n        ---\n        outlier_frames=null : longblob  # mask with true for frames with outlier shifts\n                                        # (already corrected)\n        y_shifts            : longblob  # (pixels) y motion correction shifts\n        x_shifts            : longblob  # (pixels) x motion correction shifts\n        y_std               : float     # (pixels) standard deviation of\n                                        # y shifts across all frames\n        x_std               : float     # (pixels) standard deviation of\n                                        # x shifts across all frames\n        \"\"\"\n\n    class NonRigidMotionCorrection(dj.Part):\n\"\"\"Automated table with piece-wise rigid motion correction data.\n\n        Attributes:\n            MotionCorrection (foreign key): MotionCorrection primary key.\n            outlier_frames (longblob): Mask with true for frames with outlier shifts (already corrected).\n            block_height (int): Height in pixels.\n            block_width (int): Width in pixels.\n            block_count_y (int): Number of blocks tiled in the y direction.\n            block_count_x (int): Number of blocks tiled in the x direction.\n        \"\"\"\n\n        definition = \"\"\"\n        -&gt; master\n        ---\n        outlier_frames=null             : longblob  # mask with true for frames with\n                                                    # outlier shifts (already corrected)\n        block_height                    : int       # (pixels)\n        block_width                     : int       # (pixels)\n        block_count_y                   : int       # number of blocks tiled in the\n                                                    # y direction\n        block_count_x                   : int       # number of blocks tiled in the\n                                                    # x direction\n        \"\"\"\n\n    class Block(dj.Part):\n\"\"\"Automated table with data for blocks used in non-rigid motion correction.\n\n        Attributes:\n            master.NonRigidMotionCorrection (foreign key): NonRigidMotionCorrection primary key.\n            block_id (foreign key, int): Unique ID for each block.\n            block_y (longblob): y_start and y_end of this block in pixels.\n            block_x (longblob): x_start and x_end of this block in pixels.\n            y_shifts (longblob): y motion correction shifts for every frame in pixels.\n            x_shifts (longblob): x motion correction shifts for every frame in pixels.\n            y_std (float): standard deviation of y shifts across all frames in pixels.\n            x_std (float): standard deviation of x shifts across all frames in pixels.\n        \"\"\"\n\n        definition = \"\"\"  # FOV-tiled blocks used for non-rigid motion correction\n        -&gt; master.NonRigidMotionCorrection\n        block_id : int\n        ---\n        block_y  : longblob  # (y_start, y_end) in pixel of this block\n        block_x  : longblob  # (x_start, x_end) in pixel of this block\n        y_shifts : longblob  # (pixels) y motion correction shifts for every frame\n        x_shifts : longblob  # (pixels) x motion correction shifts for every frame\n        y_std    : float     # (pixels) standard deviation of y shifts across all frames\n        x_std    : float     # (pixels) standard deviation of x shifts across all frames\n        \"\"\"\n\n    class Summary(dj.Part):\n\"\"\"A summary image for each field and channel after motion correction.\n\n        Attributes:\n            MotionCorrection (foreign key): MotionCorrection primary key.\n            ref_image (longblob): Image used as the alignment template.\n            average_image (longblob): Mean of registered frames.\n            correlation_image (longblob): Correlation map computed during cell detection.\n            max_proj_image (longblob): Maximum of registered frames.\n        \"\"\"\n\n        definition = \"\"\" # summary images for each field and channel after corrections\n        -&gt; master\n        ---\n        ref_image=null         : longblob  # image used as alignment template\n        average_image          : longblob  # mean of registered frames\n        correlation_image=null : longblob  # correlation map\n                                           # (computed during cell detection)\n        max_proj_image=null    : longblob  # max of registered frames\n        \"\"\"\n\n    def make(self, key):\n\"\"\"Populate tables with motion correction data.\"\"\"\n        method, loaded_result = get_loader_result(key, ProcessingTask)\n\n        if method == \"caiman\":\n            loaded_caiman = loaded_result\n\n            self.insert1(\n                {**key, \"motion_correct_channel\": loaded_caiman.alignment_channel}\n            )\n\n            # -- rigid motion correction --\n            if not loaded_caiman.params.motion[\"pw_rigid\"]:\n                rigid_correction = {\n                    **key,\n                    \"x_shifts\": loaded_caiman.motion_correction[\"shifts_rig\"][:, 0],\n                    \"y_shifts\": loaded_caiman.motion_correction[\"shifts_rig\"][:, 1],\n                    \"x_std\": np.nanstd(\n                        loaded_caiman.motion_correction[\"shifts_rig\"][:, 0]\n                    ),\n                    \"y_std\": np.nanstd(\n                        loaded_caiman.motion_correction[\"shifts_rig\"][:, 1]\n                    ),\n                    \"outlier_frames\": None,\n                }\n\n                self.RigidMotionCorrection.insert1(rigid_correction)\n\n            # -- non-rigid motion correction --\n            else:\n                nonrigid_correction = {\n                    **key,\n                    \"block_height\": (\n                        loaded_caiman.params.motion[\"strides\"][0]\n                        + loaded_caiman.params.motion[\"overlaps\"][0]\n                    ),\n                    \"block_width\": (\n                        loaded_caiman.params.motion[\"strides\"][1]\n                        + loaded_caiman.params.motion[\"overlaps\"][1]\n                    ),\n                    \"block_count_x\": len(\n                        set(loaded_caiman.motion_correction[\"coord_shifts_els\"][:, 0])\n                    ),\n                    \"block_count_y\": len(\n                        set(loaded_caiman.motion_correction[\"coord_shifts_els\"][:, 2])\n                    ),\n                    \"outlier_frames\": None,\n                }\n\n                nonrigid_blocks = []\n                for b_id in range(\n                    len(loaded_caiman.motion_correction[\"x_shifts_els\"][0, :])\n                ):\n                    nonrigid_blocks.append(\n                        {\n                            **key,\n                            \"block_id\": b_id,\n                            \"block_x\": np.arange(\n                                *loaded_caiman.motion_correction[\"coord_shifts_els\"][\n                                    b_id, 0:2\n                                ]\n                            ),\n                            \"block_y\": np.arange(\n                                *loaded_caiman.motion_correction[\"coord_shifts_els\"][\n                                    b_id, 2:4\n                                ]\n                            ),\n                            \"x_shifts\": loaded_caiman.motion_correction[\"x_shifts_els\"][\n                                :, b_id\n                            ],\n                            \"y_shifts\": loaded_caiman.motion_correction[\"y_shifts_els\"][\n                                :, b_id\n                            ],\n                            \"x_std\": np.nanstd(\n                                loaded_caiman.motion_correction[\"x_shifts_els\"][:, b_id]\n                            ),\n                            \"y_std\": np.nanstd(\n                                loaded_caiman.motion_correction[\"y_shifts_els\"][:, b_id]\n                            ),\n                        }\n                    )\n\n                self.NonRigidMotionCorrection.insert1(nonrigid_correction)\n                self.Block.insert(nonrigid_blocks)\n\n            # -- summary images --\n            summary_images = {\n                **key,\n                \"ref_image\": loaded_caiman.motion_correction[\"reference_image\"][...][\n                    np.newaxis, ...\n                ],\n                \"average_image\": loaded_caiman.motion_correction[\"average_image\"][...][\n                    np.newaxis, ...\n                ],\n                \"correlation_image\": loaded_caiman.motion_correction[\n                    \"correlation_image\"\n                ][...][np.newaxis, ...],\n                \"max_proj_image\": loaded_caiman.motion_correction[\"max_image\"][...][\n                    np.newaxis, ...\n                ],\n            }\n\n            self.Summary.insert1(summary_images)\n\n        else:\n            raise NotImplementedError(\"Unknown/unimplemented method: {}\".format(method))\n</code></pre>"}, {"location": "api/element_miniscope/miniscope/#element_miniscope.miniscope.MotionCorrection.RigidMotionCorrection", "title": "<code>RigidMotionCorrection</code>", "text": "<p>             Bases: <code>dj.Part</code></p> <p>Automated table with ridge motion correction data.</p> <p>Attributes:</p> Name Type Description <code>MotionCorrection</code> <code>foreign key</code> <p>MotionCorrection primary key.</p> <code>outlier_frames</code> <code>longblob</code> <p>Mask with true for frames with outlier shifts.</p> <code>y_shifts</code> <code>longblob</code> <p>y motion correction shifts, pixels.</p> <code>x_shifts</code> <code>longblob</code> <p>x motion correction shifts, pixels.</p> <code>y_std</code> <code>float</code> <p>Standard deviation of y shifts across all frames, pixels.</p> <code>x_std</code> <code>float</code> <p>Standard deviation of x shifts across all frames, pixels.</p> Source code in <code>element_miniscope/miniscope.py</code> <pre><code>class RigidMotionCorrection(dj.Part):\n\"\"\"Automated table with ridge motion correction data.\n\n    Attributes:\n        MotionCorrection (foreign key): MotionCorrection primary key.\n        outlier_frames (longblob): Mask with true for frames with outlier shifts.\n        y_shifts (longblob): y motion correction shifts, pixels.\n        x_shifts (longblob): x motion correction shifts, pixels.\n        y_std (float): Standard deviation of y shifts across all frames, pixels.\n        x_std (float): Standard deviation of x shifts across all frames, pixels.\n    \"\"\"\n\n    definition = \"\"\"\n    -&gt; master\n    ---\n    outlier_frames=null : longblob  # mask with true for frames with outlier shifts\n                                    # (already corrected)\n    y_shifts            : longblob  # (pixels) y motion correction shifts\n    x_shifts            : longblob  # (pixels) x motion correction shifts\n    y_std               : float     # (pixels) standard deviation of\n                                    # y shifts across all frames\n    x_std               : float     # (pixels) standard deviation of\n                                    # x shifts across all frames\n    \"\"\"\n</code></pre>"}, {"location": "api/element_miniscope/miniscope/#element_miniscope.miniscope.MotionCorrection.NonRigidMotionCorrection", "title": "<code>NonRigidMotionCorrection</code>", "text": "<p>             Bases: <code>dj.Part</code></p> <p>Automated table with piece-wise rigid motion correction data.</p> <p>Attributes:</p> Name Type Description <code>MotionCorrection</code> <code>foreign key</code> <p>MotionCorrection primary key.</p> <code>outlier_frames</code> <code>longblob</code> <p>Mask with true for frames with outlier shifts (already corrected).</p> <code>block_height</code> <code>int</code> <p>Height in pixels.</p> <code>block_width</code> <code>int</code> <p>Width in pixels.</p> <code>block_count_y</code> <code>int</code> <p>Number of blocks tiled in the y direction.</p> <code>block_count_x</code> <code>int</code> <p>Number of blocks tiled in the x direction.</p> Source code in <code>element_miniscope/miniscope.py</code> <pre><code>class NonRigidMotionCorrection(dj.Part):\n\"\"\"Automated table with piece-wise rigid motion correction data.\n\n    Attributes:\n        MotionCorrection (foreign key): MotionCorrection primary key.\n        outlier_frames (longblob): Mask with true for frames with outlier shifts (already corrected).\n        block_height (int): Height in pixels.\n        block_width (int): Width in pixels.\n        block_count_y (int): Number of blocks tiled in the y direction.\n        block_count_x (int): Number of blocks tiled in the x direction.\n    \"\"\"\n\n    definition = \"\"\"\n    -&gt; master\n    ---\n    outlier_frames=null             : longblob  # mask with true for frames with\n                                                # outlier shifts (already corrected)\n    block_height                    : int       # (pixels)\n    block_width                     : int       # (pixels)\n    block_count_y                   : int       # number of blocks tiled in the\n                                                # y direction\n    block_count_x                   : int       # number of blocks tiled in the\n                                                # x direction\n    \"\"\"\n</code></pre>"}, {"location": "api/element_miniscope/miniscope/#element_miniscope.miniscope.MotionCorrection.Block", "title": "<code>Block</code>", "text": "<p>             Bases: <code>dj.Part</code></p> <p>Automated table with data for blocks used in non-rigid motion correction.</p> <p>Attributes:</p> Name Type Description <code>master.NonRigidMotionCorrection</code> <code>foreign key</code> <p>NonRigidMotionCorrection primary key.</p> <code>block_id</code> <code>foreign key, int</code> <p>Unique ID for each block.</p> <code>block_y</code> <code>longblob</code> <p>y_start and y_end of this block in pixels.</p> <code>block_x</code> <code>longblob</code> <p>x_start and x_end of this block in pixels.</p> <code>y_shifts</code> <code>longblob</code> <p>y motion correction shifts for every frame in pixels.</p> <code>x_shifts</code> <code>longblob</code> <p>x motion correction shifts for every frame in pixels.</p> <code>y_std</code> <code>float</code> <p>standard deviation of y shifts across all frames in pixels.</p> <code>x_std</code> <code>float</code> <p>standard deviation of x shifts across all frames in pixels.</p> Source code in <code>element_miniscope/miniscope.py</code> <pre><code>class Block(dj.Part):\n\"\"\"Automated table with data for blocks used in non-rigid motion correction.\n\n    Attributes:\n        master.NonRigidMotionCorrection (foreign key): NonRigidMotionCorrection primary key.\n        block_id (foreign key, int): Unique ID for each block.\n        block_y (longblob): y_start and y_end of this block in pixels.\n        block_x (longblob): x_start and x_end of this block in pixels.\n        y_shifts (longblob): y motion correction shifts for every frame in pixels.\n        x_shifts (longblob): x motion correction shifts for every frame in pixels.\n        y_std (float): standard deviation of y shifts across all frames in pixels.\n        x_std (float): standard deviation of x shifts across all frames in pixels.\n    \"\"\"\n\n    definition = \"\"\"  # FOV-tiled blocks used for non-rigid motion correction\n    -&gt; master.NonRigidMotionCorrection\n    block_id : int\n    ---\n    block_y  : longblob  # (y_start, y_end) in pixel of this block\n    block_x  : longblob  # (x_start, x_end) in pixel of this block\n    y_shifts : longblob  # (pixels) y motion correction shifts for every frame\n    x_shifts : longblob  # (pixels) x motion correction shifts for every frame\n    y_std    : float     # (pixels) standard deviation of y shifts across all frames\n    x_std    : float     # (pixels) standard deviation of x shifts across all frames\n    \"\"\"\n</code></pre>"}, {"location": "api/element_miniscope/miniscope/#element_miniscope.miniscope.MotionCorrection.Summary", "title": "<code>Summary</code>", "text": "<p>             Bases: <code>dj.Part</code></p> <p>A summary image for each field and channel after motion correction.</p> <p>Attributes:</p> Name Type Description <code>MotionCorrection</code> <code>foreign key</code> <p>MotionCorrection primary key.</p> <code>ref_image</code> <code>longblob</code> <p>Image used as the alignment template.</p> <code>average_image</code> <code>longblob</code> <p>Mean of registered frames.</p> <code>correlation_image</code> <code>longblob</code> <p>Correlation map computed during cell detection.</p> <code>max_proj_image</code> <code>longblob</code> <p>Maximum of registered frames.</p> Source code in <code>element_miniscope/miniscope.py</code> <pre><code>class Summary(dj.Part):\n\"\"\"A summary image for each field and channel after motion correction.\n\n    Attributes:\n        MotionCorrection (foreign key): MotionCorrection primary key.\n        ref_image (longblob): Image used as the alignment template.\n        average_image (longblob): Mean of registered frames.\n        correlation_image (longblob): Correlation map computed during cell detection.\n        max_proj_image (longblob): Maximum of registered frames.\n    \"\"\"\n\n    definition = \"\"\" # summary images for each field and channel after corrections\n    -&gt; master\n    ---\n    ref_image=null         : longblob  # image used as alignment template\n    average_image          : longblob  # mean of registered frames\n    correlation_image=null : longblob  # correlation map\n                                       # (computed during cell detection)\n    max_proj_image=null    : longblob  # max of registered frames\n    \"\"\"\n</code></pre>"}, {"location": "api/element_miniscope/miniscope/#element_miniscope.miniscope.MotionCorrection.make", "title": "<code>make(key)</code>", "text": "<p>Populate tables with motion correction data.</p> Source code in <code>element_miniscope/miniscope.py</code> <pre><code>def make(self, key):\n\"\"\"Populate tables with motion correction data.\"\"\"\n    method, loaded_result = get_loader_result(key, ProcessingTask)\n\n    if method == \"caiman\":\n        loaded_caiman = loaded_result\n\n        self.insert1(\n            {**key, \"motion_correct_channel\": loaded_caiman.alignment_channel}\n        )\n\n        # -- rigid motion correction --\n        if not loaded_caiman.params.motion[\"pw_rigid\"]:\n            rigid_correction = {\n                **key,\n                \"x_shifts\": loaded_caiman.motion_correction[\"shifts_rig\"][:, 0],\n                \"y_shifts\": loaded_caiman.motion_correction[\"shifts_rig\"][:, 1],\n                \"x_std\": np.nanstd(\n                    loaded_caiman.motion_correction[\"shifts_rig\"][:, 0]\n                ),\n                \"y_std\": np.nanstd(\n                    loaded_caiman.motion_correction[\"shifts_rig\"][:, 1]\n                ),\n                \"outlier_frames\": None,\n            }\n\n            self.RigidMotionCorrection.insert1(rigid_correction)\n\n        # -- non-rigid motion correction --\n        else:\n            nonrigid_correction = {\n                **key,\n                \"block_height\": (\n                    loaded_caiman.params.motion[\"strides\"][0]\n                    + loaded_caiman.params.motion[\"overlaps\"][0]\n                ),\n                \"block_width\": (\n                    loaded_caiman.params.motion[\"strides\"][1]\n                    + loaded_caiman.params.motion[\"overlaps\"][1]\n                ),\n                \"block_count_x\": len(\n                    set(loaded_caiman.motion_correction[\"coord_shifts_els\"][:, 0])\n                ),\n                \"block_count_y\": len(\n                    set(loaded_caiman.motion_correction[\"coord_shifts_els\"][:, 2])\n                ),\n                \"outlier_frames\": None,\n            }\n\n            nonrigid_blocks = []\n            for b_id in range(\n                len(loaded_caiman.motion_correction[\"x_shifts_els\"][0, :])\n            ):\n                nonrigid_blocks.append(\n                    {\n                        **key,\n                        \"block_id\": b_id,\n                        \"block_x\": np.arange(\n                            *loaded_caiman.motion_correction[\"coord_shifts_els\"][\n                                b_id, 0:2\n                            ]\n                        ),\n                        \"block_y\": np.arange(\n                            *loaded_caiman.motion_correction[\"coord_shifts_els\"][\n                                b_id, 2:4\n                            ]\n                        ),\n                        \"x_shifts\": loaded_caiman.motion_correction[\"x_shifts_els\"][\n                            :, b_id\n                        ],\n                        \"y_shifts\": loaded_caiman.motion_correction[\"y_shifts_els\"][\n                            :, b_id\n                        ],\n                        \"x_std\": np.nanstd(\n                            loaded_caiman.motion_correction[\"x_shifts_els\"][:, b_id]\n                        ),\n                        \"y_std\": np.nanstd(\n                            loaded_caiman.motion_correction[\"y_shifts_els\"][:, b_id]\n                        ),\n                    }\n                )\n\n            self.NonRigidMotionCorrection.insert1(nonrigid_correction)\n            self.Block.insert(nonrigid_blocks)\n\n        # -- summary images --\n        summary_images = {\n            **key,\n            \"ref_image\": loaded_caiman.motion_correction[\"reference_image\"][...][\n                np.newaxis, ...\n            ],\n            \"average_image\": loaded_caiman.motion_correction[\"average_image\"][...][\n                np.newaxis, ...\n            ],\n            \"correlation_image\": loaded_caiman.motion_correction[\n                \"correlation_image\"\n            ][...][np.newaxis, ...],\n            \"max_proj_image\": loaded_caiman.motion_correction[\"max_image\"][...][\n                np.newaxis, ...\n            ],\n        }\n\n        self.Summary.insert1(summary_images)\n\n    else:\n        raise NotImplementedError(\"Unknown/unimplemented method: {}\".format(method))\n</code></pre>"}, {"location": "api/element_miniscope/miniscope/#element_miniscope.miniscope.Segmentation", "title": "<code>Segmentation</code>", "text": "<p>             Bases: <code>dj.Computed</code></p> <p>Automated table computes different mask segmentations.</p> <p>Attributes:</p> Name Type Description <code>Curation</code> <code>foreign key</code> <p>Curation primary key.</p> Source code in <code>element_miniscope/miniscope.py</code> <pre><code>@schema\nclass Segmentation(dj.Computed):\n\"\"\"Automated table computes different mask segmentations.\n\n    Attributes:\n        Curation (foreign key): Curation primary key.\n    \"\"\"\n\n    definition = \"\"\" # Different mask segmentations.\n    -&gt; Curation\n    \"\"\"\n\n    class Mask(dj.Part):\n\"\"\"Image masks produced during segmentation.\n\n        Attributes:\n            Segmentation (foreign key): Segmentation primary key.\n            mask (smallint): Unique ID for each mask.\n            channel.proj(segmentation_channel='channel') (query): Channel to be used for segmentation.\n            mask_npix (int): Number of pixels in the mask.\n            mask_center_x (int): Center x coordinate in pixels.\n            mask_center_y (int): Center y coordinate in pixels.\n            mask_xpix (longblob): x coordinates of the mask in pixels.\n            mask_ypix (longblob): y coordinates of the mask in pixels.\n            mask_weights (longblob): weights of the mask at the indices above.\n        \"\"\"\n\n        definition = \"\"\" # A mask produced by segmentation.\n        -&gt; master\n        mask                 : smallint\n        ---\n        -&gt; Channel.proj(segmentation_channel='channel')  # channel used for segmentation\n        mask_npix            : int       # number of pixels in this mask\n        mask_center_x=null   : int       # (pixels) center x coordinate\n        mask_center_y=null   : int       # (pixels) center y coordinate\n        mask_xpix=null       : longblob  # (pixels) x coordinates\n        mask_ypix=null       : longblob  # (pixels) y coordinates\n        mask_weights         : longblob  # weights of the mask at the indices above\n        \"\"\"\n\n    def make(self, key):\n\"\"\"Populates table with segmentation data.\"\"\"\n        method, loaded_result = get_loader_result(key, Curation)\n\n        if method == \"caiman\":\n            loaded_caiman = loaded_result\n\n            # infer `segmentation_channel` from `params` if available,\n            # else from caiman loader\n            params = (ProcessingParamSet * ProcessingTask &amp; key).fetch1(\"params\")\n            segmentation_channel = params.get(\n                \"segmentation_channel\", loaded_caiman.segmentation_channel\n            )\n\n            masks, cells = [], []\n            for mask in loaded_caiman.masks:\n                # Sample data had _id key, not mask. Permitting both\n                mask_id = mask.get(\"mask\", mask[\"mask_id\"])\n                masks.append(\n                    {\n                        **key,\n                        \"segmentation_channel\": segmentation_channel,\n                        \"mask\": mask_id,\n                        \"mask_npix\": mask[\"mask_npix\"],\n                        \"mask_center_x\": mask[\"mask_center_x\"],\n                        \"mask_center_y\": mask[\"mask_center_y\"],\n                        \"mask_xpix\": mask[\"mask_xpix\"],\n                        \"mask_ypix\": mask[\"mask_ypix\"],\n                        \"mask_weights\": mask[\"mask_weights\"],\n                    }\n                )\n\n                if loaded_caiman.cnmf.estimates.idx_components is not None:\n                    if mask_id in loaded_caiman.cnmf.estimates.idx_components:\n                        cells.append(\n                            {\n                                **key,\n                                \"mask_classification_method\": \"caiman_default_classifier\",\n                                \"mask\": mask_id,\n                                \"mask_type\": \"soma\",\n                            }\n                        )\n\n            if not all([all(m.values()) for m in masks]):\n                logger.warning(\"Could not load all pixel values for at least one mask\")\n\n            self.insert1(key)\n            self.Mask.insert(masks, ignore_extra_fields=True)\n\n            if cells:\n                MaskClassification.insert1(\n                    {**key, \"mask_classification_method\": \"caiman_default_classifier\"},\n                    allow_direct_insert=True,\n                )\n                MaskClassification.MaskType.insert(\n                    cells, ignore_extra_fields=True, allow_direct_insert=True\n                )\n\n        else:\n            raise NotImplementedError(f\"Unknown/unimplemented method: {method}\")\n</code></pre>"}, {"location": "api/element_miniscope/miniscope/#element_miniscope.miniscope.Segmentation.Mask", "title": "<code>Mask</code>", "text": "<p>             Bases: <code>dj.Part</code></p> <p>Image masks produced during segmentation.</p> <p>Attributes:</p> Name Type Description <code>Segmentation</code> <code>foreign key</code> <p>Segmentation primary key.</p> <code>mask</code> <code>smallint</code> <p>Unique ID for each mask.</p> <code>channel.proj(segmentation_channel='channel')</code> <code>query</code> <p>Channel to be used for segmentation.</p> <code>mask_npix</code> <code>int</code> <p>Number of pixels in the mask.</p> <code>mask_center_x</code> <code>int</code> <p>Center x coordinate in pixels.</p> <code>mask_center_y</code> <code>int</code> <p>Center y coordinate in pixels.</p> <code>mask_xpix</code> <code>longblob</code> <p>x coordinates of the mask in pixels.</p> <code>mask_ypix</code> <code>longblob</code> <p>y coordinates of the mask in pixels.</p> <code>mask_weights</code> <code>longblob</code> <p>weights of the mask at the indices above.</p> Source code in <code>element_miniscope/miniscope.py</code> <pre><code>class Mask(dj.Part):\n\"\"\"Image masks produced during segmentation.\n\n    Attributes:\n        Segmentation (foreign key): Segmentation primary key.\n        mask (smallint): Unique ID for each mask.\n        channel.proj(segmentation_channel='channel') (query): Channel to be used for segmentation.\n        mask_npix (int): Number of pixels in the mask.\n        mask_center_x (int): Center x coordinate in pixels.\n        mask_center_y (int): Center y coordinate in pixels.\n        mask_xpix (longblob): x coordinates of the mask in pixels.\n        mask_ypix (longblob): y coordinates of the mask in pixels.\n        mask_weights (longblob): weights of the mask at the indices above.\n    \"\"\"\n\n    definition = \"\"\" # A mask produced by segmentation.\n    -&gt; master\n    mask                 : smallint\n    ---\n    -&gt; Channel.proj(segmentation_channel='channel')  # channel used for segmentation\n    mask_npix            : int       # number of pixels in this mask\n    mask_center_x=null   : int       # (pixels) center x coordinate\n    mask_center_y=null   : int       # (pixels) center y coordinate\n    mask_xpix=null       : longblob  # (pixels) x coordinates\n    mask_ypix=null       : longblob  # (pixels) y coordinates\n    mask_weights         : longblob  # weights of the mask at the indices above\n    \"\"\"\n</code></pre>"}, {"location": "api/element_miniscope/miniscope/#element_miniscope.miniscope.Segmentation.make", "title": "<code>make(key)</code>", "text": "<p>Populates table with segmentation data.</p> Source code in <code>element_miniscope/miniscope.py</code> <pre><code>def make(self, key):\n\"\"\"Populates table with segmentation data.\"\"\"\n    method, loaded_result = get_loader_result(key, Curation)\n\n    if method == \"caiman\":\n        loaded_caiman = loaded_result\n\n        # infer `segmentation_channel` from `params` if available,\n        # else from caiman loader\n        params = (ProcessingParamSet * ProcessingTask &amp; key).fetch1(\"params\")\n        segmentation_channel = params.get(\n            \"segmentation_channel\", loaded_caiman.segmentation_channel\n        )\n\n        masks, cells = [], []\n        for mask in loaded_caiman.masks:\n            # Sample data had _id key, not mask. Permitting both\n            mask_id = mask.get(\"mask\", mask[\"mask_id\"])\n            masks.append(\n                {\n                    **key,\n                    \"segmentation_channel\": segmentation_channel,\n                    \"mask\": mask_id,\n                    \"mask_npix\": mask[\"mask_npix\"],\n                    \"mask_center_x\": mask[\"mask_center_x\"],\n                    \"mask_center_y\": mask[\"mask_center_y\"],\n                    \"mask_xpix\": mask[\"mask_xpix\"],\n                    \"mask_ypix\": mask[\"mask_ypix\"],\n                    \"mask_weights\": mask[\"mask_weights\"],\n                }\n            )\n\n            if loaded_caiman.cnmf.estimates.idx_components is not None:\n                if mask_id in loaded_caiman.cnmf.estimates.idx_components:\n                    cells.append(\n                        {\n                            **key,\n                            \"mask_classification_method\": \"caiman_default_classifier\",\n                            \"mask\": mask_id,\n                            \"mask_type\": \"soma\",\n                        }\n                    )\n\n        if not all([all(m.values()) for m in masks]):\n            logger.warning(\"Could not load all pixel values for at least one mask\")\n\n        self.insert1(key)\n        self.Mask.insert(masks, ignore_extra_fields=True)\n\n        if cells:\n            MaskClassification.insert1(\n                {**key, \"mask_classification_method\": \"caiman_default_classifier\"},\n                allow_direct_insert=True,\n            )\n            MaskClassification.MaskType.insert(\n                cells, ignore_extra_fields=True, allow_direct_insert=True\n            )\n\n    else:\n        raise NotImplementedError(f\"Unknown/unimplemented method: {method}\")\n</code></pre>"}, {"location": "api/element_miniscope/miniscope/#element_miniscope.miniscope.MaskClassificationMethod", "title": "<code>MaskClassificationMethod</code>", "text": "<p>             Bases: <code>dj.Lookup</code></p> <p>Method to classify segmented masks.</p> <p>Attributes:</p> Name Type Description <code>mask_classification_method</code> <code>foreign key, varchar(48) </code> <p>Method by which masks are classified into mask types.</p> Source code in <code>element_miniscope/miniscope.py</code> <pre><code>@schema\nclass MaskClassificationMethod(dj.Lookup):\n\"\"\"Method to classify segmented masks.\n\n    Attributes:\n        mask_classification_method (foreign key, varchar(48) ): Method by which masks\n            are classified into mask types.\n    \"\"\"\n\n    definition = \"\"\"\n    mask_classification_method: varchar(48)\n    \"\"\"\n\n    contents = zip([\"caiman_default_classifier\"])\n</code></pre>"}, {"location": "api/element_miniscope/miniscope/#element_miniscope.miniscope.MaskClassification", "title": "<code>MaskClassification</code>", "text": "<p>             Bases: <code>dj.Computed</code></p> <p>Automated table with mask classification data.</p> <p>Attributes:</p> Name Type Description <code>Segmentation</code> <code>foreign key</code> <p>Segmentation primary key.</p> <code>MaskClassificationMethod</code> <code>foreign key</code> <p>MaskClassificationMethod primary key.</p> Source code in <code>element_miniscope/miniscope.py</code> <pre><code>@schema\nclass MaskClassification(dj.Computed):\n\"\"\"Automated table with mask classification data.\n\n    Attributes:\n        Segmentation (foreign key): Segmentation primary key.\n        MaskClassificationMethod (foreign key): MaskClassificationMethod primary key.\n    \"\"\"\n\n    definition = \"\"\"\n    -&gt; Segmentation\n    -&gt; MaskClassificationMethod\n    \"\"\"\n\n    class MaskType(dj.Part):\n\"\"\"Automated table storing mask type data.\n\n        Attributes:\n            MaskClassification (foreign key): MaskClassification primary key.\n            Segmentation.Mask (foreign key): Segmentation.Mask primary key.\n            MaskType (dict): Select mask type from entries within `MaskType` look up table.\n            confidence (float): Statistical confidence of mask classification.\n        \"\"\"\n\n        definition = \"\"\"\n        -&gt; master\n        -&gt; Segmentation.Mask\n        ---\n        -&gt; MaskType\n        confidence=null: float\n        \"\"\"\n\n    def make(self, key):\n        raise NotImplementedError(\n            \"To add to this table, use `insert` with allow_direct_insert=True\"\n        )\n</code></pre>"}, {"location": "api/element_miniscope/miniscope/#element_miniscope.miniscope.MaskClassification.MaskType", "title": "<code>MaskType</code>", "text": "<p>             Bases: <code>dj.Part</code></p> <p>Automated table storing mask type data.</p> <p>Attributes:</p> Name Type Description <code>MaskClassification</code> <code>foreign key</code> <p>MaskClassification primary key.</p> <code>Segmentation.Mask</code> <code>foreign key</code> <p>Segmentation.Mask primary key.</p> <code>MaskType</code> <code>dict</code> <p>Select mask type from entries within <code>MaskType</code> look up table.</p> <code>confidence</code> <code>float</code> <p>Statistical confidence of mask classification.</p> Source code in <code>element_miniscope/miniscope.py</code> <pre><code>class MaskType(dj.Part):\n\"\"\"Automated table storing mask type data.\n\n    Attributes:\n        MaskClassification (foreign key): MaskClassification primary key.\n        Segmentation.Mask (foreign key): Segmentation.Mask primary key.\n        MaskType (dict): Select mask type from entries within `MaskType` look up table.\n        confidence (float): Statistical confidence of mask classification.\n    \"\"\"\n\n    definition = \"\"\"\n    -&gt; master\n    -&gt; Segmentation.Mask\n    ---\n    -&gt; MaskType\n    confidence=null: float\n    \"\"\"\n</code></pre>"}, {"location": "api/element_miniscope/miniscope/#element_miniscope.miniscope.Fluorescence", "title": "<code>Fluorescence</code>", "text": "<p>             Bases: <code>dj.Computed</code></p> <p>Extracts fluorescence trace information.</p> <p>Attributes:</p> Name Type Description <code>Segmentation</code> <code>foreign key</code> <p>Segmentation primary key.</p> Source code in <code>element_miniscope/miniscope.py</code> <pre><code>@schema\nclass Fluorescence(dj.Computed):\n\"\"\"Extracts fluorescence trace information.\n\n    Attributes:\n        Segmentation (foreign key): Segmentation primary key.\n    \"\"\"\n\n    definition = \"\"\"  # fluorescence traces before spike extraction or filtering\n    -&gt; Segmentation\n    \"\"\"\n\n    class Trace(dj.Part):\n\"\"\"Automated table with Fluorescence traces\n\n        Attributes:\n            Fluorescence (foreign key): Fluorescence primary key.\n            Segmentation.Mask (foreign key): Segmentation.Mask primary key.\n            Channel.proj(fluorescence_channel='channel') (foreign key, query): Channel\n                used for this trace.\n            fluorescence (longblob): A fluorescence trace associated with a given mask.\n            neuropil_fluorescence (longblob): A neuropil fluorescence trace.\n        \"\"\"\n\n        definition = \"\"\"\n        -&gt; master\n        -&gt; Segmentation.Mask\n        -&gt; Channel.proj(fluorescence_channel='channel')  # channel used for this trace\n        ---\n        fluorescence                : longblob  # fluorescence trace associated\n                                                # with this mask\n        neuropil_fluorescence=null  : longblob  # Neuropil fluorescence trace\n        \"\"\"\n\n    def make(self, key):\n\"\"\"Populates table with fluorescence trace data.\"\"\"\n        method, loaded_result = get_loader_result(key, Curation)\n\n        if method == \"caiman\":\n            loaded_caiman = loaded_result\n\n            # infer `segmentation_channel` from `params` if available,\n            # else from caiman loader\n            params = (ProcessingParamSet * ProcessingTask &amp; key).fetch1(\"params\")\n            segmentation_channel = params.get(\n                \"segmentation_channel\", loaded_caiman.segmentation_channel\n            )\n\n            self.insert1(key)\n            self.Trace.insert(\n                [\n                    {\n                        **key,\n                        \"mask\": mask.get(\"mask\", mask[\"mask_id\"]),\n                        \"fluorescence_channel\": segmentation_channel,\n                        \"fluorescence\": mask[\"inferred_trace\"],\n                    }\n                    for mask in loaded_caiman.masks\n                ]\n            )\n\n        else:\n            raise NotImplementedError(\"Unknown/unimplemented method: {}\".format(method))\n</code></pre>"}, {"location": "api/element_miniscope/miniscope/#element_miniscope.miniscope.Fluorescence.Trace", "title": "<code>Trace</code>", "text": "<p>             Bases: <code>dj.Part</code></p> <p>Automated table with Fluorescence traces</p> <p>Attributes:</p> Name Type Description <code>Fluorescence</code> <code>foreign key</code> <p>Fluorescence primary key.</p> <code>Segmentation.Mask</code> <code>foreign key</code> <p>Segmentation.Mask primary key.</p> <code>Channel.proj(fluorescence_channel='channel')</code> <code>foreign key, query</code> <p>Channel used for this trace.</p> <code>fluorescence</code> <code>longblob</code> <p>A fluorescence trace associated with a given mask.</p> <code>neuropil_fluorescence</code> <code>longblob</code> <p>A neuropil fluorescence trace.</p> Source code in <code>element_miniscope/miniscope.py</code> <pre><code>class Trace(dj.Part):\n\"\"\"Automated table with Fluorescence traces\n\n    Attributes:\n        Fluorescence (foreign key): Fluorescence primary key.\n        Segmentation.Mask (foreign key): Segmentation.Mask primary key.\n        Channel.proj(fluorescence_channel='channel') (foreign key, query): Channel\n            used for this trace.\n        fluorescence (longblob): A fluorescence trace associated with a given mask.\n        neuropil_fluorescence (longblob): A neuropil fluorescence trace.\n    \"\"\"\n\n    definition = \"\"\"\n    -&gt; master\n    -&gt; Segmentation.Mask\n    -&gt; Channel.proj(fluorescence_channel='channel')  # channel used for this trace\n    ---\n    fluorescence                : longblob  # fluorescence trace associated\n                                            # with this mask\n    neuropil_fluorescence=null  : longblob  # Neuropil fluorescence trace\n    \"\"\"\n</code></pre>"}, {"location": "api/element_miniscope/miniscope/#element_miniscope.miniscope.Fluorescence.make", "title": "<code>make(key)</code>", "text": "<p>Populates table with fluorescence trace data.</p> Source code in <code>element_miniscope/miniscope.py</code> <pre><code>def make(self, key):\n\"\"\"Populates table with fluorescence trace data.\"\"\"\n    method, loaded_result = get_loader_result(key, Curation)\n\n    if method == \"caiman\":\n        loaded_caiman = loaded_result\n\n        # infer `segmentation_channel` from `params` if available,\n        # else from caiman loader\n        params = (ProcessingParamSet * ProcessingTask &amp; key).fetch1(\"params\")\n        segmentation_channel = params.get(\n            \"segmentation_channel\", loaded_caiman.segmentation_channel\n        )\n\n        self.insert1(key)\n        self.Trace.insert(\n            [\n                {\n                    **key,\n                    \"mask\": mask.get(\"mask\", mask[\"mask_id\"]),\n                    \"fluorescence_channel\": segmentation_channel,\n                    \"fluorescence\": mask[\"inferred_trace\"],\n                }\n                for mask in loaded_caiman.masks\n            ]\n        )\n\n    else:\n        raise NotImplementedError(\"Unknown/unimplemented method: {}\".format(method))\n</code></pre>"}, {"location": "api/element_miniscope/miniscope/#element_miniscope.miniscope.ActivityExtractionMethod", "title": "<code>ActivityExtractionMethod</code>", "text": "<p>             Bases: <code>dj.Lookup</code></p> <p>Lookup table for activity extraction methods.</p> <p>Attributes:</p> Name Type Description <code>extraction_method</code> <code>foreign key, varchar(32) </code> <p>Extraction method from CaImAn.</p> Source code in <code>element_miniscope/miniscope.py</code> <pre><code>@schema\nclass ActivityExtractionMethod(dj.Lookup):\n\"\"\"Lookup table for activity extraction methods.\n\n    Attributes:\n        extraction_method (foreign key, varchar(32) ): Extraction method from CaImAn.\n    \"\"\"\n\n    definition = \"\"\"\n    extraction_method: varchar(32)\n    \"\"\"\n\n    contents = zip([\"caiman_deconvolution\", \"caiman_dff\"])\n</code></pre>"}, {"location": "api/element_miniscope/miniscope/#element_miniscope.miniscope.Activity", "title": "<code>Activity</code>", "text": "<p>             Bases: <code>dj.Computed</code></p> <p>Inferred neural activity from the fluorescence trace.</p> <p>Attributes:</p> Name Type Description <code>Fluorescence</code> <code>foreign key</code> <p>Fluorescence primary key.</p> <code>ActivityExtractionMethod</code> <code>foreign key</code> <p>ActivityExtractionMethod primary key.</p> Source code in <code>element_miniscope/miniscope.py</code> <pre><code>@schema\nclass Activity(dj.Computed):\n\"\"\"Inferred neural activity from the fluorescence trace.\n\n    Attributes:\n        Fluorescence (foreign key): Fluorescence primary key.\n        ActivityExtractionMethod (foreign key): ActivityExtractionMethod primary key.\n    \"\"\"\n\n    definition = \"\"\"\n    # inferred neural activity from fluorescence trace - e.g. dff, spikes\n    -&gt; Fluorescence\n    -&gt; ActivityExtractionMethod\n    \"\"\"\n\n    class Trace(dj.Part):\n\"\"\"Automated table with activity traces.\n\n        Attributes:\n            Activity (foreign key): Activity primary key.\n            Fluorescence.Trace (foreign key): fluorescence.Trace primary key.\n            activity_trace (longblob): Inferred activity trace.\n        \"\"\"\n\n        definition = \"\"\"\n        -&gt; master\n        -&gt; Fluorescence.Trace\n        ---\n        activity_trace: longblob\n        \"\"\"\n\n    @property\n    def key_source(self):\n\"\"\"Defines the order of keys when the `make` function is called.\"\"\"\n        caiman_key_source = (\n            Fluorescence\n            * ActivityExtractionMethod\n            * ProcessingParamSet.proj(\"processing_method\")\n            &amp; 'processing_method = \"caiman\"'\n            &amp; 'extraction_method LIKE \"caiman%\"'\n        )\n\n        return caiman_key_source.proj()\n\n    def make(self, key):\n\"\"\"Populates table with activity trace data.\"\"\"\n        method, loaded_result = get_loader_result(key, Curation)\n\n        if method == \"caiman\":\n            loaded_caiman = loaded_result\n\n            if key[\"extraction_method\"] in (\"caiman_deconvolution\", \"caiman_dff\"):\n                attr_mapper = {\"caiman_deconvolution\": \"spikes\", \"caiman_dff\": \"dff\"}\n\n                # infer `segmentation_channel` from `params` if available,\n                # else from caiman loader\n                params = (ProcessingParamSet * ProcessingTask &amp; key).fetch1(\"params\")\n                segmentation_channel = params.get(\n                    \"segmentation_channel\", loaded_caiman.segmentation_channel\n                )\n\n                self.insert1(key)\n                self.Trace.insert(\n                    [\n                        {\n                            **key,\n                            \"mask\": mask.get(\"mask\", mask[\"mask_id\"]),\n                            \"fluorescence_channel\": segmentation_channel,\n                            \"activity_trace\": mask[\n                                attr_mapper[key[\"extraction_method\"]]\n                            ],\n                        }\n                        for mask in loaded_caiman.masks\n                    ]\n                )\n\n        else:\n            raise NotImplementedError(\"Unknown/unimplemented method: {}\".format(method))\n</code></pre>"}, {"location": "api/element_miniscope/miniscope/#element_miniscope.miniscope.Activity.Trace", "title": "<code>Trace</code>", "text": "<p>             Bases: <code>dj.Part</code></p> <p>Automated table with activity traces.</p> <p>Attributes:</p> Name Type Description <code>Activity</code> <code>foreign key</code> <p>Activity primary key.</p> <code>Fluorescence.Trace</code> <code>foreign key</code> <p>fluorescence.Trace primary key.</p> <code>activity_trace</code> <code>longblob</code> <p>Inferred activity trace.</p> Source code in <code>element_miniscope/miniscope.py</code> <pre><code>class Trace(dj.Part):\n\"\"\"Automated table with activity traces.\n\n    Attributes:\n        Activity (foreign key): Activity primary key.\n        Fluorescence.Trace (foreign key): fluorescence.Trace primary key.\n        activity_trace (longblob): Inferred activity trace.\n    \"\"\"\n\n    definition = \"\"\"\n    -&gt; master\n    -&gt; Fluorescence.Trace\n    ---\n    activity_trace: longblob\n    \"\"\"\n</code></pre>"}, {"location": "api/element_miniscope/miniscope/#element_miniscope.miniscope.Activity.key_source", "title": "<code>key_source</code>  <code>property</code>", "text": "<p>Defines the order of keys when the <code>make</code> function is called.</p>"}, {"location": "api/element_miniscope/miniscope/#element_miniscope.miniscope.Activity.make", "title": "<code>make(key)</code>", "text": "<p>Populates table with activity trace data.</p> Source code in <code>element_miniscope/miniscope.py</code> <pre><code>def make(self, key):\n\"\"\"Populates table with activity trace data.\"\"\"\n    method, loaded_result = get_loader_result(key, Curation)\n\n    if method == \"caiman\":\n        loaded_caiman = loaded_result\n\n        if key[\"extraction_method\"] in (\"caiman_deconvolution\", \"caiman_dff\"):\n            attr_mapper = {\"caiman_deconvolution\": \"spikes\", \"caiman_dff\": \"dff\"}\n\n            # infer `segmentation_channel` from `params` if available,\n            # else from caiman loader\n            params = (ProcessingParamSet * ProcessingTask &amp; key).fetch1(\"params\")\n            segmentation_channel = params.get(\n                \"segmentation_channel\", loaded_caiman.segmentation_channel\n            )\n\n            self.insert1(key)\n            self.Trace.insert(\n                [\n                    {\n                        **key,\n                        \"mask\": mask.get(\"mask\", mask[\"mask_id\"]),\n                        \"fluorescence_channel\": segmentation_channel,\n                        \"activity_trace\": mask[\n                            attr_mapper[key[\"extraction_method\"]]\n                        ],\n                    }\n                    for mask in loaded_caiman.masks\n                ]\n            )\n\n    else:\n        raise NotImplementedError(\"Unknown/unimplemented method: {}\".format(method))\n</code></pre>"}, {"location": "api/element_miniscope/miniscope/#element_miniscope.miniscope.ProcessingQualityMetrics", "title": "<code>ProcessingQualityMetrics</code>", "text": "<p>             Bases: <code>dj.Computed</code></p> <p>Quality metrics used to evaluate the results of the calcium imaging analysis pipeline.</p> <p>Attributes:</p> Name Type Description <code>Fluorescence</code> <code>foreign key</code> <p>Primary key from Fluorescence.</p> Source code in <code>element_miniscope/miniscope.py</code> <pre><code>@schema\nclass ProcessingQualityMetrics(dj.Computed):\n\"\"\"Quality metrics used to evaluate the results of the calcium imaging analysis pipeline.\n\n    Attributes:\n        Fluorescence (foreign key): Primary key from Fluorescence.\n    \"\"\"\n\n    definition = \"\"\"\n    -&gt; Fluorescence\n    \"\"\"\n\n    class Trace(dj.Part):\n\"\"\"Quality metrics used to evaluate the fluorescence traces.\n\n        Attributes:\n            Fluorescence (foreign key): Primary key from Fluorescence.\n            Fluorescence.Trace (foreign key): Primary key from Fluorescence.Trace.\n            skewness (float): Skewness of the fluorescence trace.\n            variance (float): Variance of the fluorescence trace.\n        \"\"\"\n\n        definition = \"\"\"\n        -&gt; master\n        -&gt; Fluorescence.Trace\n        ---\n        skewness: float   # Skewness of the fluorescence trace.\n        variance: float   # Variance of the fluorescence trace.\n        \"\"\"\n\n    def make(self, key):\n\"\"\"Populate the ProcessingQualityMetrics table and its part tables.\"\"\"\n        from scipy.stats import skew\n\n        (fluorescence, fluorescence_channels, mask_ids,) = (\n            Segmentation.Mask * RecordingInfo * Fluorescence.Trace &amp; key\n        ).fetch(\"fluorescence\", \"fluorescence_channel\", \"mask\")\n\n        fluorescence = np.stack(fluorescence)\n\n        self.insert1(key)\n\n        self.Trace.insert(\n            dict(\n                key,\n                fluorescence_channel=fluorescence_channel,\n                mask=mask_id,\n                skewness=skewness,\n                variance=variance,\n            )\n            for fluorescence_channel, mask_id, skewness, variance in zip(\n                fluorescence_channels,\n                mask_ids,\n                skew(fluorescence, axis=1),\n                fluorescence.std(axis=1),\n            )\n        )\n</code></pre>"}, {"location": "api/element_miniscope/miniscope/#element_miniscope.miniscope.ProcessingQualityMetrics.Trace", "title": "<code>Trace</code>", "text": "<p>             Bases: <code>dj.Part</code></p> <p>Quality metrics used to evaluate the fluorescence traces.</p> <p>Attributes:</p> Name Type Description <code>Fluorescence</code> <code>foreign key</code> <p>Primary key from Fluorescence.</p> <code>Fluorescence.Trace</code> <code>foreign key</code> <p>Primary key from Fluorescence.Trace.</p> <code>skewness</code> <code>float</code> <p>Skewness of the fluorescence trace.</p> <code>variance</code> <code>float</code> <p>Variance of the fluorescence trace.</p> Source code in <code>element_miniscope/miniscope.py</code> <pre><code>class Trace(dj.Part):\n\"\"\"Quality metrics used to evaluate the fluorescence traces.\n\n    Attributes:\n        Fluorescence (foreign key): Primary key from Fluorescence.\n        Fluorescence.Trace (foreign key): Primary key from Fluorescence.Trace.\n        skewness (float): Skewness of the fluorescence trace.\n        variance (float): Variance of the fluorescence trace.\n    \"\"\"\n\n    definition = \"\"\"\n    -&gt; master\n    -&gt; Fluorescence.Trace\n    ---\n    skewness: float   # Skewness of the fluorescence trace.\n    variance: float   # Variance of the fluorescence trace.\n    \"\"\"\n</code></pre>"}, {"location": "api/element_miniscope/miniscope/#element_miniscope.miniscope.ProcessingQualityMetrics.make", "title": "<code>make(key)</code>", "text": "<p>Populate the ProcessingQualityMetrics table and its part tables.</p> Source code in <code>element_miniscope/miniscope.py</code> <pre><code>def make(self, key):\n\"\"\"Populate the ProcessingQualityMetrics table and its part tables.\"\"\"\n    from scipy.stats import skew\n\n    (fluorescence, fluorescence_channels, mask_ids,) = (\n        Segmentation.Mask * RecordingInfo * Fluorescence.Trace &amp; key\n    ).fetch(\"fluorescence\", \"fluorescence_channel\", \"mask\")\n\n    fluorescence = np.stack(fluorescence)\n\n    self.insert1(key)\n\n    self.Trace.insert(\n        dict(\n            key,\n            fluorescence_channel=fluorescence_channel,\n            mask=mask_id,\n            skewness=skewness,\n            variance=variance,\n        )\n        for fluorescence_channel, mask_id, skewness, variance in zip(\n            fluorescence_channels,\n            mask_ids,\n            skew(fluorescence, axis=1),\n            fluorescence.std(axis=1),\n        )\n    )\n</code></pre>"}, {"location": "api/element_miniscope/miniscope/#element_miniscope.miniscope.get_loader_result", "title": "<code>get_loader_result(key, table)</code>", "text": "<p>Retrieve the loaded processed imaging results from the loader (e.g. caiman, etc.)</p> <p>Parameters:</p> Name Type Description Default <code>key</code> <code>dict</code> <p>the <code>key</code> to one entry of ProcessingTask or Curation.</p> required <code>table</code> <code>str</code> <p>the class defining the table to retrieve the loaded results from (e.g. ProcessingTask, Curation).</p> required <p>Returns:</p> Type Description <code>tuple</code> <p>method, loaded_output (tuple): method string and loader object with results (e.g. caiman.CaImAn, etc.)</p> Source code in <code>element_miniscope/miniscope.py</code> <pre><code>def get_loader_result(key, table) -&gt; tuple:\n\"\"\"Retrieve the loaded processed imaging results from the loader (e.g. caiman, etc.)\n\n    Args:\n        key (dict): the `key` to one entry of ProcessingTask or Curation.\n        table (str): the class defining the table to retrieve\n            the loaded results from (e.g. ProcessingTask, Curation).\n\n    Returns:\n        method, loaded_output (tuple): method string and loader object with results (e.g. caiman.CaImAn, etc.)\n    \"\"\"\n\n    method, output_dir = (ProcessingParamSet * table &amp; key).fetch1(\n        \"processing_method\", _table_attribute_mapper[table.__name__]\n    )\n\n    output_dir = find_full_path(get_miniscope_root_data_dir(), output_dir)\n\n    if method == \"caiman\":\n        from element_interface import caiman_loader\n\n        loaded_output = caiman_loader.CaImAn(output_dir)\n    else:\n        raise NotImplementedError(\"Unknown/unimplemented method: {}\".format(method))\n\n    return method, loaded_output\n</code></pre>"}, {"location": "api/element_miniscope/miniscope_report/", "title": "miniscope_report.py", "text": ""}, {"location": "api/element_miniscope/miniscope_report/#element_miniscope.miniscope_report.activate", "title": "<code>activate(schema_name, miniscope_schema_name, *, create_schema=True, create_tables=True)</code>", "text": "<p>Activate this schema.</p> <p>The \"activation\" of miniscope_report should be evoked by the miniscope module</p> <p>Parameters:</p> Name Type Description Default <code>schema_name</code> <code>str</code> <p>schema name on the database server to activate the <code>miniscope_report</code> schema</p> required <code>miniscope_schema_name</code> <code>str</code> <p>schema name of the activated miniscope element for which this miniscope_report schema will be downstream from</p> required <code>create_schema</code> <code>bool</code> <p>when True (default), create schema in the database if it does not yet exist.</p> <code>True</code> <code>create_tables</code> <code>str</code> <p>when True (default), create schema takes in the database if they do not yet exist.</p> <code>True</code> Source code in <code>element_miniscope/miniscope_report.py</code> <pre><code>def activate(\n    schema_name, miniscope_schema_name, *, create_schema=True, create_tables=True\n):\n\"\"\"Activate this schema.\n\n    The \"activation\" of miniscope_report should be evoked by the miniscope module\n\n    Args:\n        schema_name (str): schema name on the database server to activate the\n            `miniscope_report` schema\n        miniscope_schema_name (str): schema name of the activated miniscope element for\n            which this miniscope_report schema will be downstream from\n        create_schema (bool): when True (default), create schema in the database if it\n            does not yet exist.\n        create_tables (str): when True (default), create schema takes in the database\n            if they do not yet exist.\n    \"\"\"\n    global miniscope\n    miniscope = dj.create_virtual_module(\"miniscope\", miniscope_schema_name)\n    schema.activate(\n        schema_name,\n        create_schema=create_schema,\n        create_tables=create_tables,\n        add_objects=miniscope.__dict__,\n    )\n</code></pre>"}, {"location": "api/element_miniscope/qc/", "title": "qc.py", "text": ""}, {"location": "api/element_miniscope/qc/#element_miniscope.qc.QualityMetricFigs", "title": "<code>QualityMetricFigs</code>", "text": "<p>             Bases: <code>object</code></p> Source code in <code>element_miniscope/qc.py</code> <pre><code>class QualityMetricFigs(object):\n    def __init__(\n        self,\n        mini: types.ModuleType,\n        key: dict = None,\n        scale: float = 1,\n        fig_width: int = 800,\n        dark_mode: bool = False,\n    ):\n\"\"\"Initialize QC metric class\n\n        Args:\n            mini (module): datajoint module with a QualityMetric table\n            key (dict, optional): key from mini.QualityMetric table. Defaults to None.\n            scale (float, optional): Scale at which to render figure. Defaults to 1.4.\n            fig_width (int, optional): Figure width in pixels. Defaults to 800.\n            dark_mode (bool, optional): Set background to black, foreground white.\n                Default False, black on white.\n        \"\"\"\n        self._mini = mini\n        self._key = (self._mini.Curation &amp; key).fetch1(\"KEY\")\n        self._scale = scale\n        self._plots = {}  # Empty default to defer set to dict property below\n        self._fig_width = fig_width\n        self._dark_mode = dark_mode\n        self._estimates = None\n        self._component_list = []\n        self._components = pd.DataFrame()  # Empty default\n        self._x_fmt = dict(showgrid=False, zeroline=False, linewidth=2, ticks=\"outside\")\n        self._y_fmt = dict(showgrid=False, linewidth=0, zeroline=True, visible=False)\n        self._no_data_text = \"No data available\"  # What to show when no data in table\n        self._null_series = pd.Series(np.nan)  # What to substitute when no data\n\n    @property\n    def key(self) -&gt; dict:\n\"\"\"Key in mini.Curation table\"\"\"\n        return self._key\n\n    @key.setter  # Allows `cls.property = new_item` notation\n    def key(self, key: dict):\n\"\"\"Use class_instance.key = your_key to reset key\"\"\"\n        if key not in self._mini.Curation.fetch(\"KEY\"):\n            # If not already full key, check if uniquely identifies entry\n            key = (self._mini.Curation &amp; key).fetch1(\"KEY\")\n            self._estimates = None  # Refresh estimates\n        self._key = key\n\n    @key.deleter  # Allows `del cls.property` to clear key\n    def key(self):\n\"\"\"Use del class_instance.key to clear key\"\"\"\n        logger.info(\"Cleared key\")\n        self._key = None\n\n    @property\n    def estimates(self) -&gt; Estimates:\n        if not self._estimates:\n            method, loaded_result = get_loader_result(self._key, self._mini.Curation)\n            assert (\n                method == \"caiman\"\n            ), f\"Quality figures for {method} not yet implemented. Try CaImAn.\"\n\n            self._estimates = loaded_result.cnmf.estimates\n        return self._estimates\n\n    @property\n    def component_list(self) -&gt; list:\n        if not self._component_list:\n            self._component_list = [\"r_values\", \"SNR_comp\", \"cnn_preds\"]\n        return self._component_list\n\n    @component_list.setter\n    def component_list(self, component_list: list):\n        self._component_list = component_list\n        self._components = pd.DataFrame()  # Reset components\n\n    @property\n    def components(self) -&gt; pd.DataFrame:\n\"\"\"Pandas dataframe of QC metrics\"\"\"\n        if not self._key:\n            return self._null_series\n\n        if self._components.empty:\n            empty_array = np.zeros((self.estimates.C.shape[0],))\n\n            self._components = pd.DataFrame(\n                data=[\n                    getattr(self.estimates, attrib, empty_array).astype(np.float64)\n                    for attrib in self.component_list\n                ],\n                index=self.component_list,\n            ).T\n\n        return self._components\n\n    def _format_fig(\n        self, fig: go.Figure = None, scale: float = None, ratio: float = 1.0\n    ) -&gt; go.Figure:\n\"\"\"Return formatted figure or apply formatting to existing figure\n\n        Args:\n            fig (go.Figure, optional): Apply formatting to this plotly graph object\n                Figure to apply formatting. Defaults to empty.\n            scale (float, optional): Scale to render figure. Defaults to scale from\n                class init, 1.\n            ratio (float, optional): Figure aspect ratio width/height . Defaults to 1.\n\n        Returns:\n            go.Figure: Formatted figure\n        \"\"\"\n        if not fig:\n            fig = go.Figure()\n        if not scale:\n            scale = self._scale\n\n        width = self._fig_width * scale\n\n        return fig.update_layout(\n            template=\"plotly_dark\" if self._dark_mode else \"simple_white\",\n            width=width,\n            height=width / ratio,\n            margin=dict(l=20 * scale, r=20 * scale, t=40 * scale, b=40 * scale),\n            showlegend=False,\n        )\n\n    def _empty_fig(\n        self, text=\"Select a key to visualize QC metrics\", scale=None\n    ) -&gt; go.Figure:\n\"\"\"Return figure object for when no key is provided\"\"\"\n        if not scale:\n            scale = self._scale\n\n        return (\n            self._format_fig(scale=scale)\n            .add_annotation(text=text, showarrow=False)\n            .update_layout(xaxis=self._y_fmt, yaxis=self._y_fmt)\n        )\n\n    def _plot_metric(\n        self,\n        data: pd.DataFrame,\n        bins: np.ndarray,\n        scale: float = None,\n        fig: go.Figure = None,\n        **trace_kwargs,\n    ) -&gt; go.Figure:\n\"\"\"Plot histogram using bins provided\n\n        Args:\n            data (pd.DataFrame): Data to be plotted, from QC metric\n            bins (np.ndarray): Array of bins to use for histogram\n            scale (float, optional): Scale to render figure. Defaults to scale from\n                class initialization.\n            fig (go.Figure, optional): Add trace to this figure. Defaults to empty\n                formatted figure.\n\n        Returns:\n            go.Figure: Histogram plot\n        \"\"\"\n        if not scale:\n            scale = self._scale\n        if not fig:\n            fig = self._format_fig(scale=scale)\n\n        if not data.isnull().all():\n            histogram, histogram_bins = np.histogram(data, bins=bins, density=True)\n        else:\n            # To quiet divide by zero error when no data\n            histogram, histogram_bins = np.ndarray(0), np.ndarray(0)\n\n        return fig.add_trace(\n            go.Scatter(\n                x=histogram_bins[:-1],\n                y=gaussian_filter1d(histogram, 1),  # TODO: remove smoothing\n                mode=\"lines\",\n                line=dict(color=\"rgb(0, 160, 223)\", width=2 * scale),  # DataJoint Blue\n                hovertemplate=\"%{x:.2f}&lt;br&gt;%{y:.2f}&lt;extra&gt;&lt;/extra&gt;\",\n            ),\n            **trace_kwargs,\n        )\n\n    def get_single_fig(self, fig_name: str, scale: float = None) -&gt; go.Figure:\n\"\"\"Return a single figure of the plots listed in the plot_list property\n\n        Args:\n            fig_name (str): Name of figure to be rendered\n            scale (float, optional): Scale to render fig. Defaults to scale at class\n                init, 1.\n\n        Returns:\n            go.Figure: Histogram plot\n        \"\"\"\n        if not self._key:\n            return self._empty_fig()\n        if not scale:\n            scale = self._scale\n\n        fig_dict = self.plots.get(fig_name, dict()) if self._key else dict()\n        data = fig_dict.get(\"data\", self._null_series)\n        bins = fig_dict.get(\"bins\", np.linspace(0, 0, 0))\n        vline = fig_dict.get(\"vline\", None)\n\n        if data.isnull().all():\n            return self._empty_fig(text=self._no_data_text)\n\n        fig = (\n            self._plot_metric(data=data, bins=bins, scale=scale)\n            .update_layout(xaxis=self._x_fmt, yaxis=self._y_fmt)\n            .update_layout(  # Add title\n                title=dict(text=fig_dict.get(\"xaxis\", \" \"), xanchor=\"center\", x=0.5),\n                font=dict(size=12 * scale),\n            )\n        )\n\n        if vline:\n            fig.add_vline(x=vline, line_width=2 * scale, line_dash=\"dash\")\n\n        return fig\n\n    def get_grid(self, n_columns: int = 3, scale: float = 1.0) -&gt; go.Figure:\n\"\"\"Plot grid of histograms as subplots in go.Figure using n_columns\n\n        Args:\n            n_columns (int, optional): Number of columns in grid. Defaults to 4.\n            scale (float, optional): Scale to render fig. Defaults to scale at class\n                init, 1.\n\n        Returns:\n            go.Figure: grid of available plots\n        \"\"\"\n        from plotly.subplots import make_subplots\n\n        if not self._key:\n            return self._empty_fig()\n        if not scale:\n            scale = self._scale\n\n        n_rows = int(np.ceil(len(self.plots) / n_columns))\n\n        fig = self._format_fig(\n            fig=make_subplots(\n                rows=n_rows,\n                cols=n_columns,\n                shared_xaxes=False,\n                shared_yaxes=False,\n                vertical_spacing=(0.5 / n_rows),\n            ),\n            scale=scale,\n            ratio=(n_columns / n_rows),\n        ).update_layout(  # Global title\n            title=dict(text=\"Histograms of Quality Metrics\", xanchor=\"center\", x=0.5),\n            font=dict(size=12 * scale),\n        )\n\n        for idx, plot in enumerate(self._plots.values()):  # Each subplot\n            this_row = int(np.floor(idx / n_columns) + 1)\n            this_col = idx % n_columns + 1\n            data = plot.get(\"data\", self._null_series)\n            vline = plot.get(\"vline\", None)\n            if data.isnull().all():\n                vline = None  # If no data, don't want vline either\n                fig[\"layout\"].update(\n                    annotations=[\n                        dict(\n                            xref=f\"x{idx+1}\",\n                            yref=f\"y{idx+1}\",\n                            text=self._no_data_text,\n                            showarrow=False,\n                        ),\n                    ]\n                )\n            fig = self._plot_metric(  # still need to plot empty to cal y_vals min/max\n                data=data,\n                bins=plot[\"bins\"],\n                fig=fig,\n                row=this_row,\n                col=this_col,\n                scale=scale,\n            )\n            fig.update_xaxes(\n                title=dict(text=plot[\"xaxis\"], font_size=11 * scale),\n                row=this_row,\n                col=this_col,\n            )\n            if vline:\n                y_vals = fig.to_dict()[\"data\"][idx][\"y\"]\n                fig.add_shape(  # Add overlay WRT whole fig\n                    go.layout.Shape(\n                        type=\"line\",\n                        yref=\"paper\",\n                        xref=\"x\",  # relative to subplot x\n                        x0=vline,\n                        y0=min(y_vals),\n                        x1=vline,\n                        y1=max(y_vals),\n                        line=dict(width=2 * scale),\n                    ),\n                    row=this_row,\n                    col=this_col,\n                )\n\n        return fig.update_xaxes(**self._x_fmt).update_yaxes(**self._y_fmt)\n\n    @property\n    def plot_list(self):\n\"\"\"List of plots that can be rendered individually by name or as grid\"\"\"\n        if not self._plots:\n            _ = self.plots\n        return [plot for plot in self._plots]\n\n    def _default_bins(self, component: pd.Series, nbins: int = 10) -&gt; np.ndarray:\n\"\"\"Default bins for rendered histograms\n\n        Args:\n            component (pd.Series): Pandas series of which we'll use min and max\n            nbins (int, optional): Number of bins to use. Defaults to 10.\n\n        Returns:\n            numpy.ndarray: numpy linspace(min(component), max(component), nbins)\n        \"\"\"\n        values = self.components.get(component, self._null_series).replace(\n            [np.inf, -np.inf], np.nan\n        )\n        return np.linspace(min(values), max(values), nbins)\n\n    @property\n    def plots(self) -&gt; dict:\n\"\"\"Set of plots available to be rendered\"\"\"\n        if not self._plots:\n            self._plots = {\n                \"r_values\": {\n                    \"xaxis\": \"R Values\",\n                    \"data\": self.components.get(\"r_values\", self._null_series),\n                    \"bins\": self._default_bins(\"r_values\"),\n                    \"vline\": 0.85,\n                },\n                \"SNR\": {\n                    \"xaxis\": \"SNR\",\n                    \"data\": self.components.get(\"SNR_comp\", self._null_series),\n                    \"bins\": self._default_bins(\"SNR_comp\"),\n                    \"vline\": 2,\n                },\n                \"cnn_preds\": {\n                    \"xaxis\": \"CNN Preds\",\n                    \"data\": self.components.get(\"cnn_preds\", self._null_series),\n                    \"bins\": self._default_bins(\"cnn_preds\"),\n                    \"vline\": 0.1,\n                },\n            }\n        return self._plots\n\n    @plots.setter\n    def plots(self, new_plot_dict: dict):\n\"\"\"Adds or updates plot item in the set to be rendered.\n\n        plot items are structured as followed: dict with name key, embedded dict with\n            xaxis: string x-axis label\n            data: pandas dataframe to be plotted\n            bins: numpy ndarray of bin cutoffs for histogram\n        \"\"\"\n        _ = self.plots\n        [self._plots.update({k: v}) for k, v in new_plot_dict.items()]\n\n    def remove_plot(self, plot_name):\n\"\"\"Removes an item from the set of plots\"\"\"\n        _ = self._plots.pop(plot_name)\n</code></pre>"}, {"location": "api/element_miniscope/qc/#element_miniscope.qc.QualityMetricFigs.__init__", "title": "<code>__init__(mini, key=None, scale=1, fig_width=800, dark_mode=False)</code>", "text": "<p>Initialize QC metric class</p> <p>Parameters:</p> Name Type Description Default <code>mini</code> <code>module</code> <p>datajoint module with a QualityMetric table</p> required <code>key</code> <code>dict</code> <p>key from mini.QualityMetric table. Defaults to None.</p> <code>None</code> <code>scale</code> <code>float</code> <p>Scale at which to render figure. Defaults to 1.4.</p> <code>1</code> <code>fig_width</code> <code>int</code> <p>Figure width in pixels. Defaults to 800.</p> <code>800</code> <code>dark_mode</code> <code>bool</code> <p>Set background to black, foreground white. Default False, black on white.</p> <code>False</code> Source code in <code>element_miniscope/qc.py</code> <pre><code>def __init__(\n    self,\n    mini: types.ModuleType,\n    key: dict = None,\n    scale: float = 1,\n    fig_width: int = 800,\n    dark_mode: bool = False,\n):\n\"\"\"Initialize QC metric class\n\n    Args:\n        mini (module): datajoint module with a QualityMetric table\n        key (dict, optional): key from mini.QualityMetric table. Defaults to None.\n        scale (float, optional): Scale at which to render figure. Defaults to 1.4.\n        fig_width (int, optional): Figure width in pixels. Defaults to 800.\n        dark_mode (bool, optional): Set background to black, foreground white.\n            Default False, black on white.\n    \"\"\"\n    self._mini = mini\n    self._key = (self._mini.Curation &amp; key).fetch1(\"KEY\")\n    self._scale = scale\n    self._plots = {}  # Empty default to defer set to dict property below\n    self._fig_width = fig_width\n    self._dark_mode = dark_mode\n    self._estimates = None\n    self._component_list = []\n    self._components = pd.DataFrame()  # Empty default\n    self._x_fmt = dict(showgrid=False, zeroline=False, linewidth=2, ticks=\"outside\")\n    self._y_fmt = dict(showgrid=False, linewidth=0, zeroline=True, visible=False)\n    self._no_data_text = \"No data available\"  # What to show when no data in table\n    self._null_series = pd.Series(np.nan)  # What to substitute when no data\n</code></pre>"}, {"location": "api/element_miniscope/qc/#element_miniscope.qc.QualityMetricFigs.key", "title": "<code>key: dict</code>  <code>deletable</code> <code>property</code> <code>writable</code>", "text": "<p>Key in mini.Curation table</p>"}, {"location": "api/element_miniscope/qc/#element_miniscope.qc.QualityMetricFigs.components", "title": "<code>components: pd.DataFrame</code>  <code>property</code>", "text": "<p>Pandas dataframe of QC metrics</p>"}, {"location": "api/element_miniscope/qc/#element_miniscope.qc.QualityMetricFigs.get_single_fig", "title": "<code>get_single_fig(fig_name, scale=None)</code>", "text": "<p>Return a single figure of the plots listed in the plot_list property</p> <p>Parameters:</p> Name Type Description Default <code>fig_name</code> <code>str</code> <p>Name of figure to be rendered</p> required <code>scale</code> <code>float</code> <p>Scale to render fig. Defaults to scale at class init, 1.</p> <code>None</code> <p>Returns:</p> Type Description <code>go.Figure</code> <p>go.Figure: Histogram plot</p> Source code in <code>element_miniscope/qc.py</code> <pre><code>def get_single_fig(self, fig_name: str, scale: float = None) -&gt; go.Figure:\n\"\"\"Return a single figure of the plots listed in the plot_list property\n\n    Args:\n        fig_name (str): Name of figure to be rendered\n        scale (float, optional): Scale to render fig. Defaults to scale at class\n            init, 1.\n\n    Returns:\n        go.Figure: Histogram plot\n    \"\"\"\n    if not self._key:\n        return self._empty_fig()\n    if not scale:\n        scale = self._scale\n\n    fig_dict = self.plots.get(fig_name, dict()) if self._key else dict()\n    data = fig_dict.get(\"data\", self._null_series)\n    bins = fig_dict.get(\"bins\", np.linspace(0, 0, 0))\n    vline = fig_dict.get(\"vline\", None)\n\n    if data.isnull().all():\n        return self._empty_fig(text=self._no_data_text)\n\n    fig = (\n        self._plot_metric(data=data, bins=bins, scale=scale)\n        .update_layout(xaxis=self._x_fmt, yaxis=self._y_fmt)\n        .update_layout(  # Add title\n            title=dict(text=fig_dict.get(\"xaxis\", \" \"), xanchor=\"center\", x=0.5),\n            font=dict(size=12 * scale),\n        )\n    )\n\n    if vline:\n        fig.add_vline(x=vline, line_width=2 * scale, line_dash=\"dash\")\n\n    return fig\n</code></pre>"}, {"location": "api/element_miniscope/qc/#element_miniscope.qc.QualityMetricFigs.get_grid", "title": "<code>get_grid(n_columns=3, scale=1.0)</code>", "text": "<p>Plot grid of histograms as subplots in go.Figure using n_columns</p> <p>Parameters:</p> Name Type Description Default <code>n_columns</code> <code>int</code> <p>Number of columns in grid. Defaults to 4.</p> <code>3</code> <code>scale</code> <code>float</code> <p>Scale to render fig. Defaults to scale at class init, 1.</p> <code>1.0</code> <p>Returns:</p> Type Description <code>go.Figure</code> <p>go.Figure: grid of available plots</p> Source code in <code>element_miniscope/qc.py</code> <pre><code>def get_grid(self, n_columns: int = 3, scale: float = 1.0) -&gt; go.Figure:\n\"\"\"Plot grid of histograms as subplots in go.Figure using n_columns\n\n    Args:\n        n_columns (int, optional): Number of columns in grid. Defaults to 4.\n        scale (float, optional): Scale to render fig. Defaults to scale at class\n            init, 1.\n\n    Returns:\n        go.Figure: grid of available plots\n    \"\"\"\n    from plotly.subplots import make_subplots\n\n    if not self._key:\n        return self._empty_fig()\n    if not scale:\n        scale = self._scale\n\n    n_rows = int(np.ceil(len(self.plots) / n_columns))\n\n    fig = self._format_fig(\n        fig=make_subplots(\n            rows=n_rows,\n            cols=n_columns,\n            shared_xaxes=False,\n            shared_yaxes=False,\n            vertical_spacing=(0.5 / n_rows),\n        ),\n        scale=scale,\n        ratio=(n_columns / n_rows),\n    ).update_layout(  # Global title\n        title=dict(text=\"Histograms of Quality Metrics\", xanchor=\"center\", x=0.5),\n        font=dict(size=12 * scale),\n    )\n\n    for idx, plot in enumerate(self._plots.values()):  # Each subplot\n        this_row = int(np.floor(idx / n_columns) + 1)\n        this_col = idx % n_columns + 1\n        data = plot.get(\"data\", self._null_series)\n        vline = plot.get(\"vline\", None)\n        if data.isnull().all():\n            vline = None  # If no data, don't want vline either\n            fig[\"layout\"].update(\n                annotations=[\n                    dict(\n                        xref=f\"x{idx+1}\",\n                        yref=f\"y{idx+1}\",\n                        text=self._no_data_text,\n                        showarrow=False,\n                    ),\n                ]\n            )\n        fig = self._plot_metric(  # still need to plot empty to cal y_vals min/max\n            data=data,\n            bins=plot[\"bins\"],\n            fig=fig,\n            row=this_row,\n            col=this_col,\n            scale=scale,\n        )\n        fig.update_xaxes(\n            title=dict(text=plot[\"xaxis\"], font_size=11 * scale),\n            row=this_row,\n            col=this_col,\n        )\n        if vline:\n            y_vals = fig.to_dict()[\"data\"][idx][\"y\"]\n            fig.add_shape(  # Add overlay WRT whole fig\n                go.layout.Shape(\n                    type=\"line\",\n                    yref=\"paper\",\n                    xref=\"x\",  # relative to subplot x\n                    x0=vline,\n                    y0=min(y_vals),\n                    x1=vline,\n                    y1=max(y_vals),\n                    line=dict(width=2 * scale),\n                ),\n                row=this_row,\n                col=this_col,\n            )\n\n    return fig.update_xaxes(**self._x_fmt).update_yaxes(**self._y_fmt)\n</code></pre>"}, {"location": "api/element_miniscope/qc/#element_miniscope.qc.QualityMetricFigs.plot_list", "title": "<code>plot_list</code>  <code>property</code>", "text": "<p>List of plots that can be rendered individually by name or as grid</p>"}, {"location": "api/element_miniscope/qc/#element_miniscope.qc.QualityMetricFigs.plots", "title": "<code>plots: dict</code>  <code>property</code> <code>writable</code>", "text": "<p>Set of plots available to be rendered</p>"}, {"location": "api/element_miniscope/qc/#element_miniscope.qc.QualityMetricFigs.remove_plot", "title": "<code>remove_plot(plot_name)</code>", "text": "<p>Removes an item from the set of plots</p> Source code in <code>element_miniscope/qc.py</code> <pre><code>def remove_plot(self, plot_name):\n\"\"\"Removes an item from the set of plots\"\"\"\n    _ = self._plots.pop(plot_name)\n</code></pre>"}, {"location": "api/workflow_miniscope/analysis/", "title": "analysis.py", "text": ""}, {"location": "api/workflow_miniscope/analysis/#workflow_miniscope.analysis.ActivityAlignmentCondition", "title": "<code>ActivityAlignmentCondition</code>", "text": "<p>             Bases: <code>dj.Manual</code></p> <p>Alignment activity table</p> <p>Attributes:</p> Name Type Description <code>miniscope.Activity</code> <code>foreign key</code> <p>Activity primary key</p> <code>event.AlignmentEvent</code> <code>foreign key</code> <p>Alignment Event primary key</p> <code>trial_condition</code> <code>foreign key</code> <p>varchar(128) # user-friendly name of condition</p> <code>condition_description</code> <code> varchar(1000), nullable</code> <p>condition description</p> <code>bin_size</code> <code>float</code> <p>Bin-size (in second) used to compute the PSTH Default 0.04</p> Source code in <code>workflow_miniscope/analysis.py</code> <pre><code>@schema\nclass ActivityAlignmentCondition(dj.Manual):\n\"\"\"Alignment activity table\n\n    Attributes:\n        miniscope.Activity (foreign key): Activity primary key\n        event.AlignmentEvent (foreign key): Alignment Event primary key\n        trial_condition: varchar(128) # user-friendly name of condition\n        condition_description ( varchar(1000), nullable): condition description\n        bin_size (float, optional): Bin-size (in second) used to compute the PSTH\n            Default 0.04\n    \"\"\"\n\n    definition = \"\"\"\n    -&gt; miniscope.Activity\n    -&gt; event.AlignmentEvent\n    trial_condition: varchar(128) # user-friendly name of condition\n    ---\n    condition_description='': varchar(1000)\n    bin_size=0.04: float # bin-size (in second) used to compute the PSTH\n    \"\"\"\n\n    class Trial(dj.Part):\n        definition = \"\"\"  # Trials (or subset) to compute event-aligned activity\n        -&gt; master\n        -&gt; trial.Trial\n        \"\"\"\n</code></pre>"}, {"location": "api/workflow_miniscope/analysis/#workflow_miniscope.analysis.ActivityAlignment", "title": "<code>ActivityAlignment</code>", "text": "<p>             Bases: <code>dj.Computed</code></p> <p>Computed table for alignment activity</p> <p>Attributes:</p> Name Type Description <code>ActivityAlignmentCondition</code> <code>foreign key</code> <p>Activity Alignment Condition key</p> <code>aligned_timestamps</code> <code>longblob</code> <p>aligned timestamps</p> Source code in <code>workflow_miniscope/analysis.py</code> <pre><code>@schema\nclass ActivityAlignment(dj.Computed):\n\"\"\"Computed table for alignment activity\n\n    Attributes:\n        ActivityAlignmentCondition (foreign key): Activity Alignment Condition key\n        aligned_timestamps (longblob): aligned timestamps\n    \"\"\"\n\n    definition = \"\"\"\n    -&gt; ActivityAlignmentCondition\n    ---\n    aligned_timestamps: longblob\n    \"\"\"\n\n    class AlignedTrialActivity(dj.Part):\n\"\"\"Calcium activity aligned to the event time within the designated window\n\n        Attributes:\n            miniscope.Activity.Trace (foreign key): Activity trace primary key\n            ActivityAlignmentCondition.Trial (foreign key): Alignment condition key\n            aligned_trace (longblob): (s) Calcium activity aligned to the event time\n        \"\"\"\n\n        definition = \"\"\"\n        -&gt; master\n        -&gt; miniscope.Activity.Trace\n        -&gt; ActivityAlignmentCondition.Trial\n        ---\n        aligned_trace: longblob  # (s) Calcium activity aligned to the event time\n        \"\"\"\n\n    def make(self, key):\n\"\"\"Populate ActivityAlignment and AlignedTrialActivity\n\n        Args:\n            key (dict): Dict uniquely identifying one ActivityAlignmentCondition\n        \"\"\"\n        session_time, rec_time, nframes, frame_rate = (\n            miniscope.RecordingInfo * session.Session &amp; key\n        ).fetch1(\"session_datetime\", \"recording_datetime\", \"nframes\", \"fps\")\n\n        # Estimation of frame timestamps with respect to the session-start\n        # (to be replaced by timestamps retrieved from some synchronization routine)\n        # rec_start = (rec_time - session_time).total_seconds() if rec_time else 0\n        # frame_timestamps = np.arange(nframes) / frame_rate + rec_start\n\n        trialized_event_times = trial.get_trialized_alignment_event_times(\n            key, trial.Trial &amp; (ActivityAlignmentCondition.Trial &amp; key)\n        )\n\n        min_limit = (trialized_event_times.event - trialized_event_times.start).max()\n        max_limit = (trialized_event_times.end - trialized_event_times.event).max()\n\n        aligned_timestamps = np.arange(-min_limit, max_limit, 1 / frame_rate)\n        nsamples = len(aligned_timestamps)\n\n        trace_keys, activity_traces = (miniscope.Activity.Trace &amp; key).fetch(\n            \"KEY\", \"activity_trace\", order_by=\"mask_id\"\n        )\n        activity_traces = np.vstack(activity_traces)\n\n        aligned_trial_activities = []\n        for _, r in trialized_event_times.iterrows():\n            if r.event is None or np.isnan(r.event):\n                continue\n            alignment_start_idx = int((r.event - min_limit) * frame_rate)\n            roi_aligned_activities = activity_traces[\n                :, alignment_start_idx : (alignment_start_idx + nsamples)\n            ]\n            if roi_aligned_activities.shape[-1] != nsamples:\n                shape_diff = nsamples - roi_aligned_activities.shape[-1]\n                roi_aligned_activities = np.pad(\n                    roi_aligned_activities,\n                    ((0, 0), (0, shape_diff)),\n                    mode=\"constant\",\n                    constant_values=np.nan,\n                )\n\n            aligned_trial_activities.extend(\n                [\n                    {**key, **r.trial_key, **trace_key, \"aligned_trace\": aligned_trace}\n                    for trace_key, aligned_trace in zip(\n                        trace_keys, roi_aligned_activities\n                    )\n                ]\n            )\n\n        self.insert1({**key, \"aligned_timestamps\": aligned_timestamps})\n        self.AlignedTrialActivity.insert(aligned_trial_activities)\n\n    def plot_aligned_activities(\n        self, key: dict, roi, axs: tuple = None, title: str = None\n    ) -&gt; plt.figure.Figure:\n\"\"\"Plot event-aligned and trial-averaged calcium activities\n\n        Activities including: dF/F, neuropil-corrected dF/F, Calcium events, etc.\n\n        Args:\n            key (dict): key of ActivityAlignment master table\n            roi (int): miniscope segmentation mask\n            axs (tuple, optional): Definition of axes for plot.\n                Default is plt.subplots(2, 1, figsize=(12, 8))\n            title (str, optional): Optional title label. Defaults to None.\n\n        Returns:\n            fig (matplotlib.figure.Figure): Plot event-aligned and trial-averaged\n                calcium activities\n        \"\"\"\n\n        fig = None\n        if axs is None:\n            fig, (ax0, ax1) = plt.subplots(2, 1, figsize=(12, 8))\n        else:\n            ax0, ax1 = axs\n\n        aligned_timestamps = (self &amp; key).fetch1(\"aligned_timestamps\")\n        _, aligned_spikes = (self.AlignedTrialActivity &amp; key &amp; {\"mask_id\": roi}).fetch(\n            \"trial_id\", \"aligned_trace\", order_by=\"trial_id\"\n        )\n\n        aligned_spikes = np.vstack(aligned_spikes)\n\n        ax0.imshow(\n            aligned_spikes,\n            cmap=\"inferno\",\n            interpolation=\"nearest\",\n            aspect=\"auto\",\n            extent=(\n                aligned_timestamps[0],\n                aligned_timestamps[-1],\n                0,\n                aligned_spikes.shape[0],\n            ),\n        )\n        ax0.axvline(x=0, linestyle=\"--\", color=\"white\")\n        ax0.set_axis_off()\n\n        ax1.plot(aligned_timestamps, np.nanmean(aligned_spikes, axis=0))\n        ax1.axvline(x=0, linestyle=\"--\", color=\"black\")\n        ax1.set_xlabel(\"Time (s)\")\n        ax1.set_xlim(aligned_timestamps[0], aligned_timestamps[-1])\n\n        if title:\n            plt.suptitle(title)\n\n        return fig\n</code></pre>"}, {"location": "api/workflow_miniscope/analysis/#workflow_miniscope.analysis.ActivityAlignment.AlignedTrialActivity", "title": "<code>AlignedTrialActivity</code>", "text": "<p>             Bases: <code>dj.Part</code></p> <p>Calcium activity aligned to the event time within the designated window</p> <p>Attributes:</p> Name Type Description <code>miniscope.Activity.Trace</code> <code>foreign key</code> <p>Activity trace primary key</p> <code>ActivityAlignmentCondition.Trial</code> <code>foreign key</code> <p>Alignment condition key</p> <code>aligned_trace</code> <code>longblob</code> <p>(s) Calcium activity aligned to the event time</p> Source code in <code>workflow_miniscope/analysis.py</code> <pre><code>class AlignedTrialActivity(dj.Part):\n\"\"\"Calcium activity aligned to the event time within the designated window\n\n    Attributes:\n        miniscope.Activity.Trace (foreign key): Activity trace primary key\n        ActivityAlignmentCondition.Trial (foreign key): Alignment condition key\n        aligned_trace (longblob): (s) Calcium activity aligned to the event time\n    \"\"\"\n\n    definition = \"\"\"\n    -&gt; master\n    -&gt; miniscope.Activity.Trace\n    -&gt; ActivityAlignmentCondition.Trial\n    ---\n    aligned_trace: longblob  # (s) Calcium activity aligned to the event time\n    \"\"\"\n</code></pre>"}, {"location": "api/workflow_miniscope/analysis/#workflow_miniscope.analysis.ActivityAlignment.make", "title": "<code>make(key)</code>", "text": "<p>Populate ActivityAlignment and AlignedTrialActivity</p> <p>Parameters:</p> Name Type Description Default <code>key</code> <code>dict</code> <p>Dict uniquely identifying one ActivityAlignmentCondition</p> required Source code in <code>workflow_miniscope/analysis.py</code> <pre><code>def make(self, key):\n\"\"\"Populate ActivityAlignment and AlignedTrialActivity\n\n    Args:\n        key (dict): Dict uniquely identifying one ActivityAlignmentCondition\n    \"\"\"\n    session_time, rec_time, nframes, frame_rate = (\n        miniscope.RecordingInfo * session.Session &amp; key\n    ).fetch1(\"session_datetime\", \"recording_datetime\", \"nframes\", \"fps\")\n\n    # Estimation of frame timestamps with respect to the session-start\n    # (to be replaced by timestamps retrieved from some synchronization routine)\n    # rec_start = (rec_time - session_time).total_seconds() if rec_time else 0\n    # frame_timestamps = np.arange(nframes) / frame_rate + rec_start\n\n    trialized_event_times = trial.get_trialized_alignment_event_times(\n        key, trial.Trial &amp; (ActivityAlignmentCondition.Trial &amp; key)\n    )\n\n    min_limit = (trialized_event_times.event - trialized_event_times.start).max()\n    max_limit = (trialized_event_times.end - trialized_event_times.event).max()\n\n    aligned_timestamps = np.arange(-min_limit, max_limit, 1 / frame_rate)\n    nsamples = len(aligned_timestamps)\n\n    trace_keys, activity_traces = (miniscope.Activity.Trace &amp; key).fetch(\n        \"KEY\", \"activity_trace\", order_by=\"mask_id\"\n    )\n    activity_traces = np.vstack(activity_traces)\n\n    aligned_trial_activities = []\n    for _, r in trialized_event_times.iterrows():\n        if r.event is None or np.isnan(r.event):\n            continue\n        alignment_start_idx = int((r.event - min_limit) * frame_rate)\n        roi_aligned_activities = activity_traces[\n            :, alignment_start_idx : (alignment_start_idx + nsamples)\n        ]\n        if roi_aligned_activities.shape[-1] != nsamples:\n            shape_diff = nsamples - roi_aligned_activities.shape[-1]\n            roi_aligned_activities = np.pad(\n                roi_aligned_activities,\n                ((0, 0), (0, shape_diff)),\n                mode=\"constant\",\n                constant_values=np.nan,\n            )\n\n        aligned_trial_activities.extend(\n            [\n                {**key, **r.trial_key, **trace_key, \"aligned_trace\": aligned_trace}\n                for trace_key, aligned_trace in zip(\n                    trace_keys, roi_aligned_activities\n                )\n            ]\n        )\n\n    self.insert1({**key, \"aligned_timestamps\": aligned_timestamps})\n    self.AlignedTrialActivity.insert(aligned_trial_activities)\n</code></pre>"}, {"location": "api/workflow_miniscope/analysis/#workflow_miniscope.analysis.ActivityAlignment.plot_aligned_activities", "title": "<code>plot_aligned_activities(key, roi, axs=None, title=None)</code>", "text": "<p>Plot event-aligned and trial-averaged calcium activities</p> <p>Activities including: dF/F, neuropil-corrected dF/F, Calcium events, etc.</p> <p>Parameters:</p> Name Type Description Default <code>key</code> <code>dict</code> <p>key of ActivityAlignment master table</p> required <code>roi</code> <code>int</code> <p>miniscope segmentation mask</p> required <code>axs</code> <code>tuple</code> <p>Definition of axes for plot. Default is plt.subplots(2, 1, figsize=(12, 8))</p> <code>None</code> <code>title</code> <code>str</code> <p>Optional title label. Defaults to None.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>fig</code> <code>matplotlib.figure.Figure</code> <p>Plot event-aligned and trial-averaged calcium activities</p> Source code in <code>workflow_miniscope/analysis.py</code> <pre><code>def plot_aligned_activities(\n    self, key: dict, roi, axs: tuple = None, title: str = None\n) -&gt; plt.figure.Figure:\n\"\"\"Plot event-aligned and trial-averaged calcium activities\n\n    Activities including: dF/F, neuropil-corrected dF/F, Calcium events, etc.\n\n    Args:\n        key (dict): key of ActivityAlignment master table\n        roi (int): miniscope segmentation mask\n        axs (tuple, optional): Definition of axes for plot.\n            Default is plt.subplots(2, 1, figsize=(12, 8))\n        title (str, optional): Optional title label. Defaults to None.\n\n    Returns:\n        fig (matplotlib.figure.Figure): Plot event-aligned and trial-averaged\n            calcium activities\n    \"\"\"\n\n    fig = None\n    if axs is None:\n        fig, (ax0, ax1) = plt.subplots(2, 1, figsize=(12, 8))\n    else:\n        ax0, ax1 = axs\n\n    aligned_timestamps = (self &amp; key).fetch1(\"aligned_timestamps\")\n    _, aligned_spikes = (self.AlignedTrialActivity &amp; key &amp; {\"mask_id\": roi}).fetch(\n        \"trial_id\", \"aligned_trace\", order_by=\"trial_id\"\n    )\n\n    aligned_spikes = np.vstack(aligned_spikes)\n\n    ax0.imshow(\n        aligned_spikes,\n        cmap=\"inferno\",\n        interpolation=\"nearest\",\n        aspect=\"auto\",\n        extent=(\n            aligned_timestamps[0],\n            aligned_timestamps[-1],\n            0,\n            aligned_spikes.shape[0],\n        ),\n    )\n    ax0.axvline(x=0, linestyle=\"--\", color=\"white\")\n    ax0.set_axis_off()\n\n    ax1.plot(aligned_timestamps, np.nanmean(aligned_spikes, axis=0))\n    ax1.axvline(x=0, linestyle=\"--\", color=\"black\")\n    ax1.set_xlabel(\"Time (s)\")\n    ax1.set_xlim(aligned_timestamps[0], aligned_timestamps[-1])\n\n    if title:\n        plt.suptitle(title)\n\n    return fig\n</code></pre>"}, {"location": "api/workflow_miniscope/paths/", "title": "paths.py", "text": ""}, {"location": "api/workflow_miniscope/paths/#workflow_miniscope.paths.get_miniscope_root_data_dir", "title": "<code>get_miniscope_root_data_dir()</code>", "text": "<p>Return root directory for miniscope from 'miniscope_root_data_dir' config as list</p> <p>Returns:</p> Name Type Description <code>path</code> <code>any</code> <p>List of path(s) if available or None</p> Source code in <code>workflow_miniscope/paths.py</code> <pre><code>def get_miniscope_root_data_dir() -&gt; Union[list, None]:\n\"\"\"Return root directory for miniscope from 'miniscope_root_data_dir' config as list\n\n    Returns:\n        path (any): List of path(s) if available or None\n    \"\"\"\n    mini_root_dirs = dj.config.get(\"custom\", {}).get(\"miniscope_root_data_dir\")\n\n    if not mini_root_dirs:\n        return None\n    elif not isinstance(mini_root_dirs, abc.Sequence):\n        return list(mini_root_dirs)\n    else:\n        return mini_root_dirs\n</code></pre>"}, {"location": "api/workflow_miniscope/paths/#workflow_miniscope.paths.get_session_directory", "title": "<code>get_session_directory(session_key)</code>", "text": "<p>Return relative path from SessionDirectory table given key</p> <p>Parameters:</p> Name Type Description Default <code>session_key</code> <code>dict</code> <p>Key uniquely identifying a session</p> required <p>Returns:</p> Name Type Description <code>path</code> <code>str</code> <p>Relative path of session directory</p> Source code in <code>workflow_miniscope/paths.py</code> <pre><code>def get_session_directory(session_key: dict) -&gt; str:\n\"\"\"Return relative path from SessionDirectory table given key\n\n    Args:\n        session_key (dict): Key uniquely identifying a session\n\n    Returns:\n        path (str): Relative path of session directory\n    \"\"\"\n    from .pipeline import session\n\n    session_dir = (session.SessionDirectory &amp; session_key).fetch1(\"session_dir\")\n    return session_dir\n</code></pre>"}, {"location": "api/workflow_miniscope/pipeline/", "title": "pipeline.py", "text": ""}, {"location": "api/workflow_miniscope/pipeline/#workflow_miniscope.pipeline.get_miniscope_root_data_dir", "title": "<code>get_miniscope_root_data_dir()</code>", "text": "<p>Return root directory for miniscope from 'miniscope_root_data_dir' config as list</p> <p>Returns:</p> Name Type Description <code>path</code> <code>any</code> <p>List of path(s) if available or None</p> Source code in <code>workflow_miniscope/paths.py</code> <pre><code>def get_miniscope_root_data_dir() -&gt; Union[list, None]:\n\"\"\"Return root directory for miniscope from 'miniscope_root_data_dir' config as list\n\n    Returns:\n        path (any): List of path(s) if available or None\n    \"\"\"\n    mini_root_dirs = dj.config.get(\"custom\", {}).get(\"miniscope_root_data_dir\")\n\n    if not mini_root_dirs:\n        return None\n    elif not isinstance(mini_root_dirs, abc.Sequence):\n        return list(mini_root_dirs)\n    else:\n        return mini_root_dirs\n</code></pre>"}, {"location": "api/workflow_miniscope/pipeline/#workflow_miniscope.pipeline.Device", "title": "<code>Device</code>", "text": "<p>             Bases: <code>dj.Lookup</code></p> <p>Table for managing lab Devices.</p> <p>Attributes:</p> Name Type Description <code>device</code> <code> varchar(32) </code> <p>Device short name.</p> <code>modality</code> <code> varchar(64) </code> <p>Modality for which this device is used.</p> <code>description</code> <code> varchar(256) </code> <p>Optional. Description of device.</p> Source code in <code>workflow_miniscope/reference.py</code> <pre><code>@schema\nclass Device(dj.Lookup):\n\"\"\"Table for managing lab Devices.\n\n    Attributes:\n        device ( varchar(32) ): Device short name.\n        modality ( varchar(64) ): Modality for which this device is used.\n        description ( varchar(256) ): Optional. Description of device.\n    \"\"\"\n\n    definition = \"\"\"\n    device             : varchar(32)\n    ---\n    modality           : varchar(64)\n    description=''     : varchar(256)\n    \"\"\"\n    contents = [\n        [\"Miniscope_V4_BNO\", \"Miniscope\", \"V4 Miniscope with head orientation sensor.\"],\n    ]\n</code></pre>"}, {"location": "api/workflow_miniscope/pipeline/#workflow_miniscope.pipeline.get_session_directory", "title": "<code>get_session_directory(session_key)</code>", "text": "<p>Return relative path from SessionDirectory table given key</p> <p>Parameters:</p> Name Type Description Default <code>session_key</code> <code>dict</code> <p>Key uniquely identifying a session</p> required <p>Returns:</p> Name Type Description <code>path</code> <code>str</code> <p>Relative path of session directory</p> Source code in <code>workflow_miniscope/paths.py</code> <pre><code>def get_session_directory(session_key: dict) -&gt; str:\n\"\"\"Return relative path from SessionDirectory table given key\n\n    Args:\n        session_key (dict): Key uniquely identifying a session\n\n    Returns:\n        path (str): Relative path of session directory\n    \"\"\"\n    from .pipeline import session\n\n    session_dir = (session.SessionDirectory &amp; session_key).fetch1(\"session_dir\")\n    return session_dir\n</code></pre>"}, {"location": "api/workflow_miniscope/pipeline/#workflow_miniscope.pipeline.AnatomicalLocation", "title": "<code>AnatomicalLocation</code>", "text": "<p>             Bases: <code>dj.Manual</code></p> <p>Lookup table for anatomical location</p> <p>Attributes:</p> Name Type Description <code>recording_location_id</code> <code> ( varchar(16) </code> <p>Lookup id for location</p> <code>anatomical_description</code> <code> varchar(256) </code> <p>Location full description</p> Source code in <code>workflow_miniscope/reference.py</code> <pre><code>@schema\nclass AnatomicalLocation(dj.Manual):\n\"\"\"Lookup table for anatomical location\n\n    Attributes:\n        recording_location_id  ( varchar(16) ): Lookup id for location\n        anatomical_description ( varchar(256) ): Location full description\n    \"\"\"\n\n    definition = \"\"\"\n    recording_location_id : varchar(16) # Lookup id for location\n    ---\n    anatomical_description: varchar(256) # Location full description\n    \"\"\"\n</code></pre>"}, {"location": "api/workflow_miniscope/reference/", "title": "reference.py", "text": ""}, {"location": "api/workflow_miniscope/reference/#workflow_miniscope.reference.Device", "title": "<code>Device</code>", "text": "<p>             Bases: <code>dj.Lookup</code></p> <p>Table for managing lab Devices.</p> <p>Attributes:</p> Name Type Description <code>device</code> <code> varchar(32) </code> <p>Device short name.</p> <code>modality</code> <code> varchar(64) </code> <p>Modality for which this device is used.</p> <code>description</code> <code> varchar(256) </code> <p>Optional. Description of device.</p> Source code in <code>workflow_miniscope/reference.py</code> <pre><code>@schema\nclass Device(dj.Lookup):\n\"\"\"Table for managing lab Devices.\n\n    Attributes:\n        device ( varchar(32) ): Device short name.\n        modality ( varchar(64) ): Modality for which this device is used.\n        description ( varchar(256) ): Optional. Description of device.\n    \"\"\"\n\n    definition = \"\"\"\n    device             : varchar(32)\n    ---\n    modality           : varchar(64)\n    description=''     : varchar(256)\n    \"\"\"\n    contents = [\n        [\"Miniscope_V4_BNO\", \"Miniscope\", \"V4 Miniscope with head orientation sensor.\"],\n    ]\n</code></pre>"}, {"location": "api/workflow_miniscope/reference/#workflow_miniscope.reference.AnatomicalLocation", "title": "<code>AnatomicalLocation</code>", "text": "<p>             Bases: <code>dj.Manual</code></p> <p>Lookup table for anatomical location</p> <p>Attributes:</p> Name Type Description <code>recording_location_id</code> <code> ( varchar(16) </code> <p>Lookup id for location</p> <code>anatomical_description</code> <code> varchar(256) </code> <p>Location full description</p> Source code in <code>workflow_miniscope/reference.py</code> <pre><code>@schema\nclass AnatomicalLocation(dj.Manual):\n\"\"\"Lookup table for anatomical location\n\n    Attributes:\n        recording_location_id  ( varchar(16) ): Lookup id for location\n        anatomical_description ( varchar(256) ): Location full description\n    \"\"\"\n\n    definition = \"\"\"\n    recording_location_id : varchar(16) # Lookup id for location\n    ---\n    anatomical_description: varchar(256) # Location full description\n    \"\"\"\n</code></pre>"}, {"location": "tutorials/", "title": "Tutorials", "text": "<ul> <li>DataJoint Elements are modular pipelines that can be connected into a complete workflow.  Workflow Miniscope is an example that combines five DataJoint Elements - Lab, Animal, Session, Event, and Miniscope.</li> </ul> <ul> <li>Workflow Miniscope includes an interactive tutorial on GitHub Codespaces, which is configured for users to run the pipeline.</li> </ul> <ul> <li>In the interactive tutorial, the example notebooks describe the pipeline and provide instructions for running the pipeline.  For convenience, these notebooks are also rendered on this website:<ul> <li>Tutorial notebook</li> <li>Quality metrics notebook</li> </ul> </li> </ul>"}, {"location": "tutorials/#installation-instructions-for-active-projects", "title": "Installation Instructions for Active Projects", "text": "<ul> <li>The Workflow Miniscope described above can be modified for a user's specific experimental requirements and thereby used in active projects.  </li> </ul> <ul> <li>The GitHub Codespace and Dev Container is configured for tutorials and prototyping. We recommend users to configure a database specifically for production pipelines.  Instructions for a local installation of the integrated development environment with a database can be found on the User Guide page.</li> </ul>"}, {"location": "tutorials/#videos", "title": "Videos", "text": "<ul> <li>The YouTube tutorial gives an overview  of the workflow files and notebooks, as well as core concepts related to calcium imaging analysis.</li> </ul>"}, {"location": "tutorials/01-Configure/", "title": "01 Configure", "text": "In\u00a0[\u00a0]: Copied! <pre>import os\n\nif os.path.basename(os.getcwd()) == \"notebooks\":\n    os.chdir(\"..\")\n</pre> import os  if os.path.basename(os.getcwd()) == \"notebooks\":     os.chdir(\"..\") In\u00a0[\u00a0]: Copied! <pre>import datajoint as dj\n</pre> import datajoint as dj In\u00a0[\u00a0]: Copied! <pre>import getpass\n\ndj.config[\"database.host\"] = \"{YOUR_HOST}\"\ndj.config[\"database.user\"] = \"{YOUR_USERNAME}\"\ndj.config[\"database.password\"] = getpass.getpass()  # enter the password securely\n</pre> import getpass  dj.config[\"database.host\"] = \"{YOUR_HOST}\" dj.config[\"database.user\"] = \"{YOUR_USERNAME}\" dj.config[\"database.password\"] = getpass.getpass()  # enter the password securely <p>You should be able to connect to the database at this stage.</p> In\u00a0[\u00a0]: Copied! <pre>dj.conn()\n</pre> dj.conn() In\u00a0[\u00a0]: Copied! <pre>dj.config[\"custom\"] = {\"database.prefix\": \"neuro_\"}\n</pre> dj.config[\"custom\"] = {\"database.prefix\": \"neuro_\"} <p>If using our example dataset, downloaded with this notebook 00-data-download, the root directory will be:</p> In\u00a0[\u00a0]: Copied! <pre># If there is only one root path:\ndj.config[\"custom\"][\"miniscope_root_data_dir\"] = \"/tmp/example_data\"\n# If there are multiple possible root paths:\ndj.config[\"custom\"][\"miniscope_root_data_dir\"] = [\"/tmp/example_data\"]\n</pre> # If there is only one root path: dj.config[\"custom\"][\"miniscope_root_data_dir\"] = \"/tmp/example_data\" # If there are multiple possible root paths: dj.config[\"custom\"][\"miniscope_root_data_dir\"] = [\"/tmp/example_data\"] In\u00a0[\u00a0]: Copied! <pre>dj.config\n</pre> dj.config In\u00a0[\u00a0]: Copied! <pre>dj.config.save_local()\n</pre> dj.config.save_local() In\u00a0[\u00a0]: Copied! <pre>ls\n</pre> ls <p>Local configuration file is saved as <code>dj_local_conf.json</code> in the root directory of this package <code>workflow-miniscope</code>. Next time if you change your directory to <code>workflow-miniscope</code> before importing DataJoint and the pipeline packages, the configurations will get properly loaded.</p> <p>If saved globally, there will be a hidden configuration file saved in your root directory. The configuration will be loaded no matter where the directory is.</p> In\u00a0[\u00a0]: Copied! <pre># dj.config.save_global()\n</pre> # dj.config.save_global()"}, {"location": "tutorials/01-Configure/#configure-datajoint-connection-to-the-database", "title": "Configure DataJoint connection to the database\u00b6", "text": "<ul> <li><p>To run <code>workflow-miniscope</code>, we need to properly set up the DataJoint configuration. The configuration will be saved in a file called <code>dj_local_conf.json</code> on each machine and this notebook walks you through the process.</p> </li> <li><p>The configuration only needs to be set up once. If you have gone through the configuration before, directly go to 02-workflow-structure.</p> </li> </ul>"}, {"location": "tutorials/01-Configure/#set-up-configuration-in-root-directory-of-this-package", "title": "Set up configuration in root directory of this package\u00b6", "text": "<ul> <li>As a convention, we set the configuration up in the root directory of the <code>workflow-miniscope</code> package and always start importing DataJoint and pipeline modules from there.</li> </ul>"}, {"location": "tutorials/01-Configure/#configure-database-host-address-and-credentials", "title": "Configure database host address and credentials\u00b6", "text": "<p>Now let's set up the host, user and password in the <code>dj.config</code> global variable</p>"}, {"location": "tutorials/01-Configure/#configure-the-custom-field-in-djconfig-for-element-miniscope", "title": "Configure the <code>custom</code> field in <code>dj.config</code> for element-miniscope\u00b6", "text": "<ul> <li>The major component of the current workflow is the DataJoint element-miniscope. <code>element-miniscope</code> requires configurations in the field <code>custom</code> in <code>dj.config</code>:</li> </ul>"}, {"location": "tutorials/01-Configure/#database-prefix", "title": "Database prefix\u00b6", "text": "<ul> <li><p>Giving a prefix to schema could help on the configuration of privilege settings. For example, if we set prefix <code>neuro_</code>, every schema created with the current workflow will start with <code>neuro_</code>, e.g. <code>neuro_lab</code>, <code>neuro_subject</code>, <code>neuro_session</code>, and <code>neuro_miniscope</code>.</p> </li> <li><p>The prefix could be configured as follows in <code>dj.config</code>:</p> </li> </ul>"}, {"location": "tutorials/01-Configure/#root-directories-for-miniscope-calcium-imaging-raw-data-and-processed-results", "title": "Root directories for miniscope calcium imaging raw data and processed results\u00b6", "text": "<ul> <li><p><code>miniscope_root_data_dir</code> field indicates the root directory for the miniscope raw data from the Miniscope-DAQ acquisition software (e.g. <code>*.avi</code>) or the processed results from CaImAn (e.g. <code>*.hdf5</code>). The root path typically do not contain information of subjects or sessions, all data from subjects/sessions should be subdirectories in the root path.</p> </li> <li><p>In the database, every path for the raw miniscope data is relative to this root path. The benefit is that the absolute path could be configured for each machine, and when data transfer happens, we just need to change the root directory in the config file.</p> </li> <li><p>The workflow supports multiple root directories. If there are multiple possible root directories, specify the <code>miniscope_root_data_dir</code> as a list.</p> </li> <li><p>The root path(s) are specific to each machine, as the name of drive mount could be different for different operating systems or machines.</p> </li> <li><p>In the context of the workflow, all the paths saved into the database or saved in the config file need to be in the POSIX standards (Unix/Linux), with <code>/</code>. The path conversion for machines of any operating system is taken care of inside the elements.</p> </li> </ul>"}, {"location": "tutorials/01-Configure/#save-the-configuration-as-a-json-file", "title": "Save the configuration as a json file\u00b6", "text": "<p>With the proper configurations, we could save this as a file, either as a local json file, or a global file.</p>"}, {"location": "tutorials/01-Configure/#next-step", "title": "Next Step\u00b6", "text": "<p>After the configuration, we will be able to run through the workflow with the 02-workflow-structure notebook.</p>"}, {"location": "tutorials/02-WorkflowStructure_Optional/", "title": "02 WorkflowStructure Optional", "text": "In\u00a0[\u00a0]: Copied! <pre>import os\n\nos.chdir(\"..\")\n</pre> import os  os.chdir(\"..\") In\u00a0[\u00a0]: Copied! <pre>import datajoint as dj\nfrom workflow_miniscope.pipeline import lab, subject, session, miniscope\n</pre> import datajoint as dj from workflow_miniscope.pipeline import lab, subject, session, miniscope <ul> <li>Each module contains a schema object that enables interaction with the schema in the database.</li> </ul> In\u00a0[\u00a0]: Copied! <pre>miniscope.schema\n</pre> miniscope.schema <ul> <li>The table classes in the module corresponds to a table in the schema in the database.</li> </ul> In\u00a0[\u00a0]: Copied! <pre># preview columns and contents in a table\nminiscope.Processing()\n</pre> # preview columns and contents in a table miniscope.Processing() <ul> <li><p>By importing the modules for the first time, the schemas and tables will be created inside the database.</p> </li> <li><p>Once created, importing modules will not create schemas and tables again, but the existing schemas/tables can be accessed and manipulated by the modules.</p> </li> </ul> In\u00a0[\u00a0]: Copied! <pre>dj.list_schemas()\n</pre> dj.list_schemas() <ul> <li><code>dj.Diagram()</code>: plot tables and dependencies in a schema.</li> </ul> In\u00a0[\u00a0]: Copied! <pre># plot diagram for all tables in a schema\ndj.Diagram(miniscope)\n</pre> # plot diagram for all tables in a schema dj.Diagram(miniscope) <p>Table tiers:</p> <ul> <li>Manual table<ul> <li>Visually represented with a green box.</li> <li>Manually inserted table</li> <li>Expect new entries daily, e.g. Subject, Recording.</li> </ul> </li> <li>Lookup table<ul> <li>Visually represented with a gray box.</li> <li>Pre-inserted table</li> <li>Commonly used for general facts or parameters. e.g. Strain, ProcessingParamSet.</li> </ul> </li> <li>Imported table<ul> <li>Visually represented with a blue oval.</li> <li>Auto-processing table</li> <li>Processing depends on the importing of external files. e.g. <code>Processing</code> requires output files from CaImAn.</li> </ul> </li> <li>Computed table<ul> <li>Visually represented with a red circle.</li> <li>Auto-processing table</li> <li>Processing does not depend on files external to the database.</li> </ul> </li> <li>Part table<ul> <li>Visually represented with plain text.</li> <li>As an appendix to the master table, all the part entries of a given master entry represent a intact set of the master entry. e.g. <code>Mask</code> of a <code>Segmentation</code>.</li> </ul> </li> </ul> <p>Dependencies:</p> <ul> <li>One-to-one primary<ul> <li>Visually represented with a thick solid line.</li> <li>Share the exact same primary key, meaning the child table inherits all the primary key fields from the parent table as its own primary key.</li> </ul> </li> <li>One-to-many primary<ul> <li>Visually represented with a thin solid line.</li> <li>Inherit the primary key from the parent table, but have additional field(s) as part of the primary key as well.</li> </ul> </li> <li>Secondary dependency<ul> <li>Visually represented with a dashed line.</li> <li>The child table inherits the primary key fields from parent table as its own secondary attribute.</li> </ul> </li> </ul> In\u00a0[\u00a0]: Copied! <pre># plot diagram of tables in multiple schemas\ndj.Diagram(subject) + dj.Diagram(session) + dj.Diagram(miniscope)\n</pre> # plot diagram of tables in multiple schemas dj.Diagram(subject) + dj.Diagram(session) + dj.Diagram(miniscope) In\u00a0[\u00a0]: Copied! <pre># plot diagram of selected tables and schemas\ndj.Diagram(subject.Subject) + dj.Diagram(session.Session) + dj.Diagram(miniscope)\n</pre> # plot diagram of selected tables and schemas dj.Diagram(subject.Subject) + dj.Diagram(session.Session) + dj.Diagram(miniscope) <ul> <li><code>describe()</code>: show table definition with foreign key references.</li> </ul> In\u00a0[\u00a0]: Copied! <pre>miniscope.Processing.describe()\n</pre> miniscope.Processing.describe() <ul> <li><code>heading</code>: show attribute definitions regardless of foreign key references</li> </ul> In\u00a0[\u00a0]: Copied! <pre>miniscope.Processing.heading\n</pre> miniscope.Processing.heading In\u00a0[\u00a0]: Copied! <pre>dj.Diagram(lab)\n</pre> dj.Diagram(lab) <ul> <li><code>subject</code>: general animal information, such as User, Genetic background.</li> </ul> In\u00a0[\u00a0]: Copied! <pre>dj.Diagram(subject)\n</pre> dj.Diagram(subject) In\u00a0[\u00a0]: Copied! <pre>subject.Subject.describe()\n</pre> subject.Subject.describe() <ul> <li><code>session</code>: General information of experimental sessions.</li> </ul> In\u00a0[\u00a0]: Copied! <pre>dj.Diagram(session)\n</pre> dj.Diagram(session) In\u00a0[\u00a0]: Copied! <pre>session.Session.describe()\n</pre> session.Session.describe() <ul> <li><code>miniscope</code>: miniscope raw recording and processed data</li> </ul> In\u00a0[\u00a0]: Copied! <pre>dj.Diagram(miniscope)\n</pre> dj.Diagram(miniscope)"}, {"location": "tutorials/02-WorkflowStructure_Optional/#introduction-to-the-workflow-structure", "title": "Introduction to the workflow structure\u00b6", "text": "<p>This notebook gives a brief overview of the workflow structure and introduces some useful DataJoint tools to facilitate the exploration.</p> <ul> <li><p>DataJoint needs to be pre-configured before running this notebook, if you haven't set up the configuration, refer to notebook 01-configure.</p> </li> <li><p>If you are familiar with DataJoint and the workflow structure, proceed directly to the next notebook 03-process to run the workflow.</p> </li> <li><p>For a more thorough introduction of DataJoint functions, please visit our general tutorial site - DataJoint CodeBook.</p> </li> </ul> <p>To load the local configuration, we will change the directory to the package root.</p>"}, {"location": "tutorials/02-WorkflowStructure_Optional/#schemas-and-tables", "title": "Schemas and tables\u00b6", "text": "<ul> <li>The current workflow is composed of multiple database schemas, each of them corresponds to a module within <code>workflow_miniscope.pipeline</code></li> </ul>"}, {"location": "tutorials/02-WorkflowStructure_Optional/#datajoint-tools-to-explore-schemas-and-tables", "title": "DataJoint tools to explore schemas and tables\u00b6", "text": "<ul> <li><code>dj.list_schemas()</code>: list all schemas a user has access to in the current database</li> </ul>"}, {"location": "tutorials/02-WorkflowStructure_Optional/#datajoint-elements-installed-in-workflow-miniscope", "title": "DataJoint Elements installed in <code>workflow-miniscope</code>\u00b6", "text": "<ul> <li><code>lab</code>: lab management related information, such as Lab, User, Project, Protocol, Source.</li> </ul>"}, {"location": "tutorials/02-WorkflowStructure_Optional/#summary-and-next-step", "title": "Summary and next step\u00b6", "text": "<ul> <li><p>This notebook introduced the overall structures of the schemas and tables in the workflow and relevant tools to explore the schema structure and table definitions.</p> </li> <li><p>In the next notebook 03-process, we will introduce the detailed steps to run through the workflow.</p> </li> </ul>"}, {"location": "tutorials/03-Process/", "title": "03 Process", "text": "<p>Let's change the directory to the package root directory to load the local configuration (<code>dj_local_conf.json</code>).</p> In\u00a0[\u00a0]: Copied! <pre>import os\n\nif os.path.basename(os.getcwd()) == \"notebooks\":\n    os.chdir(\"..\")\nimport datajoint as dj\n</pre> import os  if os.path.basename(os.getcwd()) == \"notebooks\":     os.chdir(\"..\") import datajoint as dj In\u00a0[\u00a0]: Copied! <pre>from workflow_miniscope.pipeline import (\n    subject,\n    session,\n    AnatomicalLocation,\n    Equipment,\n    miniscope,\n)\n</pre> from workflow_miniscope.pipeline import (     subject,     session,     AnatomicalLocation,     Equipment,     miniscope, ) In\u00a0[\u00a0]: Copied! <pre>(\n    dj.Diagram(subject.Subject)\n    + dj.Diagram(session.Session)\n    + dj.Diagram(AnatomicalLocation)\n    + dj.Diagram(Equipment)\n    + dj.Diagram(miniscope)\n)\n</pre> (     dj.Diagram(subject.Subject)     + dj.Diagram(session.Session)     + dj.Diagram(AnatomicalLocation)     + dj.Diagram(Equipment)     + dj.Diagram(miniscope) ) In\u00a0[\u00a0]: Copied! <pre>subject.Subject.heading\n</pre> subject.Subject.heading In\u00a0[\u00a0]: Copied! <pre>subject.Subject.insert1(\n    dict(\n        subject=\"subject1\",\n        sex=\"F\",\n        subject_birth_date=\"2020-01-01\",\n        subject_description=\"UCLA Miniscope acquisition\",\n    )\n)\n</pre> subject.Subject.insert1(     dict(         subject=\"subject1\",         sex=\"F\",         subject_birth_date=\"2020-01-01\",         subject_description=\"UCLA Miniscope acquisition\",     ) ) In\u00a0[\u00a0]: Copied! <pre>Equipment.insert1(\n    dict(equipment=\"UCLA Miniscope\", modality=\"miniscope\", description=\"\")\n)\n</pre> Equipment.insert1(     dict(equipment=\"UCLA Miniscope\", modality=\"miniscope\", description=\"\") ) In\u00a0[\u00a0]: Copied! <pre>session.Session.describe()\n</pre> session.Session.describe() In\u00a0[\u00a0]: Copied! <pre>session.Session.heading\n</pre> session.Session.heading In\u00a0[\u00a0]: Copied! <pre>session_key = dict(subject=\"subject1\", session_datetime=\"2021-01-01 00:00:01\")\n</pre> session_key = dict(subject=\"subject1\", session_datetime=\"2021-01-01 00:00:01\") In\u00a0[\u00a0]: Copied! <pre>session.Session.insert1(session_key)\n</pre> session.Session.insert1(session_key) In\u00a0[\u00a0]: Copied! <pre>session.Session()\n</pre> session.Session() In\u00a0[\u00a0]: Copied! <pre>session.SessionDirectory.describe()\n</pre> session.SessionDirectory.describe() In\u00a0[\u00a0]: Copied! <pre>session.SessionDirectory.heading\n</pre> session.SessionDirectory.heading In\u00a0[\u00a0]: Copied! <pre>session.SessionDirectory.insert1(dict(**session_key, session_dir=\"subject1/session1\"))\n</pre> session.SessionDirectory.insert1(dict(**session_key, session_dir=\"subject1/session1\")) In\u00a0[\u00a0]: Copied! <pre>session.SessionDirectory()\n</pre> session.SessionDirectory() In\u00a0[\u00a0]: Copied! <pre>miniscope.Recording.heading\n</pre> miniscope.Recording.heading In\u00a0[\u00a0]: Copied! <pre>recording_key = dict(**session_key, recording_id=0)\n</pre> recording_key = dict(**session_key, recording_id=0) In\u00a0[\u00a0]: Copied! <pre>miniscope.Recording.insert1(\n    dict(\n        **recording_key,\n        equipment=\"UCLA Miniscope\",\n        acquisition_software=\"Miniscope-DAQ-V4\",\n        recording_directory=\"subject1/session1\",\n        recording_notes=\"No notes for this session.\"\n    )\n)\n</pre> miniscope.Recording.insert1(     dict(         **recording_key,         equipment=\"UCLA Miniscope\",         acquisition_software=\"Miniscope-DAQ-V4\",         recording_directory=\"subject1/session1\",         recording_notes=\"No notes for this session.\"     ) ) In\u00a0[\u00a0]: Copied! <pre>miniscope.Recording()\n</pre> miniscope.Recording() In\u00a0[\u00a0]: Copied! <pre>miniscope.RecordingInfo.describe()\n</pre> miniscope.RecordingInfo.describe() In\u00a0[\u00a0]: Copied! <pre>miniscope.RecordingInfo.heading\n</pre> miniscope.RecordingInfo.heading In\u00a0[\u00a0]: Copied! <pre>populate_settings = {\"display_progress\": True}\n</pre> populate_settings = {\"display_progress\": True} In\u00a0[\u00a0]: Copied! <pre>miniscope.RecordingInfo.populate(**populate_settings)\n</pre> miniscope.RecordingInfo.populate(**populate_settings) In\u00a0[\u00a0]: Copied! <pre>miniscope.RecordingInfo()\n</pre> miniscope.RecordingInfo() In\u00a0[\u00a0]: Copied! <pre>params = dict(\n    decay_time=0.4,\n    pw_rigid=False,\n    max_shifts=(5, 5),\n    gSig_filt=(3, 3),\n    strides=(48, 48),\n    overlaps=(24, 24),\n    max_deviation_rigid=3,\n    border_nan=\"copy\",\n    method_init=\"corr_pnr\",\n    K=None,\n    gSig=(3, 3),\n    gSiz=(13, 13),\n    merge_thr=0.7,\n    p=1,\n    tsub=2,\n    ssub=1,\n    rf=40,\n    stride=20,\n    only_init=True,\n    nb=0,\n    nb_patch=0,\n    method_deconvolution=\"oasis\",\n    low_rank_background=None,\n    update_background_components=True,\n    min_corr=0.8,\n    min_pnr=10,\n    normalize_init=False,\n    center_psf=True,\n    ssub_B=2,\n    ring_size_factor=1.4,\n    del_duplicates=True,\n    border_pix=0,\n    min_SNR=3,\n    rval_thr=0.85,\n    use_cnn=False,\n)\n</pre> params = dict(     decay_time=0.4,     pw_rigid=False,     max_shifts=(5, 5),     gSig_filt=(3, 3),     strides=(48, 48),     overlaps=(24, 24),     max_deviation_rigid=3,     border_nan=\"copy\",     method_init=\"corr_pnr\",     K=None,     gSig=(3, 3),     gSiz=(13, 13),     merge_thr=0.7,     p=1,     tsub=2,     ssub=1,     rf=40,     stride=20,     only_init=True,     nb=0,     nb_patch=0,     method_deconvolution=\"oasis\",     low_rank_background=None,     update_background_components=True,     min_corr=0.8,     min_pnr=10,     normalize_init=False,     center_psf=True,     ssub_B=2,     ring_size_factor=1.4,     del_duplicates=True,     border_pix=0,     min_SNR=3,     rval_thr=0.85,     use_cnn=False, ) In\u00a0[\u00a0]: Copied! <pre>miniscope.ProcessingParamSet.insert_new_params(\n    processing_method=\"caiman\",\n    paramset_id=0,\n    paramset_desc=\"Calcium imaging analysis with CaImAn using default parameters\",\n    params=params,\n)\n</pre> miniscope.ProcessingParamSet.insert_new_params(     processing_method=\"caiman\",     paramset_id=0,     paramset_desc=\"Calcium imaging analysis with CaImAn using default parameters\",     params=params, ) In\u00a0[\u00a0]: Copied! <pre>miniscope.ProcessingTask.insert1(\n    dict(\n        **recording_key,\n        paramset_id=0,\n        processing_output_dir=\"subject1/session1/caiman\",\n        task_mode=\"trigger\"\n    )\n)\n</pre> miniscope.ProcessingTask.insert1(     dict(         **recording_key,         paramset_id=0,         processing_output_dir=\"subject1/session1/caiman\",         task_mode=\"trigger\"     ) ) In\u00a0[\u00a0]: Copied! <pre>miniscope.Processing.populate(**populate_settings)\n</pre> miniscope.Processing.populate(**populate_settings) In\u00a0[\u00a0]: Copied! <pre>miniscope.Curation.insert1(\n    dict(\n        **recording_key,\n        paramset_id=0,\n        curation_id=0,\n        curation_time=\"2022-04-30 12:22:15\",\n        curation_output_dir=\"subject1/session1/caiman\",\n        manual_curation=False,\n        curation_note=\"\"\n    )\n)\n</pre> miniscope.Curation.insert1(     dict(         **recording_key,         paramset_id=0,         curation_id=0,         curation_time=\"2022-04-30 12:22:15\",         curation_output_dir=\"subject1/session1/caiman\",         manual_curation=False,         curation_note=\"\"     ) ) In\u00a0[\u00a0]: Copied! <pre>miniscope.MotionCorrection.populate(**populate_settings)\n</pre> miniscope.MotionCorrection.populate(**populate_settings) In\u00a0[\u00a0]: Copied! <pre>miniscope.Segmentation.populate(**populate_settings)\n</pre> miniscope.Segmentation.populate(**populate_settings) In\u00a0[\u00a0]: Copied! <pre>miniscope.Fluorescence.populate(**populate_settings)\n</pre> miniscope.Fluorescence.populate(**populate_settings) In\u00a0[\u00a0]: Copied! <pre>miniscope.Activity.populate(**populate_settings)\n</pre> miniscope.Activity.populate(**populate_settings)"}, {"location": "tutorials/03-Process/#interactively-run-miniscope-workflow", "title": "Interactively run miniscope workflow\u00b6", "text": "<ul> <li><p>This notebook walks you through the steps in detail to run the <code>workflow-miniscope</code>.</p> </li> <li><p>The workflow requires the data acquired from the UCLA Miniscope and Miniscope-DAQ software and processing with CaImAn.</p> </li> <li><p>If you haven't configured the paths, refer to 01-configure.</p> </li> <li><p>To overview the schema structures, refer to 02-workflow-structure.</p> </li> <li><p>If you need a more automatic approach to run the workflow, refer to 04-automate.</p> </li> </ul>"}, {"location": "tutorials/03-Process/#pipelinepy", "title": "<code>Pipeline.py</code>\u00b6", "text": "<ul> <li>This script <code>activates</code> the DataJoint <code>Elements</code> and declares other required tables.</li> </ul>"}, {"location": "tutorials/03-Process/#schema-diagrams", "title": "Schema diagrams\u00b6", "text": "<ul> <li><p>The following outputs are the diagrams of the schemas comprising this workflow.</p> </li> <li><p>Please refer back to these diagrams to visualize the relationships of different tables.</p> </li> </ul>"}, {"location": "tutorials/03-Process/#insert-an-entry-into-subjectsubject", "title": "Insert an entry into <code>subject.Subject</code>\u00b6", "text": ""}, {"location": "tutorials/03-Process/#insert-an-entry-into-labequipment", "title": "Insert an entry into <code>lab.Equipment</code>\u00b6", "text": ""}, {"location": "tutorials/03-Process/#insert-an-entry-into-sessionsession", "title": "Insert an entry into <code>session.Session</code>\u00b6", "text": ""}, {"location": "tutorials/03-Process/#insert-an-entry-into-sessionsessiondirectory", "title": "Insert an entry into <code>session.SessionDirectory</code>\u00b6", "text": "<ul> <li><p>The <code>session_dir</code> is the relative path to the <code>miniscope_root_data_dir</code> for the given session, in POSIX format with <code>/</code>.</p> </li> <li><p>Instead of a relative path, <code>session_dir</code> could be an absolute path but it is not recommended as the absolute path would have to match the <code>miniscope_root_data_dir</code> in <code>dj_local_conf.json</code>.</p> </li> </ul>"}, {"location": "tutorials/03-Process/#insert-an-entry-into-miniscoperecording", "title": "Insert an entry into <code>miniscope.Recording</code>\u00b6", "text": ""}, {"location": "tutorials/03-Process/#populate-miniscoperecordinginfo", "title": "Populate <code>miniscope.RecordingInfo</code>\u00b6", "text": "<ul> <li>This imported table stores information about the acquired image (e.g. image dimensions, file paths, etc.).</li> <li><code>populate</code> automatically calls <code>make</code> for every key for which the auto-populated table is missing data.</li> <li><code>populate_settings</code> passes arguments to the <code>populate</code> method.</li> <li><code>display_progress=True</code> reports the progress bar</li> </ul>"}, {"location": "tutorials/03-Process/#insert-a-new-entry-into-miniscopeprocessingparamset-for-caiman", "title": "Insert a new entry into <code>miniscope.ProcessingParamSet</code> for CaImAn\u00b6", "text": "<ul> <li><p>Define and insert the parameters that will be used for the CaImAn processing.</p> </li> <li><p>This step is not needed if you are using an existing ProcessingParamSet.</p> </li> </ul>"}, {"location": "tutorials/03-Process/#define-caiman-parameters", "title": "Define CaImAn parameters\u00b6", "text": ""}, {"location": "tutorials/03-Process/#insert-caiman-parameters", "title": "Insert CaImAn parameters\u00b6", "text": "<ul> <li>A method of the class <code>ProcessingParamset</code> called <code>insert_new_params</code> is a helper function to insert the CaImAn parameters and ensures that the parameter set inserted is not duplicated.</li> </ul>"}, {"location": "tutorials/03-Process/#insert-new-processingtask-to-trigger-analysis-and-ingestion-of-motion-correction-and-segmentation-results", "title": "Insert new ProcessingTask to trigger analysis and ingestion of motion correction and segmentation results\u00b6", "text": "<ul> <li><p>Motion correction and segmentation are performed for each recording in CaImAn.</p> </li> <li><p>If <code>task_mode=trigger</code>, this entry will trigger running analysis (i.e. motion correction, segmentation, and traces) within the <code>miniscope.Processing</code> table.</p> </li> <li><p>If the <code>task_mode=load</code> this step ensures that the output directory contains the valid processed outputs.</p> </li> <li><p>The <code>paramset_id</code> is the parameter set stored in <code>miniscope.ProcessingParamSet</code> that is used for the imaging processing.</p> </li> <li><p>The <code>processing_output_dir</code> stores the directory of the processing results (relative to the miniscope root data directory).</p> </li> </ul>"}, {"location": "tutorials/03-Process/#populate-miniscopeprocessing", "title": "Populate <code>miniscope.Processing</code>\u00b6", "text": ""}, {"location": "tutorials/03-Process/#insert-new-curation-following-the-processingtask", "title": "Insert new Curation following the ProcessingTask\u00b6", "text": "<ul> <li><p>The next step in the pipeline is the curation of motion correction and segmentation results.</p> </li> <li><p>If a manual curation was implemented, an entry needs to be manually inserted into the table <code>miniscope.Curation</code>, which specifies the directory to the curated results in <code>curation_output_dir</code>.</p> </li> <li><p>If we would like to use the processed outcome directly, an entry is also needed in <code>miniscope.Curation</code>. A method <code>create1_from_processing_task</code> was provided to help this insertion. It copies the <code>processing_output_dir</code> in <code>miniscope.ProcessingTask</code> to the field <code>curation_output_dir</code> in the table <code>miniscope.Curation</code> with a new <code>curation_id</code>.</p> <ul> <li><p>In this example, we create/insert one <code>miniscope.Curation</code> for each <code>miniscope.ProcessingTask</code>, specifying the same output directory.</p> </li> <li><p>To this end, we could also make use of a convenient function <code>miniscope.Curation().create1_from_processing_task()</code></p> </li> </ul> </li> </ul>"}, {"location": "tutorials/03-Process/#populate-miniscopemotioncorrection", "title": "Populate <code>miniscope.MotionCorrection</code>\u00b6", "text": "<ul> <li>This table contains the rigid or non-rigid motion correction data including the shifts and summary images.</li> </ul>"}, {"location": "tutorials/03-Process/#populate-miniscopesegmentation", "title": "Populate <code>miniscope.Segmentation</code>\u00b6", "text": "<ul> <li>This table contains the mask coordinates, weights, and centers.</li> <li>This table also inserts the data into <code>MaskClassification</code>, which is the classification of the segmented masks and the confidence of classification.</li> </ul>"}, {"location": "tutorials/03-Process/#add-another-set-of-results-from-a-new-round-of-curation", "title": "Add another set of results from a new round of curation\u00b6", "text": "<p>If you performed curation on an existing processed results (i.e. motion correction or segmentation) then:</p> <ul> <li><p>Add an entry into <code>miniscope.Curation</code> with the directory of the curated results and a new <code>curation_id</code>.</p> </li> <li><p>Populate the <code>miniscope.MotionCorrection</code> and <code>miniscope.Segmentation</code> tables again.</p> </li> </ul>"}, {"location": "tutorials/03-Process/#populate-miniscopefluorescence", "title": "Populate <code>miniscope.Fluorescence</code>\u00b6", "text": "<ul> <li>This table contains the fluorescence traces prior to filtering and spike extraction.</li> </ul>"}, {"location": "tutorials/03-Process/#populate-miniscopeactivity", "title": "Populate <code>miniscope.Activity</code>\u00b6", "text": "<ul> <li>This table contains the inferred neural activity from the fluorescence traces.</li> </ul>"}, {"location": "tutorials/03-Process/#next-steps", "title": "Next steps\u00b6", "text": "<ul> <li>Proceed to the 05-explore to learn how to query, fetch, and visualize the imaging data.</li> </ul>"}, {"location": "tutorials/04-Automate_Optional/", "title": "04 Automate Optional", "text": "In\u00a0[1]: Copied! <pre>import os\nfrom pathlib import Path\n\n# change to the upper level folder to detect dj_local_conf.json\nif os.path.basename(os.getcwd()) == \"notebooks\":\n    os.chdir(\"..\")\nfrom workflow_miniscope.pipeline import session, miniscope\nfrom workflow_miniscope import process\n</pre> import os from pathlib import Path  # change to the upper level folder to detect dj_local_conf.json if os.path.basename(os.getcwd()) == \"notebooks\":     os.chdir(\"..\") from workflow_miniscope.pipeline import session, miniscope from workflow_miniscope import process <pre>[2023-01-05 14:40:41,466][WARNING]: lab.Project and related tables will be removed in a future version of Element Lab. Please use the project schema.\n[2023-01-05 14:40:41,529][INFO]: Connecting cbroz@dss-db.datajoint.io:3306\n[2023-01-05 14:40:41,893][INFO]: Connected cbroz@dss-db.datajoint.io:3306\n</pre> <p>We'll be using the <code>process.py</code>'s <code>run</code> function automatically loop through all <code>make</code> functions, as a shortcut for calling each individually.</p> <p>If you previously completed the 03-Process notebook, you may want to delete the contents ingested there, to avoid duplication errors.</p> In\u00a0[3]: Copied! <pre>safemode = True  # Set to false to turn off confirmation prompts\n(session.Session &amp; 'subject=\"subject1\"').delete(safemode=safemode)\ntable_list = [\n    miniscope.RecordingInfo,\n    miniscope.Processing,\n    miniscope.MotionCorrection,\n    miniscope.Segmentation,\n    miniscope.Fluorescence,\n    miniscope.Activity,\n]\nfor table in table_list:\n    table.delete(safemode=safemode)\n</pre> safemode = True  # Set to false to turn off confirmation prompts (session.Session &amp; 'subject=\"subject1\"').delete(safemode=safemode) table_list = [     miniscope.RecordingInfo,     miniscope.Processing,     miniscope.MotionCorrection,     miniscope.Segmentation,     miniscope.Fluorescence,     miniscope.Activity, ] for table in table_list:     table.delete(safemode=safemode) <pre>[2023-01-05 14:42:32,975][INFO]: Deleting 0 rows from `u24_mini_session`.`session`\n[2023-01-05 14:42:33,378][INFO]: Deleting 0 rows from `u24_mini_miniscope`.`_recording_info`\n[2023-01-05 14:42:33,783][INFO]: Deleting 0 rows from `u24_mini_miniscope`.`__processing`\n[2023-01-05 14:42:34,184][INFO]: Deleting 0 rows from `u24_mini_miniscope`.`_motion_correction`\n[2023-01-05 14:42:34,586][INFO]: Deleting 0 rows from `u24_mini_miniscope`.`__segmentation`\n[2023-01-05 14:42:34,988][INFO]: Deleting 0 rows from `u24_mini_miniscope`.`__fluorescence`\n[2023-01-05 14:42:35,396][INFO]: Deleting 0 rows from `u24_mini_miniscope`.`__activity`\n</pre> In\u00a0[4]: Copied! <pre>from workflow_miniscope.ingest import ingest_subjects, ingest_sessions\n\ningest_subjects()\ningest_sessions()\n</pre> from workflow_miniscope.ingest import ingest_subjects, ingest_sessions  ingest_subjects() ingest_sessions() <pre>[2023-01-05 14:43:22,668][INFO]: \n---- Inserting 0 entry(s) into Subject ----\n[2023-01-05 14:43:22,669][INFO]: ---- Insert new `Session` and `Recording` ----\n[2023-01-05 14:43:22,834][INFO]: ---- Inserting 0 entry(s) into reference.Device ----\n[2023-01-05 14:43:23,128][INFO]: ---- Inserting 1 entry(s) into session.Session ----\n[2023-01-05 14:43:23,377][INFO]: ---- Inserting 1 entry(s) into miniscope.Recording ----\n[2023-01-05 14:43:23,379][INFO]: ---- Successfully completed ingest_sessions ----\n</pre> In\u00a0[7]: Copied! <pre>params_caiman = dict(\n    decay_time=0.4,\n    pw_rigid=False,\n    max_shifts=(5, 5),\n    gSig_filt=(3, 3),\n    strides=(48, 48),\n    overlaps=(24, 24),\n    max_deviation_rigid=3,\n    border_nan=\"copy\",\n    method_init=\"corr_pnr\",\n    K=None,\n    gSig=(3, 3),\n    gSiz=(13, 13),\n    merge_thr=0.7,\n    p=1,\n    tsub=2,\n    ssub=1,\n    rf=40,\n    stride=20,\n    only_init=True,\n    nb=0,\n    nb_patch=0,\n    method_deconvolution=\"oasis\",\n    low_rank_background=None,\n    update_background_components=True,\n    min_corr=0.8,\n    min_pnr=10,\n    normalize_init=False,\n    center_psf=True,\n    ssub_B=2,\n    ring_size_factor=1.4,\n    del_duplicates=True,\n    border_pix=0,\n    min_SNR=3,\n    rval_thr=0.85,\n    use_cnn=False,\n)\n\nparams_dict = dict(\n    processing_method=\"caiman\",\n    paramset_id=0,  # Change ID if changing parameters\n    paramset_desc=\"Calcium imaging analysis with CaImAn using default parameters\",\n    params=params_caiman,\n)\n\nminiscope.ProcessingParamSet.insert_new_params(**params_dict)\n</pre> params_caiman = dict(     decay_time=0.4,     pw_rigid=False,     max_shifts=(5, 5),     gSig_filt=(3, 3),     strides=(48, 48),     overlaps=(24, 24),     max_deviation_rigid=3,     border_nan=\"copy\",     method_init=\"corr_pnr\",     K=None,     gSig=(3, 3),     gSiz=(13, 13),     merge_thr=0.7,     p=1,     tsub=2,     ssub=1,     rf=40,     stride=20,     only_init=True,     nb=0,     nb_patch=0,     method_deconvolution=\"oasis\",     low_rank_background=None,     update_background_components=True,     min_corr=0.8,     min_pnr=10,     normalize_init=False,     center_psf=True,     ssub_B=2,     ring_size_factor=1.4,     del_duplicates=True,     border_pix=0,     min_SNR=3,     rval_thr=0.85,     use_cnn=False, )  params_dict = dict(     processing_method=\"caiman\",     paramset_id=0,  # Change ID if changing parameters     paramset_desc=\"Calcium imaging analysis with CaImAn using default parameters\",     params=params_caiman, )  miniscope.ProcessingParamSet.insert_new_params(**params_dict) <ul> <li><p>The <code>process.run()</code> function in the workflow populates every auto-processing table in the workflow. If a table is dependent on a manual table upstream, it will not get populated until the manual table is inserted.</p> </li> <li><p>At this stage, process script populates through the table upstream of <code>ProcessingTask</code> (i.e. <code>RecordingInfo</code>)</p> </li> </ul> In\u00a0[5]: Copied! <pre>process.run()\n</pre> process.run() <pre>[2023-01-05 14:44:40,146][INFO]: ---- Populating RecordingInfo ----\nRecordingInfo: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1/1 [00:00&lt;00:00,  1.05it/s]\n[2023-01-05 14:44:41,759][INFO]: ---- Populating Processing ----\n[2023-01-05 14:44:42,074][INFO]: ---- Populating MotionCorrection ----\n[2023-01-05 14:44:42,366][INFO]: ---- Populating Segmentation ----\n[2023-01-05 14:44:42,666][INFO]: ---- Populating Fluorescence ----\n[2023-01-05 14:44:42,953][INFO]: ---- Populating Activity ----\n[2023-01-05 14:44:43,246][INFO]: ---- Successfully completed miniscope/populate.py ----\n</pre> <p>We can then add a processing task as a combination of a scan key, processing parameters, and an output directory.</p> In\u00a0[8]: Copied! <pre>from element_interface.utils import find_full_path\nfrom workflow_miniscope.pipeline import get_miniscope_root_data_dir\n\nscan_key = (session.Session * miniscope.Recording).fetch(\"KEY\", limit=1)[0]\n\nscan_file = find_full_path(\n    get_miniscope_root_data_dir(),\n    (miniscope.RecordingInfo.File &amp; scan_key).fetch(\"file_path\", limit=1)[0],\n)\ncaiman_dir = Path(scan_file.parent / \"caiman\")\nminiscope.ProcessingTask.insert1(\n    {**scan_key, \"paramset_id\": 0, \"processing_output_dir\": caiman_dir}\n)\n</pre> from element_interface.utils import find_full_path from workflow_miniscope.pipeline import get_miniscope_root_data_dir  scan_key = (session.Session * miniscope.Recording).fetch(\"KEY\", limit=1)[0]  scan_file = find_full_path(     get_miniscope_root_data_dir(),     (miniscope.RecordingInfo.File &amp; scan_key).fetch(\"file_path\", limit=1)[0], ) caiman_dir = Path(scan_file.parent / \"caiman\") miniscope.ProcessingTask.insert1(     {**scan_key, \"paramset_id\": 0, \"processing_output_dir\": caiman_dir} ) <p>And trigger the processing</p> In\u00a0[9]: Copied! <pre>process.run()\n</pre> process.run() <pre>[2023-01-05 14:52:27,650][INFO]: ---- Populating RecordingInfo ----\n[2023-01-05 14:52:27,819][INFO]: ---- Populating Processing ----\nProcessing: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1/1 [00:06&lt;00:00,  6.69s/it]\n[2023-01-05 14:52:34,673][INFO]: ---- Populating MotionCorrection ----\nINFO:datajoint:---- Populating MotionCorrection ----\n[2023-01-05 14:52:34,835][INFO]: ---- Populating Segmentation ----\nINFO:datajoint:---- Populating Segmentation ----\n[2023-01-05 14:52:34,995][INFO]: ---- Populating Fluorescence ----\nINFO:datajoint:---- Populating Fluorescence ----\n[2023-01-05 14:52:35,159][INFO]: ---- Populating Activity ----\nINFO:datajoint:---- Populating Activity ----\n[2023-01-05 14:52:35,201][INFO]: ---- Successfully completed miniscope/populate.py ----\nINFO:datajoint:---- Successfully completed miniscope/populate.py ----\n</pre> <p>Next, we would select one of the results at the curation table.</p> In\u00a0[12]: Copied! <pre>key = miniscope.Processing.fetch(\"KEY\")[0]\nminiscope.Curation.create1_from_processing_task(key)\n</pre> key = miniscope.Processing.fetch(\"KEY\")[0] miniscope.Curation.create1_from_processing_task(key) <p>And then we can continue processing.</p> In\u00a0[13]: Copied! <pre>process.run()\n</pre> process.run() <pre>[2023-01-05 14:57:55,980][INFO]: ---- Populating RecordingInfo ----\nINFO:datajoint:---- Populating RecordingInfo ----\n[2023-01-05 14:57:56,147][INFO]: ---- Populating Processing ----\nINFO:datajoint:---- Populating Processing ----\n[2023-01-05 14:57:56,314][INFO]: ---- Populating MotionCorrection ----\nINFO:datajoint:---- Populating MotionCorrection ----\nMotionCorrection: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1/1 [00:01&lt;00:00,  1.65s/it]\n[2023-01-05 14:57:58,128][INFO]: ---- Populating Segmentation ----\nINFO:datajoint:---- Populating Segmentation ----\nSegmentation:   0%|          | 0/1 [00:00&lt;?, ?it/s][2023-01-05 14:57:58,721][WARNING]: Could not load all pixel values for at least one mask\nWARNING:datajoint:Could not load all pixel values for at least one mask\nSegmentation: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1/1 [00:01&lt;00:00,  1.10s/it]\n[2023-01-05 14:57:59,392][INFO]: ---- Populating Fluorescence ----\nINFO:datajoint:---- Populating Fluorescence ----\nFluorescence: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1/1 [00:01&lt;00:00,  1.15s/it]\n[2023-01-05 14:58:00,711][INFO]: ---- Populating Activity ----\nINFO:datajoint:---- Populating Activity ----\nActivity: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 2/2 [00:01&lt;00:00,  1.24it/s]\n[2023-01-05 14:58:02,362][INFO]: ---- Successfully completed miniscope/populate.py ----\nINFO:datajoint:---- Successfully completed miniscope/populate.py ----\n</pre>"}, {"location": "tutorials/04-Automate_Optional/#datajoint-u24-workflow-miniscope", "title": "DataJoint U24 - Workflow Miniscope\u00b6", "text": ""}, {"location": "tutorials/04-Automate_Optional/#workflow-automation", "title": "Workflow Automation\u00b6", "text": "<p>In the previous notebook 03-Process, we ran through the workflow in detailed steps, manually adding each. The current notebook provides a more automated approach.</p> <p>The commands here run a workflow using example data from the 00-DownloadData notebook, but note where placeholders could be changed for a different dataset.</p>"}, {"location": "tutorials/04-Automate_Optional/#ingestion-of-subjects-sessions", "title": "Ingestion of subjects, sessions\u00b6", "text": "<p>Refer to the <code>user_data</code> folder in the workflow. Fill subject and session information in files <code>subjects.csv</code> and <code>sessions.csv</code>. We can then use corresponding functions below to automatically ingest subject and session metadata.</p>"}, {"location": "tutorials/04-Automate_Optional/#insert-new-processingparamset-for-caiman", "title": "Insert new ProcessingParamSet for CaImAn\u00b6", "text": "<p>This is not needed if you are using an existing ProcessingParamSet.</p>"}, {"location": "tutorials/04-Automate_Optional/#trigger-autoprocessing-of-the-remaining-calcium-imaging-workflow", "title": "Trigger autoprocessing of the remaining calcium imaging workflow\u00b6", "text": ""}, {"location": "tutorials/04-Automate_Optional/#summary-and-next-step", "title": "Summary and next step\u00b6", "text": "<ul> <li><p>This notebook runs through the workflow in an automatic manner.</p> </li> <li><p>The next notebook 05-Explore discussed the role of each table in more depth.</p> </li> </ul>"}, {"location": "tutorials/05-Explore/", "title": "05 Explore", "text": "In\u00a0[1]: Copied! <pre>import os\n\nos.chdir(\"..\")\n</pre> import os  os.chdir(\"..\") In\u00a0[\u00a0]: Copied! <pre>import datajoint as dj\nimport matplotlib.pyplot as plt\nimport numpy as np\n\nfrom workflow_miniscope.pipeline import subject, session, miniscope\n</pre> import datajoint as dj import matplotlib.pyplot as plt import numpy as np  from workflow_miniscope.pipeline import subject, session, miniscope In\u00a0[\u00a0]: Copied! <pre>dj.Diagram(miniscope) + (dj.Diagram(session.Session) + 1) - 1\n</pre> dj.Diagram(miniscope) + (dj.Diagram(session.Session) + 1) - 1 In\u00a0[4]: Copied! <pre>subject.Subject()\n</pre> subject.Subject() Out[4]: Animal Subject <p>subject</p> <p>sex</p> <p>subject_birth_date</p> <p>subject_description</p> subject1 M 2021-01-01 Theosubject6 M 2020-01-01 manuel <p>Total: 2</p> In\u00a0[5]: Copied! <pre>session.Session()\n</pre> session.Session() Out[5]: <p>subject</p> <p>session_datetime</p> subject1 2021-01-01 00:00:01subject1 2022-04-27 12:13:01subject6 2021-06-01 13:33:33subject6 2021-06-02 14:04:22 <p>Total: 4</p> <ul> <li>Fetch the primary key for the session of interest which will be used later on in this notebook.</li> </ul> In\u00a0[9]: Copied! <pre>session_key = (\n    session.Session\n    &amp; 'subject = \"subject1\"'\n    &amp; 'session_datetime = \"2021-01-01 00:00:01\"'\n).fetch1(\"KEY\")\n</pre> session_key = (     session.Session     &amp; 'subject = \"subject1\"'     &amp; 'session_datetime = \"2021-01-01 00:00:01\"' ).fetch1(\"KEY\") In\u00a0[10]: Copied! <pre>miniscope.Recording &amp; session_key\n</pre> miniscope.Recording &amp; session_key Out[10]: <p>subject</p> <p>session_datetime</p> <p>recording_id</p> <p>equipment</p> <p>acquisition_software</p> <p>recording_directory</p> relative to root data directory <p>recording_notes</p> free-notes subject1 2021-01-01 00:00:01 0 UCLA Miniscope Miniscope-DAQ-V4 subject1/session1 No notes for this session. <p>Total: 1</p> In\u00a0[11]: Copied! <pre>miniscope.RecordingInfo &amp; session_key\n</pre> miniscope.RecordingInfo &amp; session_key Out[11]: Store metadata about recording <p>subject</p> <p>session_datetime</p> <p>recording_id</p> <p>nchannels</p> number of channels <p>nframes</p> number of recorded frames <p>px_height</p> height in pixels <p>px_width</p> width in pixels <p>um_height</p> height in microns <p>um_width</p> width in microns <p>fps</p> (Hz) frames per second <p>gain</p> recording gain <p>spatial_downsample</p> e.g. 1, 2, 4, 8. 1 for no downsampling <p>led_power</p> LED power used in the given recording <p>time_stamps</p> time stamps of each frame <p>recording_datetime</p> datetime of the recording <p>recording_duration</p> (seconds) duration of the recording subject1 2021-01-01 00:00:01 0 1 111770 600 600 nan nan 20.0 2.0 1 5.0 =BLOB= None 5588.5 <p>Total: 1</p> In\u00a0[13]: Copied! <pre>miniscope.RecordingInfo.File &amp; session_key\n</pre> miniscope.RecordingInfo.File &amp; session_key Out[13]: <p>subject</p> <p>session_datetime</p> <p>recording_id</p> <p>file_id</p> <p>file_path</p> relative to root data directory subject1 2021-01-01 00:00:01 0 0 subject1/session1/0.avi <p>Total: 1</p> In\u00a0[14]: Copied! <pre>miniscope.ProcessingParamSet()\n</pre> miniscope.ProcessingParamSet() Out[14]: Parameter set used for processing of miniscope data <p>paramset_id</p> <p>processing_method</p> <p>paramset_desc</p> <p>param_set_hash</p> <p>params</p> dictionary of all applicable parameters 0 caiman Calcium imaging analysis with CaImAn using default parameters 7ebfca75-7997-82ce-c46b-f0cc28f69308 =BLOB= <p>Total: 1</p> In\u00a0[16]: Copied! <pre>miniscope.ProcessingTask * miniscope.Processing &amp; session_key\n</pre> miniscope.ProcessingTask * miniscope.Processing &amp; session_key Out[16]: <p>subject</p> <p>session_datetime</p> <p>recording_id</p> <p>paramset_id</p> <p>processing_output_dir</p> relative to the root data directory <p>task_mode</p> 'load': load existing results <p>processing_time</p> generation time of processed, segmented results <p>package_version</p> subject1 2021-01-01 00:00:01 0 0 subject1/session1/caiman load 2022-04-27 12:13:32 <p>Total: 1</p> <p>In this example workflow, <code>curation_output_dir</code> is the same as the <code>processing_output_dir</code>, as these results were not manually curated.</p> In\u00a0[17]: Copied! <pre>miniscope.Curation &amp; session_key\n</pre> miniscope.Curation &amp; session_key Out[17]: Different rounds of curation performed on the processing results of the data <p>subject</p> <p>session_datetime</p> <p>recording_id</p> <p>paramset_id</p> <p>curation_id</p> <p>curation_time</p> time of generation of these curated results <p>curation_output_dir</p> output directory of the curated results, <p>manual_curation</p> has manual curation been performed? <p>curation_note</p> subject1 2021-01-01 00:00:01 0 0 0 2022-04-30 12:22:15 subject1/session1/caiman 0 <p>Total: 1</p> In\u00a0[18]: Copied! <pre>curation_key = (miniscope.Curation &amp; session_key &amp; \"curation_id=0\").fetch1(\"KEY\")\n</pre> curation_key = (miniscope.Curation &amp; session_key &amp; \"curation_id=0\").fetch1(\"KEY\") In\u00a0[19]: Copied! <pre>curation_key\n</pre> curation_key Out[19]: <pre>{'subject': 'subject1',\n 'session_datetime': datetime.datetime(2021, 1, 1, 0, 0, 1),\n 'recording_id': 0,\n 'paramset_id': 0,\n 'curation_id': 0}</pre> In\u00a0[20]: Copied! <pre>miniscope.MotionCorrection.RigidMotionCorrection &amp; curation_key\n</pre> miniscope.MotionCorrection.RigidMotionCorrection &amp; curation_key Out[20]: <p>subject</p> <p>session_datetime</p> <p>recording_id</p> <p>paramset_id</p> <p>curation_id</p> <p>outlier_frames</p> mask with true for frames with outlier shifts <p>y_shifts</p> (pixels) y motion correction shifts <p>x_shifts</p> (pixels) x motion correction shifts <p>y_std</p> (pixels) standard deviation of <p>x_std</p> (pixels) standard deviation of subject1 2021-01-01 00:00:01 0 0 0 =BLOB= =BLOB= =BLOB= 0.0561964 0.0570838 <p>Total: 1</p> In\u00a0[\u00a0]: Copied! <pre>miniscope.MotionCorrection.NonRigidMotionCorrection &amp; curation_key\n</pre> miniscope.MotionCorrection.NonRigidMotionCorrection &amp; curation_key <ul> <li>For non-rigid motion correction, the details for the individual blocks are stored in <code>imaging.MotionCorrection.Block</code>.</li> </ul> In\u00a0[\u00a0]: Copied! <pre>miniscope.MotionCorrection.Block &amp; curation_key &amp; \"block_id=0\"\n</pre> miniscope.MotionCorrection.Block &amp; curation_key &amp; \"block_id=0\" <ul> <li><p>Summary images are stored in <code>imaging.MotionCorrection.Summary</code></p> <ul> <li><p>Reference image - image used as an alignment template</p> </li> <li><p>Average image - mean of registered frames</p> </li> <li><p>Correlation image - correlation map (computed during region of interest [ROI] detection)</p> </li> <li><p>Maximum projection image - max of registered frames</p> </li> </ul> </li> </ul> In\u00a0[24]: Copied! <pre>miniscope.MotionCorrection.Summary &amp; curation_key\n</pre> miniscope.MotionCorrection.Summary &amp; curation_key Out[24]: summary images for each field and channel after corrections <p>subject</p> <p>session_datetime</p> <p>recording_id</p> <p>paramset_id</p> <p>curation_id</p> <p>ref_image</p> image used as alignment template <p>average_image</p> mean of registered frames <p>correlation_image</p> correlation map <p>max_proj_image</p> max of registered frames subject1 2021-01-01 00:00:01 0 0 0 =BLOB= =BLOB= =BLOB= =BLOB= <p>Total: 1</p> <ul> <li>Lets fetch the <code>average_image</code> and plot it.</li> </ul> In\u00a0[31]: Copied! <pre>average_image = (\n    (miniscope.MotionCorrection.Summary &amp; curation_key)\n    .fetch1(\"average_image\")\n    .reshape(600, 600, 1)\n)\n</pre> average_image = (     (miniscope.MotionCorrection.Summary &amp; curation_key)     .fetch1(\"average_image\")     .reshape(600, 600, 1) ) In\u00a0[32]: Copied! <pre>plt.imshow(average_image);\n</pre> plt.imshow(average_image); In\u00a0[29]: Copied! <pre>mask_xpix, mask_ypix = (\n    miniscope.Segmentation.Mask * miniscope.MaskClassification.MaskType\n    &amp; curation_key\n    &amp; \"mask_npix &gt; 130\"\n).fetch(\"mask_xpix\", \"mask_ypix\")\n</pre> mask_xpix, mask_ypix = (     miniscope.Segmentation.Mask * miniscope.MaskClassification.MaskType     &amp; curation_key     &amp; \"mask_npix &gt; 130\" ).fetch(\"mask_xpix\", \"mask_ypix\") In\u00a0[33]: Copied! <pre>mask_image = np.zeros(np.shape(average_image), dtype=bool)\nfor xpix, ypix in zip(mask_xpix, mask_ypix):\n    mask_image[ypix, xpix] = True\n</pre> mask_image = np.zeros(np.shape(average_image), dtype=bool) for xpix, ypix in zip(mask_xpix, mask_ypix):     mask_image[ypix, xpix] = True In\u00a0[38]: Copied! <pre>plt.imshow(average_image)\nplt.contour(mask_image.reshape(600, 600), colors=\"white\", linewidths=0.5);\n</pre> plt.imshow(average_image) plt.contour(mask_image.reshape(600, 600), colors=\"white\", linewidths=0.5); In\u00a0[41]: Copied! <pre>miniscope.MaskClassification.MaskType &amp; curation_key &amp; \"mask_id=13\"\n</pre> miniscope.MaskClassification.MaskType &amp; curation_key &amp; \"mask_id=13\" Out[41]: <p>subject</p> <p>session_datetime</p> <p>recording_id</p> <p>paramset_id</p> <p>curation_id</p> <p>mask_classification_method</p> <p>mask_id</p> <p>mask_type</p> <p>confidence</p> subject1 2021-01-01 00:00:01 0 0 0 caiman_default_classifier 13 soma nan <p>Total: 1</p> In\u00a0[42]: Copied! <pre>query_cells = (\n    miniscope.Segmentation.Mask * miniscope.MaskClassification.MaskType\n    &amp; curation_key\n    &amp; \"mask_npix &gt; 130\"\n).proj()\n</pre> query_cells = (     miniscope.Segmentation.Mask * miniscope.MaskClassification.MaskType     &amp; curation_key     &amp; \"mask_npix &gt; 130\" ).proj() In\u00a0[44]: Copied! <pre>fluorescence_traces = (miniscope.Fluorescence.Trace &amp; query_cells).fetch(\n    \"fluorescence\", order_by=\"mask_id\"\n)\n\nactivity_traces = (miniscope.Activity.Trace &amp; query_cells).fetch(\n    \"activity_trace\", order_by=\"mask_id\"\n)\n\nsampling_rate = (miniscope.RecordingInfo &amp; curation_key).fetch1(\"fps\")  # [Hz]\n</pre> fluorescence_traces = (miniscope.Fluorescence.Trace &amp; query_cells).fetch(     \"fluorescence\", order_by=\"mask_id\" )  activity_traces = (miniscope.Activity.Trace &amp; query_cells).fetch(     \"activity_trace\", order_by=\"mask_id\" )  sampling_rate = (miniscope.RecordingInfo &amp; curation_key).fetch1(\"fps\")  # [Hz] In\u00a0[45]: Copied! <pre>fig, ax = plt.subplots(1, 1, figsize=(16, 4))\nax2 = ax.twinx()\n\nfor f, a in zip(fluorescence_traces, activity_traces):\n    ax.plot(np.r_[: f.size] * 1 / sampling_rate, f, \"k\", label=\"fluorescence trace\")\n    ax2.plot(\n        np.r_[: a.size] * 1 / sampling_rate,\n        a,\n        \"r\",\n        alpha=0.5,\n        label=\"deconvolved trace\",\n    )\n\n    break\n\nax.tick_params(labelsize=14)\nax2.tick_params(labelsize=14)\n\nax.legend(loc=\"upper left\", prop={\"size\": 14})\nax2.legend(loc=\"upper right\", prop={\"size\": 14})\n\nax.set_xlabel(\"Time (s)\")\nax.set_ylabel(\"Activity (a.u.)\")\nax2.set_ylabel(\"Activity (a.u.)\");\n</pre> fig, ax = plt.subplots(1, 1, figsize=(16, 4)) ax2 = ax.twinx()  for f, a in zip(fluorescence_traces, activity_traces):     ax.plot(np.r_[: f.size] * 1 / sampling_rate, f, \"k\", label=\"fluorescence trace\")     ax2.plot(         np.r_[: a.size] * 1 / sampling_rate,         a,         \"r\",         alpha=0.5,         label=\"deconvolved trace\",     )      break  ax.tick_params(labelsize=14) ax2.tick_params(labelsize=14)  ax.legend(loc=\"upper left\", prop={\"size\": 14}) ax2.legend(loc=\"upper right\", prop={\"size\": 14})  ax.set_xlabel(\"Time (s)\") ax.set_ylabel(\"Activity (a.u.)\") ax2.set_ylabel(\"Activity (a.u.)\");"}, {"location": "tutorials/05-Explore/#datajoint-workflow-miniscope", "title": "DataJoint Workflow Miniscope\u00b6", "text": "<ul> <li>This notebook will describe the steps for interacting with the data ingested into <code>workflow-miniscope</code>.</li> </ul>"}, {"location": "tutorials/05-Explore/#workflow-architecture", "title": "Workflow architecture\u00b6", "text": "<p>This workflow is assembled from 4 DataJoint elements:</p> <ul> <li>element-lab</li> <li>element-animal</li> <li>element-session</li> <li>element-miniscope</li> </ul> <p>For the architecture and detailed descriptions for each of those elements, please visit the respective links.</p> <p>Below is the diagram describing the core components of the fully assembled pipeline.</p>"}, {"location": "tutorials/05-Explore/#browsing-the-data-with-datajoint-query-and-fetch", "title": "Browsing the data with DataJoint <code>query</code> and <code>fetch</code>\u00b6", "text": "<ul> <li><p>DataJoint provides functions to query data and fetch.  For detailed tutorials, visit our general tutorial site.</p> </li> <li><p>Running through the pipeline, we have ingested data of subject3 into the database.</p> </li> <li><p>Here are some highlights of the important tables.</p> </li> </ul>"}, {"location": "tutorials/05-Explore/#subject-and-session-tables", "title": "<code>Subject</code> and <code>Session</code> tables\u00b6", "text": ""}, {"location": "tutorials/05-Explore/#recording-and-recordinginfo-tables", "title": "<code>Recording</code> and <code>RecordingInfo</code> tables\u00b6", "text": "<ul> <li>These tables stores the recording metadata within a particular session.</li> </ul>"}, {"location": "tutorials/05-Explore/#processingparamset-processingtask-processing-and-curation-tables", "title": "<code>ProcessingParamSet</code>, <code>ProcessingTask</code>, <code>Processing</code>, and <code>Curation</code> tables\u00b6", "text": "<ul> <li><p>The parameters used for CaImAn are stored in <code>miniscope.ProcessingParamSet</code> under a <code>paramset_idx</code>.</p> </li> <li><p>The processing details for CaImAn are stored in <code>miniscope.ProcessingTask</code> and <code>miniscope.Processing</code> for the utilized <code>paramset_idx</code>.</p> </li> <li><p>After the motion correction and segmentation, the results may go through a curation process.</p> <ul> <li><p>If it did not go through curation, a copy of the <code>miniscope.ProcessingTask</code> entry is inserted into <code>miniscope.Curation</code> with the <code>curation_output_dir</code> identical to the <code>processing_output_dir</code>.</p> </li> <li><p>If it did go through a curation, a new entry will be inserted into <code>miniscope.Curation</code>, with a <code>curation_output_dir</code> specified.</p> </li> <li><p><code>miniscope.Curation</code> supports multiple curations of an entry in <code>miniscope.ProcessingTask</code>.</p> </li> </ul> </li> </ul>"}, {"location": "tutorials/05-Explore/#motioncorrection-table", "title": "<code>MotionCorrection</code> table\u00b6", "text": "<ul> <li><p>After processing and curation, results are passed to the <code>miniscope.MotionCorrection</code> and <code>miniscope.Segmentation</code> tables.</p> </li> <li><p>For the example data, the raw data is corrected with rigid and non-rigid motion correction which is stored in <code>miniscope.MotionCorrection.RigidMotionCorrection</code> and <code>miniscope.MotionCorrection.NonRigidMotionCorrection</code>, respectively.</p> </li> <li><p>Lets first query the information for one curation.</p> </li> </ul>"}, {"location": "tutorials/05-Explore/#segmentation-table", "title": "<code>Segmentation</code> table\u00b6", "text": "<ul> <li><p>Lets fetch and plot a mask stored in the <code>miniscope.Segmentation.Mask</code> table for one <code>curation_id</code>.</p> </li> <li><p>Each mask can be associated with a field by the attribute <code>mask_center_z</code>.  For example, masks with <code>mask_center_z=0</code> are in the field identified with <code>field_idx=0</code> in <code>miniscope.RecordingInfo</code>.</p> </li> </ul>"}, {"location": "tutorials/05-Explore/#maskclassification-table", "title": "<code>MaskClassification</code> table\u00b6", "text": "<ul> <li>This table provides the <code>mask_type</code> and <code>confidence</code> for the mask classification.</li> </ul>"}, {"location": "tutorials/05-Explore/#fluorescence-and-activity-tables", "title": "<code>Fluorescence</code> and <code>Activity</code> tables\u00b6", "text": "<ul> <li>Lets fetch and plot the fluorescence and activity traces for one mask.</li> </ul>"}, {"location": "tutorials/05-Explore/#summary-and-next-step", "title": "Summary and Next Step\u00b6", "text": "<ul> <li><p>This notebook highlights the major tables in the workflow and visualize some of the ingested results.</p> </li> <li><p>The next notebook 06-drop shows how to drop schemas and tables if needed.</p> </li> </ul>"}, {"location": "tutorials/06-Drop_Optional/", "title": "06 Drop Optional", "text": "<p>Change into the parent directory to find the <code>dj_local_conf.json</code> file.</p> In\u00a0[\u00a0]: Copied! <pre>import os\n\nif os.path.basename(os.getcwd()) == \"notebooks\":\n    os.chdir(\"..\")\n</pre> import os  if os.path.basename(os.getcwd()) == \"notebooks\":     os.chdir(\"..\") In\u00a0[\u00a0]: Copied! <pre>from workflow_miniscope.pipeline import lab, subject, session, miniscope\n</pre> from workflow_miniscope.pipeline import lab, subject, session, miniscope In\u00a0[\u00a0]: Copied! <pre>miniscope.schema.drop()\nsession.schema.drop()\nsubject.schema.drop()\nlab.schema.drop()\n</pre> miniscope.schema.drop() session.schema.drop() subject.schema.drop() lab.schema.drop()"}, {"location": "tutorials/06-Drop_Optional/#drop-schemas", "title": "Drop schemas\u00b6", "text": "<ul> <li>Schemas are not typically dropped in a production workflow with real data in it.</li> <li>At the developmental phase, it might be required for the table redesign.</li> <li>When dropping all schemas is needed, the following is the dependency order.</li> </ul>"}, {"location": "tutorials/07-DownstreamAnalysis_Optional/", "title": "07 DownstreamAnalysis Optional", "text": "<p>First, let's change directories to find the <code>dj_local_conf</code> file.</p> In\u00a0[1]: Copied! <pre>import os\n\n# change to the upper level folder to detect dj_local_conf.json\nif os.path.basename(os.getcwd()) == \"notebooks\":\n    os.chdir(\"..\")\nassert (\n    os.path.basename(os.getcwd()) == \"workflow-miniscope\"\n), \"Please move to the workflow directory\"\n# We'll be working with long tables, so we'll make visualization easier with a limit\nimport datajoint as dj\n\ndj.config[\"display.limit\"] = 10\n</pre> import os  # change to the upper level folder to detect dj_local_conf.json if os.path.basename(os.getcwd()) == \"notebooks\":     os.chdir(\"..\") assert (     os.path.basename(os.getcwd()) == \"workflow-miniscope\" ), \"Please move to the workflow directory\" # We'll be working with long tables, so we'll make visualization easier with a limit import datajoint as dj  dj.config[\"display.limit\"] = 10 <p>Next, we populate the python namespace with the required schemas</p> In\u00a0[2]: Copied! <pre>from workflow_miniscope.pipeline import miniscope, trial, event\n</pre> from workflow_miniscope.pipeline import miniscope, trial, event <pre>Connecting cbroz@dss-db.datajoint.io:3306\n</pre> <p>Tables in the <code>trial</code> and <code>event</code> schemas specify the structure of your experiment, including block, trial and event timing.</p> <ul> <li>Session has a 1-to-1 mapping with a behavior recording</li> <li>A block is a continuous phase of an experiment that contains repeated instances of a condition, or trials.</li> <li>Events may occur within or outside of conditions, either instantaneous or continuous.</li> </ul> <p>The diagram below shows (a) the levels of hierarchy and (b) how the bounds may not completely overlap. A block may not fully capture trials and events may occur outside both blocks/trials.</p> <pre><code>|----------------------------------------------------------------------------|\n|-------------------------------- Session ---------------------------------|__\n|-------------------------- BehaviorRecording ---------------------------|____\n|----- Block 1 -----|______|----- Block 2 -----|______|----- Block 3 -----|___\n| trial 1 || trial 2 |____| trial 3 || trial 4 |____| trial 5 |____| trial 6 |\n|_|e1|_|e2||e3|_|e4|__|e5|__|e6||e7||e8||e9||e10||e11|____|e12||e13|_________|\n|----------------------------------------------------------------------------|\n</code></pre> <p>Let's load some example data. The <code>ingest.py</code> script has a series of loaders to help. If you've already run the other notebooks, you might skip <code>ingest_subjects</code> and <code>ingest_sessions</code>.</p> In\u00a0[3]: Copied! <pre>from workflow_miniscope.ingest import (\n    ingest_subjects,\n    ingest_sessions,\n    ingest_events,\n    ingest_alignment,\n)\n</pre> from workflow_miniscope.ingest import (     ingest_subjects,     ingest_sessions,     ingest_events,     ingest_alignment, ) <p>If you've already run previous notebooks, no need to ingest subjects or sessions.</p> In\u00a0[4]: Copied! <pre>ingest_subjects()\ningest_sessions()\ningest_events()\n</pre> ingest_subjects() ingest_sessions() ingest_events() <pre>\n---- Inserting 0 entry(s) into behavior_recording ----\n\n---- Inserting 0 entry(s) into behavior_recording__file ----\n\n---- Inserting 2 entry(s) into _block ----\n\n---- Inserting 2 entry(s) into _block__attribute ----\n\n---- Inserting 0 entry(s) into #trial_type ----\n\n---- Inserting 50 entry(s) into _trial ----\n\n---- Inserting 50 entry(s) into _trial__attribute ----\n\n---- Inserting 50 entry(s) into _block_trial ----\n\n---- Inserting 0 entry(s) into #event_type ----\n\n---- Inserting 77 entry(s) into _event ----\n\n---- Inserting 77 entry(s) into _trial_event ----\n</pre> <p>We have 50 total trials, either 'stim' or 'ctrl', with start and stop time</p> In\u00a0[6]: Copied! <pre>trial.Trial() &amp; \"subject='subject1'\"\n</pre> trial.Trial() &amp; \"subject='subject1'\" Out[6]: Experimental trials <p>subject</p> <p>session_datetime</p> <p>trial_id</p> trial number (1-based indexing) <p>trial_type</p> <p>trial_start_time</p> (second) relative to recording start <p>trial_stop_time</p> (second) relative to recording start subject1 2021-01-01 00:00:01 1 stim 0.193 1.057subject1 2021-01-01 00:00:01 2 ctrl 1.468 2.332subject1 2021-01-01 00:00:01 3 ctrl 2.662 3.526subject1 2021-01-01 00:00:01 4 ctrl 3.738 4.602subject1 2021-01-01 00:00:01 5 stim 4.826 5.69subject1 2021-01-01 00:00:01 6 stim 5.973 6.837subject1 2021-01-01 00:00:01 7 ctrl 7.252 8.116subject1 2021-01-01 00:00:01 8 ctrl 8.462 9.326subject1 2021-01-01 00:00:01 9 ctrl 9.731 10.595subject1 2021-01-01 00:00:01 10 stim 11.019 11.883 <p>...</p> <p>Total: 50</p> <p>Each trial is paired with one or more events that take place during the trial window.</p> In\u00a0[7]: Copied! <pre>trial.TrialEvent() &amp; \"trial_id&lt;5\" &amp; \"subject='subject1'\"\n</pre> trial.TrialEvent() &amp; \"trial_id&lt;5\" &amp; \"subject='subject1'\" Out[7]: <p>subject</p> <p>session_datetime</p> <p>trial_id</p> trial number (1-based indexing) <p>event_type</p> <p>event_start_time</p> (second) relative to recording start subject1 2021-01-01 00:00:01 1 left 0.407subject1 2021-01-01 00:00:01 1 right 0.269subject1 2021-01-01 00:00:01 2 center 1.611subject1 2021-01-01 00:00:01 2 center 1.649subject1 2021-01-01 00:00:01 3 left 2.777subject1 2021-01-01 00:00:01 3 left 2.935subject1 2021-01-01 00:00:01 4 right 4.006 <p>Total: 7</p> <p>Finally, the <code>AlignmentEvent</code> describes the event of interest and the window we'd like to see around it.</p> In\u00a0[7]: Copied! <pre>ingest_alignment()\n</pre> ingest_alignment() <pre>\n---- Inserting 3 entry(s) into alignment_event ----\n</pre> In\u00a0[8]: Copied! <pre>event.AlignmentEvent()\n</pre> event.AlignmentEvent() Out[8]: time_shift is seconds to shift with respect to (WRT) a variable <p>alignment_name</p> <p>alignment_description</p> <p>alignment_event_type</p> <p>alignment_time_shift</p> (s) WRT alignment_event_type <p>start_event_type</p> <p>start_time_shift</p> (s) WRT start_event_type <p>end_event_type</p> <p>end_time_shift</p> (s) WRT end_event_type center_button center 0.0 center -5.0 center 5.0left_button left 0.0 left -5.0 left 5.0right_button right 0.0 right -5.0 right 5.0 <p>Total: 3</p> In\u00a0[3]: Copied! <pre>from workflow_miniscope import analysis\n</pre> from workflow_miniscope import analysis <p>The <code>analysis</code> schema provides example tables to perform event-aligned Calcium activity analysis.</p> <ul> <li>ActivityAlignmentCondition - a manual table to specify the inputs and condition for the analysis</li> <li>ActivityAlignment - a computed table to extract event-aligned Calcium activity (e.g. dF/F, spikes)</li> </ul> <p>Let's start by creating several analyses configuration - i.e. inserting into ActivityAlignmentCondition</p> In\u00a0[4]: Copied! <pre>miniscope.Activity()\n</pre> miniscope.Activity() Out[4]: inferred neural activity from fluorescence trace - e.g. dff, spikes <p>subject</p> <p>session_datetime</p> <p>recording_id</p> <p>paramset_id</p> <p>curation_id</p> <p>extraction_method</p> subject1 2021-01-01 00:00:01 0 0 0 caiman_deconvolutionsubject1 2021-01-01 00:00:01 0 0 0 caiman_dff <p>Total: 2</p> <p>We'll isolate the scan of interest with the following key:</p> In\u00a0[18]: Copied! <pre>activity_key = (\n    miniscope.Activity &amp; {\"subject\": \"subject1\", \"extraction_method\": \"caiman_dff\"}\n).fetch1(\"KEY\")\n</pre> activity_key = (     miniscope.Activity &amp; {\"subject\": \"subject1\", \"extraction_method\": \"caiman_dff\"} ).fetch1(\"KEY\") <p>Here, we can see all trials for this scan:</p> In\u00a0[19]: Copied! <pre>trial.Trial &amp; activity_key\n</pre> trial.Trial &amp; activity_key Out[19]: Experimental trials <p>subject</p> <p>session_datetime</p> <p>trial_id</p> trial number (1-based indexing) <p>trial_type</p> <p>trial_start_time</p> (second) relative to recording start <p>trial_stop_time</p> (second) relative to recording start subject1 2021-01-01 00:00:01 1 stim 0.193 1.057subject1 2021-01-01 00:00:01 2 ctrl 1.468 2.332subject1 2021-01-01 00:00:01 3 ctrl 2.662 3.526subject1 2021-01-01 00:00:01 4 ctrl 3.738 4.602subject1 2021-01-01 00:00:01 5 stim 4.826 5.69subject1 2021-01-01 00:00:01 6 stim 5.973 6.837subject1 2021-01-01 00:00:01 7 ctrl 7.252 8.116subject1 2021-01-01 00:00:01 8 ctrl 8.462 9.326subject1 2021-01-01 00:00:01 9 ctrl 9.731 10.595subject1 2021-01-01 00:00:01 10 stim 11.019 11.883 <p>...</p> <p>Total: 50</p> <p>And highlight a subset based on <code>trial_type</code></p> In\u00a0[20]: Copied! <pre>ctrl_trials = trial.Trial &amp; activity_key &amp; 'trial_type = \"ctrl\"'\nctrl_trials\n</pre> ctrl_trials = trial.Trial &amp; activity_key &amp; 'trial_type = \"ctrl\"' ctrl_trials Out[20]: Experimental trials <p>subject</p> <p>session_datetime</p> <p>trial_id</p> trial number (1-based indexing) <p>trial_type</p> <p>trial_start_time</p> (second) relative to recording start <p>trial_stop_time</p> (second) relative to recording start subject1 2021-01-01 00:00:01 2 ctrl 1.468 2.332subject1 2021-01-01 00:00:01 3 ctrl 2.662 3.526subject1 2021-01-01 00:00:01 4 ctrl 3.738 4.602subject1 2021-01-01 00:00:01 7 ctrl 7.252 8.116subject1 2021-01-01 00:00:01 8 ctrl 8.462 9.326subject1 2021-01-01 00:00:01 9 ctrl 9.731 10.595subject1 2021-01-01 00:00:01 13 ctrl 14.427 15.291subject1 2021-01-01 00:00:01 14 ctrl 15.563 16.427subject1 2021-01-01 00:00:01 15 ctrl 16.715 17.579subject1 2021-01-01 00:00:01 16 ctrl 17.706 18.57 <p>...</p> <p>Total: 23</p> <p>Here, we target the event of interest with another key:</p> In\u00a0[21]: Copied! <pre>alignment_key = (event.AlignmentEvent &amp; 'alignment_name = \"center_button\"').fetch1(\n    \"KEY\"\n)\nalignment_key\n</pre> alignment_key = (event.AlignmentEvent &amp; 'alignment_name = \"center_button\"').fetch1(     \"KEY\" ) alignment_key Out[21]: <pre>{'alignment_name': 'center_button'}</pre> In\u00a0[23]: Copied! <pre>alignment_condition = {\n    **activity_key,\n    **alignment_key,\n    \"trial_condition\": \"ctrl_center_button\",\n}\nalignment_condition\n</pre> alignment_condition = {     **activity_key,     **alignment_key,     \"trial_condition\": \"ctrl_center_button\", } alignment_condition Out[23]: <pre>{'subject': 'subject1',\n 'session_datetime': datetime.datetime(2021, 1, 1, 0, 0, 1),\n 'recording_id': 0,\n 'paramset_id': 0,\n 'curation_id': 0,\n 'extraction_method': 'caiman_dff',\n 'alignment_name': 'center_button',\n 'trial_condition': 'ctrl_center_button'}</pre> <p>Next, we add this to the <code>ActivityAlignment</code> table in the <code>analysis</code> schema</p> In\u00a0[24]: Copied! <pre>analysis.ActivityAlignmentCondition.insert1(alignment_condition, skip_duplicates=True)\n</pre> analysis.ActivityAlignmentCondition.insert1(alignment_condition, skip_duplicates=True) In\u00a0[25]: Copied! <pre>analysis.ActivityAlignmentCondition()\n</pre> analysis.ActivityAlignmentCondition() Out[25]: <p>subject</p> <p>session_datetime</p> <p>recording_id</p> <p>paramset_id</p> <p>curation_id</p> <p>extraction_method</p> <p>alignment_name</p> <p>trial_condition</p> user-friendly name of condition <p>condition_description</p> <p>bin_size</p> bin-size (in second) used to compute the PSTH subject1 2021-01-01 00:00:01 0 0 0 caiman_dff center_button ctrl_center_button 0.04 <p>Total: 1</p> <p>Using the projection method, we can generate a table of relevant trials by <code>trial_type</code> and <code>alignment_condition</code></p> In\u00a0[26]: Copied! <pre>sample = (\n    analysis.ActivityAlignmentCondition * ctrl_trials &amp; alignment_condition\n).proj()\nsample\n</pre> sample = (     analysis.ActivityAlignmentCondition * ctrl_trials &amp; alignment_condition ).proj() sample Out[26]: <p>subject</p> <p>session_datetime</p> <p>recording_id</p> <p>paramset_id</p> <p>curation_id</p> <p>extraction_method</p> <p>alignment_name</p> <p>trial_condition</p> user-friendly name of condition <p>trial_id</p> trial number (1-based indexing) subject1 2021-01-01 00:00:01 0 0 0 caiman_dff center_button ctrl_center_button 2subject1 2021-01-01 00:00:01 0 0 0 caiman_dff center_button ctrl_center_button 3subject1 2021-01-01 00:00:01 0 0 0 caiman_dff center_button ctrl_center_button 4subject1 2021-01-01 00:00:01 0 0 0 caiman_dff center_button ctrl_center_button 7subject1 2021-01-01 00:00:01 0 0 0 caiman_dff center_button ctrl_center_button 8subject1 2021-01-01 00:00:01 0 0 0 caiman_dff center_button ctrl_center_button 9subject1 2021-01-01 00:00:01 0 0 0 caiman_dff center_button ctrl_center_button 13subject1 2021-01-01 00:00:01 0 0 0 caiman_dff center_button ctrl_center_button 14subject1 2021-01-01 00:00:01 0 0 0 caiman_dff center_button ctrl_center_button 15subject1 2021-01-01 00:00:01 0 0 0 caiman_dff center_button ctrl_center_button 16 <p>...</p> <p>Total: 23</p> <p>And insert these trials into the <code>ActivityAlignmentCondition.Trial</code> part table</p> In\u00a0[27]: Copied! <pre>analysis.ActivityAlignmentCondition.Trial.insert(sample, skip_duplicates=True)\nanalysis.ActivityAlignmentCondition.Trial()\n</pre> analysis.ActivityAlignmentCondition.Trial.insert(sample, skip_duplicates=True) analysis.ActivityAlignmentCondition.Trial() Out[27]: Trials (or subset) to compute event-aligned activity <p>subject</p> <p>session_datetime</p> <p>recording_id</p> <p>paramset_id</p> <p>curation_id</p> <p>extraction_method</p> <p>alignment_name</p> <p>trial_condition</p> user-friendly name of condition <p>trial_id</p> trial number (1-based indexing) subject1 2021-01-01 00:00:01 0 0 0 caiman_dff center_button ctrl_center_button 2subject1 2021-01-01 00:00:01 0 0 0 caiman_dff center_button ctrl_center_button 3subject1 2021-01-01 00:00:01 0 0 0 caiman_dff center_button ctrl_center_button 4subject1 2021-01-01 00:00:01 0 0 0 caiman_dff center_button ctrl_center_button 7subject1 2021-01-01 00:00:01 0 0 0 caiman_dff center_button ctrl_center_button 8subject1 2021-01-01 00:00:01 0 0 0 caiman_dff center_button ctrl_center_button 9subject1 2021-01-01 00:00:01 0 0 0 caiman_dff center_button ctrl_center_button 13subject1 2021-01-01 00:00:01 0 0 0 caiman_dff center_button ctrl_center_button 14subject1 2021-01-01 00:00:01 0 0 0 caiman_dff center_button ctrl_center_button 15subject1 2021-01-01 00:00:01 0 0 0 caiman_dff center_button ctrl_center_button 16 <p>...</p> <p>Total: 23</p> <p>With the steps above, we have create a new alignment condition for analysis, named <code>ctrl_center_button</code>, which specifies:</p> <ul> <li>an Activity of interest for analysis</li> <li>an event of interest to align the Ca+ activity to - <code>center_button</code></li> <li>a set of trials of interest to perform the analysis on - <code>ctrl</code> trials</li> </ul> <p>Now, let's create another set with:</p> <ul> <li>the same Activity of interest for analysis</li> <li>an event of interest to align the Ca+ activity to - <code>center_button</code></li> <li>a set of trials of interest to perform the analysis on - <code>stim</code> trials</li> </ul> In\u00a0[28]: Copied! <pre>stim_trials = trial.Trial &amp; activity_key &amp; 'trial_type = \"stim\"'\nalignment_condition = {\n    **activity_key,\n    **alignment_key,\n    \"trial_condition\": \"stim_center_button\",\n}\nanalysis.ActivityAlignmentCondition.insert1(alignment_condition, skip_duplicates=True)\nanalysis.ActivityAlignmentCondition.Trial.insert(\n    (analysis.ActivityAlignmentCondition * stim_trials &amp; alignment_condition).proj(),\n    skip_duplicates=True,\n)\n</pre> stim_trials = trial.Trial &amp; activity_key &amp; 'trial_type = \"stim\"' alignment_condition = {     **activity_key,     **alignment_key,     \"trial_condition\": \"stim_center_button\", } analysis.ActivityAlignmentCondition.insert1(alignment_condition, skip_duplicates=True) analysis.ActivityAlignmentCondition.Trial.insert(     (analysis.ActivityAlignmentCondition * stim_trials &amp; alignment_condition).proj(),     skip_duplicates=True, ) <p>Note the two entries in <code>ActivityAlignmentCondition.trial_condition</code></p> In\u00a0[29]: Copied! <pre>analysis.ActivityAlignmentCondition()\n</pre> analysis.ActivityAlignmentCondition() Out[29]: <p>subject</p> <p>session_datetime</p> <p>recording_id</p> <p>paramset_id</p> <p>curation_id</p> <p>extraction_method</p> <p>alignment_name</p> <p>trial_condition</p> user-friendly name of condition <p>condition_description</p> <p>bin_size</p> bin-size (in second) used to compute the PSTH subject1 2021-01-01 00:00:01 0 0 0 caiman_dff center_button ctrl_center_button 0.04subject1 2021-01-01 00:00:01 0 0 0 caiman_dff center_button stim_center_button 0.04 <p>Total: 2</p> In\u00a0[30]: Copied! <pre>analysis.ActivityAlignmentCondition.Trial &amp; 'trial_condition = \"ctrl_center_button\"'\n</pre> analysis.ActivityAlignmentCondition.Trial &amp; 'trial_condition = \"ctrl_center_button\"' Out[30]: Trials (or subset) to compute event-aligned activity <p>subject</p> <p>session_datetime</p> <p>recording_id</p> <p>paramset_id</p> <p>curation_id</p> <p>extraction_method</p> <p>alignment_name</p> <p>trial_condition</p> user-friendly name of condition <p>trial_id</p> trial number (1-based indexing) subject1 2021-01-01 00:00:01 0 0 0 caiman_dff center_button ctrl_center_button 2subject1 2021-01-01 00:00:01 0 0 0 caiman_dff center_button ctrl_center_button 3subject1 2021-01-01 00:00:01 0 0 0 caiman_dff center_button ctrl_center_button 4subject1 2021-01-01 00:00:01 0 0 0 caiman_dff center_button ctrl_center_button 7subject1 2021-01-01 00:00:01 0 0 0 caiman_dff center_button ctrl_center_button 8subject1 2021-01-01 00:00:01 0 0 0 caiman_dff center_button ctrl_center_button 9subject1 2021-01-01 00:00:01 0 0 0 caiman_dff center_button ctrl_center_button 13subject1 2021-01-01 00:00:01 0 0 0 caiman_dff center_button ctrl_center_button 14subject1 2021-01-01 00:00:01 0 0 0 caiman_dff center_button ctrl_center_button 15subject1 2021-01-01 00:00:01 0 0 0 caiman_dff center_button ctrl_center_button 16 <p>...</p> <p>Total: 23</p> In\u00a0[4]: Copied! <pre>analysis.ActivityAlignment.populate(display_progress=True)\n</pre> analysis.ActivityAlignment.populate(display_progress=True) <pre>ActivityAlignment: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 2/2 [00:10&lt;00:00,  5.34s/it]\n</pre> In\u00a0[5]: Copied! <pre>analysis.ActivityAlignment()\n</pre> analysis.ActivityAlignment() Out[5]: <p>subject</p> <p>session_datetime</p> <p>recording_id</p> <p>paramset_id</p> <p>curation_id</p> <p>extraction_method</p> <p>alignment_name</p> <p>trial_condition</p> user-friendly name of condition <p>aligned_timestamps</p> subject1 2021-01-01 00:00:01 0 0 0 caiman_dff center_button ctrl_center_button =BLOB=subject1 2021-01-01 00:00:01 0 0 0 caiman_dff center_button stim_center_button =BLOB= <p>Total: 2</p> <p>The <code>AlignedTrialActivity</code> part table captures aligned traces fore each alignment and trial condition specified in the master table.</p> In\u00a0[7]: Copied! <pre>analysis.ActivityAlignment.AlignedTrialActivity()\n</pre> analysis.ActivityAlignment.AlignedTrialActivity() Out[7]: <p>subject</p> <p>session_datetime</p> <p>recording_id</p> <p>paramset_id</p> <p>curation_id</p> <p>extraction_method</p> <p>alignment_name</p> <p>trial_condition</p> user-friendly name of condition <p>mask_id</p> <p>fluorescence_channel</p> 0-based indexing <p>trial_id</p> trial number (1-based indexing) <p>aligned_trace</p> (s) Calcium activity aligned to the event time subject1 2021-01-01 00:00:01 0 0 0 caiman_dff center_button ctrl_center_button 1 0 2 =BLOB=subject1 2021-01-01 00:00:01 0 0 0 caiman_dff center_button ctrl_center_button 1 0 7 =BLOB=subject1 2021-01-01 00:00:01 0 0 0 caiman_dff center_button ctrl_center_button 1 0 8 =BLOB=subject1 2021-01-01 00:00:01 0 0 0 caiman_dff center_button ctrl_center_button 1 0 9 =BLOB=subject1 2021-01-01 00:00:01 0 0 0 caiman_dff center_button ctrl_center_button 1 0 20 =BLOB=subject1 2021-01-01 00:00:01 0 0 0 caiman_dff center_button ctrl_center_button 1 0 27 =BLOB=subject1 2021-01-01 00:00:01 0 0 0 caiman_dff center_button ctrl_center_button 1 0 37 =BLOB=subject1 2021-01-01 00:00:01 0 0 0 caiman_dff center_button ctrl_center_button 1 0 43 =BLOB=subject1 2021-01-01 00:00:01 0 0 0 caiman_dff center_button ctrl_center_button 1 0 46 =BLOB=subject1 2021-01-01 00:00:01 0 0 0 caiman_dff center_button ctrl_center_button 1 0 50 =BLOB= <p>...</p> <p>Total: 2938</p> <p>With the <code>plot_aligned_activities</code> function, we can see the density of activity relative to our alignment event. For more information, see the corresponding docstring.</p> In\u00a0[8]: Copied! <pre>help(analysis.ActivityAlignment().plot_aligned_activities)\n</pre> help(analysis.ActivityAlignment().plot_aligned_activities) <pre>Help on method plot_aligned_activities in module workflow_miniscope.analysis:\n\nplot_aligned_activities(key, roi, axs=None, title=None) method of workflow_miniscope.analysis.ActivityAlignment instance\n    Plot event-aligned Calcium activities for all selected trials, and\n        trial-averaged Calcium activity\n        e.g. dF/F, neuropil-corrected dF/F, Calcium events, etc.\n    :param key: key of ActivityAlignment master table\n    :param roi: miniscope segmentation mask\n    :param axs: optional definition of axes for plot.\n                Default is plt.subplots(2, 1, figsize=(12, 8))\n    :param title: Optional title label\n\n</pre> <p>For a refresher on the differences between masks, we can browse the <code>imaging.Segmentation.Mask</code> table.</p> In\u00a0[10]: Copied! <pre>miniscope.Segmentation.Mask &amp; \"mask_id&lt;3\"\n</pre> miniscope.Segmentation.Mask &amp; \"mask_id&lt;3\" Out[10]: A mask produced by segmentation. <p>subject</p> <p>session_datetime</p> <p>recording_id</p> <p>paramset_id</p> <p>curation_id</p> <p>mask_id</p> <p>segmentation_channel</p> 0-based indexing <p>mask_npix</p> number of pixels in this mask <p>mask_center_x</p> (pixels) center x coordinate <p>mask_center_y</p> (pixels) center y coordinate <p>mask_xpix</p> (pixels) x coordinates <p>mask_ypix</p> (pixels) y coordinates <p>mask_weights</p> weights of the mask at the indices above subject1 2021-01-01 00:00:01 0 0 0 1 0 209 87 8 =BLOB= =BLOB= =BLOB=subject1 2021-01-01 00:00:01 0 0 0 2 0 896 83 240 =BLOB= =BLOB= =BLOB= <p>Total: 2</p> <p>Then, we can directly compare the stimulus and control conditions relative to center button presses.</p> In\u00a0[6]: Copied! <pre>miniscope.Activity()\n</pre> miniscope.Activity() Out[6]: inferred neural activity from fluorescence trace - e.g. dff, spikes <p>subject</p> <p>session_datetime</p> <p>recording_id</p> <p>paramset_id</p> <p>curation_id</p> <p>extraction_method</p> subject1 2021-01-01 00:00:01 0 0 0 caiman_deconvolutionsubject1 2021-01-01 00:00:01 0 0 0 caiman_dff <p>Total: 2</p> In\u00a0[7]: Copied! <pre>from workflow_miniscope import analysis\nfrom workflow_miniscope.pipeline import miniscope, trial, event\n\nactivity_key = (\n    miniscope.Activity\n    &amp; {\"subject\": \"subject1\", \"recording_id\": 0}\n    &amp; \"extraction_method='caiman_dff'\"\n).fetch1(\"KEY\")\nalignment_key = (event.AlignmentEvent &amp; 'alignment_name = \"center_button\"').fetch1(\n    \"KEY\"\n)\nalignment_condition_ctrl = {\n    **activity_key,\n    **alignment_key,\n    \"trial_condition\": \"ctrl_center_button\",\n}\nalignment_condition_stim = {\n    **activity_key,\n    **alignment_key,\n    \"trial_condition\": \"stim_center_button\",\n}\n</pre> from workflow_miniscope import analysis from workflow_miniscope.pipeline import miniscope, trial, event  activity_key = (     miniscope.Activity     &amp; {\"subject\": \"subject1\", \"recording_id\": 0}     &amp; \"extraction_method='caiman_dff'\" ).fetch1(\"KEY\") alignment_key = (event.AlignmentEvent &amp; 'alignment_name = \"center_button\"').fetch1(     \"KEY\" ) alignment_condition_ctrl = {     **activity_key,     **alignment_key,     \"trial_condition\": \"ctrl_center_button\", } alignment_condition_stim = {     **activity_key,     **alignment_key,     \"trial_condition\": \"stim_center_button\", } In\u00a0[8]: Copied! <pre>analysis.ActivityAlignment().plot_aligned_activities(\n    alignment_condition_stim, roi=2, title=\"Stimulus Center Button\"\n)\nanalysis.ActivityAlignment().plot_aligned_activities(\n    alignment_condition_ctrl, roi=2, title=\"Control Center Button\"\n)\n</pre> analysis.ActivityAlignment().plot_aligned_activities(     alignment_condition_stim, roi=2, title=\"Stimulus Center Button\" ) analysis.ActivityAlignment().plot_aligned_activities(     alignment_condition_ctrl, roi=2, title=\"Control Center Button\" ) In\u00a0[\u00a0]: Copied! <pre>\n</pre>"}, {"location": "tutorials/07-DownstreamAnalysis_Optional/#datajoint-u24-workflow-miniscope", "title": "DataJoint U24 - Workflow Miniscope\u00b6", "text": ""}, {"location": "tutorials/07-DownstreamAnalysis_Optional/#setup", "title": "Setup\u00b6", "text": ""}, {"location": "tutorials/07-DownstreamAnalysis_Optional/#trial-and-event-schemas", "title": "Trial and Event schemas\u00b6", "text": ""}, {"location": "tutorials/07-DownstreamAnalysis_Optional/#event-aligned-trialized-calcium-activity", "title": "Event-aligned trialized calcium activity\u00b6", "text": ""}, {"location": "tutorials/07-DownstreamAnalysis_Optional/#analysis", "title": "Analysis\u00b6", "text": ""}, {"location": "tutorials/07-DownstreamAnalysis_Optional/#computation", "title": "Computation\u00b6", "text": "<p>Just like the element itself, we can run computations with <code>populate()</code></p>"}, {"location": "tutorials/07-DownstreamAnalysis_Optional/#visualization", "title": "Visualization\u00b6", "text": ""}, {"location": "tutorials/08-Visualizations/", "title": "08 Visualizations", "text": "<p>First, let's change directories to find the <code>dj_local_conf</code> file.</p> In\u00a0[1]: Copied! <pre>import os\nimport numpy as np\nimport datajoint as dj\n\nif os.path.basename(os.getcwd()) == \"notebooks\":\n    os.chdir(\"..\")\ndj.config[\"custom\"][\"database.prefix\"] = \"u24_mini_\"\n</pre> import os import numpy as np import datajoint as dj  if os.path.basename(os.getcwd()) == \"notebooks\":     os.chdir(\"..\") dj.config[\"custom\"][\"database.prefix\"] = \"u24_mini_\" <p>Next, we populate the python namespace with the required schemas</p> In\u00a0[2]: Copied! <pre>from workflow_miniscope.pipeline import miniscope, QualityMetricFigs\n</pre> from workflow_miniscope.pipeline import miniscope, QualityMetricFigs <pre>[2023-01-10 11:28:51,513][WARNING]: lab.Project and related tables will be removed in a future version of Element Lab. Please use the project schema.\n[2023-01-10 11:28:56,262][INFO]: Connecting cbroz@dss-db.datajoint.io:3306\n[2023-01-10 11:28:56,711][INFO]: Connected cbroz@dss-db.datajoint.io:3306\n</pre> In\u00a0[3]: Copied! <pre>key = miniscope.Curation.fetch(\"KEY\", limit=1)[0]\nqm = QualityMetricFigs(miniscope, key, dark_mode=True)\nprint(\"Available plots:\", qm.plot_list)\nfig = qm.get_single_fig(\"r_values\")\nfig.show(\n    \"png\"\n)  # .show('png') is optional. Here, it is used to render the image within a notebook that is embedded in a browser.qm.get_grid()\n</pre> key = miniscope.Curation.fetch(\"KEY\", limit=1)[0] qm = QualityMetricFigs(miniscope, key, dark_mode=True) print(\"Available plots:\", qm.plot_list) fig = qm.get_single_fig(\"r_values\") fig.show(     \"png\" )  # .show('png') is optional. Here, it is used to render the image within a notebook that is embedded in a browser.qm.get_grid() <pre>Available plots: ['r_values', 'SNR', 'cnn_preds']\n</pre> <p>A number of metrics are available from CaImAn estimates.</p> In\u00a0[4]: Copied! <pre>import inspect\n\n[\n    i[0]\n    for i in inspect.getmembers(qm.estimates)  # see all available class attributes\n    if not i[0].startswith(\"_\") and not inspect.ismethod(i[1])  # filter out functions\n]\n</pre> import inspect  [     i[0]     for i in inspect.getmembers(qm.estimates)  # see all available class attributes     if not i[0].startswith(\"_\") and not inspect.ismethod(i[1])  # filter out functions ] Out[4]: <pre>['A',\n 'A_thr',\n 'Ab',\n 'Ab_dense',\n 'AtA',\n 'AtY_buf',\n 'C',\n 'CC',\n 'CY',\n 'C_on',\n 'Cf',\n 'Cn',\n 'F_dff',\n 'OASISinstances',\n 'R',\n 'S',\n 'SNR_comp',\n 'W',\n 'YrA',\n 'Yr_buf',\n 'b',\n 'b0',\n 'bl',\n 'c1',\n 'center',\n 'cnn_preds',\n 'coordinates',\n 'dims',\n 'discarded_components',\n 'ecc',\n 'f',\n 'g',\n 'groups',\n 'idx_components',\n 'idx_components_bad',\n 'ind_new',\n 'lam',\n 'merged_ROIs',\n 'mn',\n 'neurons_sn',\n 'noisyC',\n 'nr',\n 'psx',\n 'r_values',\n 'rho_buf',\n 'shifts',\n 'sn',\n 'sv',\n 'vr']</pre> <p>We can adjust which we visualize using the following syntax.</p> In\u00a0[5]: Copied! <pre>qm.component_list = [\"r_values\", \"SNR_comp\", \"cnn_preds\", \"neurons_sn\"]\nnoise = qm.components.neurons_sn\nqm.plots = {\n    \"neurons_sn\": {\n        \"xaxis\": \"Noise Std\",\n        \"data\": qm.components.neurons_sn,\n        \"bins\": np.linspace(min(noise), max(noise), 10),\n        \"vline\": noise.mean(),\n    }\n}\nfig = qm.get_grid(n_columns=4)\nfig.show(\"png\")\n</pre> qm.component_list = [\"r_values\", \"SNR_comp\", \"cnn_preds\", \"neurons_sn\"] noise = qm.components.neurons_sn qm.plots = {     \"neurons_sn\": {         \"xaxis\": \"Noise Std\",         \"data\": qm.components.neurons_sn,         \"bins\": np.linspace(min(noise), max(noise), 10),         \"vline\": noise.mean(),     } } fig = qm.get_grid(n_columns=4) fig.show(\"png\") In\u00a0[6]: Copied! <pre>qm.components\n</pre> qm.components Out[6]: r_values SNR_comp cnn_preds neurons_sn 0 0.500398 1.863260 0.045389 5.313188 1 0.568861 1.033131 0.031540 8.824791 2 0.226204 0.618304 0.012997 9.883841 3 0.599668 1.234195 0.025490 8.781350 4 0.000000 0.000000 0.000000 0.042582 ... ... ... ... ... 108 0.652990 1.495659 0.000519 13.064044 109 0.765022 1.498043 0.001978 7.738464 110 0.803198 0.420331 0.002988 10.223336 111 0.588237 1.763111 0.033076 8.086799 112 0.175811 1.353125 0.008852 11.129535 <p>113 rows \u00d7 4 columns</p> In\u00a0[\u00a0]: Copied! <pre>\n</pre>"}, {"location": "tutorials/08-Visualizations/#datajoint-u24-workflow-miniscope", "title": "DataJoint U24 - Workflow Miniscope\u00b6", "text": ""}, {"location": "tutorials/08-Visualizations/#setup", "title": "Setup\u00b6", "text": ""}, {"location": "tutorials/08-Visualizations/#visualizations", "title": "Visualizations\u00b6", "text": "<p>CaImAn produces a few metrics for estimates. These can be visualized as follows.</p>"}, {"location": "tutorials/demo_prepare/", "title": "Demo prepare", "text": "In\u00a0[\u00a0]: Copied! <pre>import os\nif os.path.basename(os.getcwd()) == \"notebooks\":\n    os.chdir(\"..\")\n</pre> import os if os.path.basename(os.getcwd()) == \"notebooks\":     os.chdir(\"..\") In\u00a0[\u00a0]: Copied! <pre>import datajoint as dj\nimport datetime\nfrom workflow_miniscope.pipeline import subject, session, miniscope, Device\n</pre> import datajoint as dj import datetime from workflow_miniscope.pipeline import subject, session, miniscope, Device In\u00a0[\u00a0]: Copied! <pre>subject.Subject.insert1(\n    dict(\n        subject='subject1',\n        subject_birth_date='2023-01-01',\n        sex='U',\n    )\n)\n</pre> subject.Subject.insert1(     dict(         subject='subject1',         subject_birth_date='2023-01-01',         sex='U',     ) ) In\u00a0[\u00a0]: Copied! <pre>Device.insert1(\n    dict(device=\"UCLA Miniscope\", \n         modality=\"miniscope\"\n        )\n)\n</pre> Device.insert1(     dict(device=\"UCLA Miniscope\",           modality=\"miniscope\"         ) ) In\u00a0[\u00a0]: Copied! <pre>session_key = dict(subject='subject1', \n                   session_datetime=datetime.datetime(2023, 5, 11, 12, 00, 00))\n\nsession.Session.insert1(session_key)\n\nsession.SessionDirectory.insert1(\n    dict(\n        session_key, \n        session_dir='subject1/session1'\n    )\n)\n</pre> session_key = dict(subject='subject1',                     session_datetime=datetime.datetime(2023, 5, 11, 12, 00, 00))  session.Session.insert1(session_key)  session.SessionDirectory.insert1(     dict(         session_key,          session_dir='subject1/session1'     ) ) In\u00a0[\u00a0]: Copied! <pre>miniscope.Recording.insert1(\n    dict(\n        session_key,\n        recording_id=0,\n        device=\"UCLA Miniscope\",\n        acq_software=\"Miniscope-DAQ-V4\",\n    )\n)\n</pre> miniscope.Recording.insert1(     dict(         session_key,         recording_id=0,         device=\"UCLA Miniscope\",         acq_software=\"Miniscope-DAQ-V4\",     ) ) In\u00a0[\u00a0]: Copied! <pre>miniscope.RecordingInfo.populate(display_progress=True)\n</pre> miniscope.RecordingInfo.populate(display_progress=True) In\u00a0[\u00a0]: Copied! <pre>caiman_params = dict(\n    decay_time=0.4,\n    pw_rigid=False,\n    max_shifts=(5, 5),\n    gSig_filt=(3, 3),\n    strides=(48, 48),\n    overlaps=(24, 24),\n    max_deviation_rigid=3,\n    border_nan=\"copy\",\n    method_init=\"corr_pnr\",\n    K=None,\n    gSig=(3, 3),\n    gSiz=(13, 13),\n    merge_thr=0.7,\n    p=1,\n    tsub=2,\n    ssub=1,\n    rf=40,\n    stride=20,\n    only_init=True,\n    nb=0,\n    nb_patch=0,\n    method_deconvolution=\"oasis\",\n    low_rank_background=None,\n    update_background_components=True,\n    min_corr=0.8,\n    min_pnr=10,\n    normalize_init=False,\n    center_psf=True,\n    ssub_B=2,\n    ring_size_factor=1.4,\n    del_duplicates=True,\n    border_pix=0,\n    min_SNR=3,\n    rval_thr=0.85,\n    use_cnn=False,\n)\n\nminiscope.ProcessingParamSet.insert_new_params(\n    processing_method=\"caiman\",\n    paramset_id=0,\n    params=caiman_params,\n    paramset_desc='Default parameter set for CaImAn'\n)\n</pre> caiman_params = dict(     decay_time=0.4,     pw_rigid=False,     max_shifts=(5, 5),     gSig_filt=(3, 3),     strides=(48, 48),     overlaps=(24, 24),     max_deviation_rigid=3,     border_nan=\"copy\",     method_init=\"corr_pnr\",     K=None,     gSig=(3, 3),     gSiz=(13, 13),     merge_thr=0.7,     p=1,     tsub=2,     ssub=1,     rf=40,     stride=20,     only_init=True,     nb=0,     nb_patch=0,     method_deconvolution=\"oasis\",     low_rank_background=None,     update_background_components=True,     min_corr=0.8,     min_pnr=10,     normalize_init=False,     center_psf=True,     ssub_B=2,     ring_size_factor=1.4,     del_duplicates=True,     border_pix=0,     min_SNR=3,     rval_thr=0.85,     use_cnn=False, )  miniscope.ProcessingParamSet.insert_new_params(     processing_method=\"caiman\",     paramset_id=0,     params=caiman_params,     paramset_desc='Default parameter set for CaImAn' ) In\u00a0[\u00a0]: Copied! <pre>miniscope.ProcessingTask.insert1(\n    dict(\n        session_key,\n        recording_id=0,\n        paramset_id=0,\n        task_mode='load', # load or trigger\n        processing_output_dir='subject1/session1/caiman',\n    )\n)\n\nminiscope.Processing.populate(display_progress=True)\n</pre> miniscope.ProcessingTask.insert1(     dict(         session_key,         recording_id=0,         paramset_id=0,         task_mode='load', # load or trigger         processing_output_dir='subject1/session1/caiman',     ) )  miniscope.Processing.populate(display_progress=True) In\u00a0[\u00a0]: Copied! <pre>miniscope.Curation.insert1(\n    dict(\n        session_key,\n        recording_id=0,\n        paramset_id=0,\n        curation_id=0,\n        curation_time=datetime.datetime(2023, 5, 11, 12, 00, 00),\n        curation_output_dir='subject1/session1/caiman',\n        manual_curation=False,\n    )\n)\n\nminiscope.MotionCorrection.populate(display_progress=True)\nminiscope.Segmentation.populate(display_progress=True)\nminiscope.Fluorescence.populate(display_progress=True)\nminiscope.Activity.populate(display_progress=True)\n</pre> miniscope.Curation.insert1(     dict(         session_key,         recording_id=0,         paramset_id=0,         curation_id=0,         curation_time=datetime.datetime(2023, 5, 11, 12, 00, 00),         curation_output_dir='subject1/session1/caiman',         manual_curation=False,     ) )  miniscope.MotionCorrection.populate(display_progress=True) miniscope.Segmentation.populate(display_progress=True) miniscope.Fluorescence.populate(display_progress=True) miniscope.Activity.populate(display_progress=True) In\u00a0[\u00a0]: Copied! <pre>\n</pre>"}, {"location": "tutorials/demo_prepare/#demo-preparation-notebook", "title": "Demo Preparation Notebook\u00b6", "text": "<p>Please Note: This notebook and demo are NOT intended to be used as learning materials. To gain a thorough understanding of the DataJoint workflow, please see the <code>tutorial</code> notebook.</p>"}, {"location": "tutorials/quality_metrics/", "title": "Quality Metrics Notebook", "text": "In\u00a0[\u00a0]: Copied! <pre>import os\nif os.path.basename(os.getcwd()) == \"notebooks\":\n    os.chdir(\"..\")\n</pre> import os if os.path.basename(os.getcwd()) == \"notebooks\":     os.chdir(\"..\") In\u00a0[\u00a0]: Copied! <pre>import datetime\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom workflow_miniscope.pipeline import miniscope\n</pre> import datetime import numpy as np import matplotlib.pyplot as plt from workflow_miniscope.pipeline import miniscope In\u00a0[\u00a0]: Copied! <pre>miniscope.ProcessingQualityMetrics.populate(display_progress=True)\n</pre> miniscope.ProcessingQualityMetrics.populate(display_progress=True) In\u00a0[\u00a0]: Copied! <pre>key = dict(\n        subject=\"subject1\",\n        session_datetime=datetime.datetime(2023, 5, 11, 12, 00, 00),\n        recording_id=0,\n        paramset_id=0,\n        curation_id=0,\n    )\nquery = miniscope.MotionCorrection.Summary &amp; key\nquery\n</pre> key = dict(         subject=\"subject1\",         session_datetime=datetime.datetime(2023, 5, 11, 12, 00, 00),         recording_id=0,         paramset_id=0,         curation_id=0,     ) query = miniscope.MotionCorrection.Summary &amp; key query In\u00a0[\u00a0]: Copied! <pre>summary_images = query.fetch1()\n</pre> summary_images = query.fetch1() In\u00a0[\u00a0]: Copied! <pre>fig, axes = plt.subplots(1, 3, figsize=(12, 9))\n\naxes[0].imshow(summary_images[\"average_image\"][0])\naxes[0].set_title('Average Image')\naxes[0].set_xlabel('x (pixels)')\naxes[0].set_ylabel('y (pixels)')\n\naxes[1].imshow(summary_images[\"correlation_image\"][0])\naxes[1].set_title('Correlation Image')\naxes[1].set_xlabel('x (pixels)')\naxes[1].set_yticks([])\naxes[1].set_yticklabels([])\n\naxes[2].imshow(summary_images[\"max_proj_image\"][0])\naxes[2].set_title('Max projection Image')\naxes[2].set_xlabel('x (pixels)')\naxes[2].set_yticks([])\naxes[2].set_yticklabels([])\n\nplt.show()\n</pre> fig, axes = plt.subplots(1, 3, figsize=(12, 9))  axes[0].imshow(summary_images[\"average_image\"][0]) axes[0].set_title('Average Image') axes[0].set_xlabel('x (pixels)') axes[0].set_ylabel('y (pixels)')  axes[1].imshow(summary_images[\"correlation_image\"][0]) axes[1].set_title('Correlation Image') axes[1].set_xlabel('x (pixels)') axes[1].set_yticks([]) axes[1].set_yticklabels([])  axes[2].imshow(summary_images[\"max_proj_image\"][0]) axes[2].set_title('Max projection Image') axes[2].set_xlabel('x (pixels)') axes[2].set_yticks([]) axes[2].set_yticklabels([])  plt.show() In\u00a0[\u00a0]: Copied! <pre>mask_xpix, mask_ypix = (miniscope.Segmentation.Mask &amp; key).fetch(\"mask_xpix\", \"mask_ypix\")\n\nmask_image = np.zeros(np.shape(summary_images[\"correlation_image\"][0]), dtype=bool)\nfor xpix, ypix in zip(mask_xpix, mask_ypix):\n    try:\n        mask_image[ypix, xpix] = True\n    except Exception as e:\n        print(e)\n\nplt.xlabel('x (pixels)')\nplt.ylabel('y (pixels)')\nplt.imshow(summary_images[\"correlation_image\"][0])\nplt.contour(mask_image, colors=\"white\", linewidths=0.5)\nplt.show()\n</pre> mask_xpix, mask_ypix = (miniscope.Segmentation.Mask &amp; key).fetch(\"mask_xpix\", \"mask_ypix\")  mask_image = np.zeros(np.shape(summary_images[\"correlation_image\"][0]), dtype=bool) for xpix, ypix in zip(mask_xpix, mask_ypix):     try:         mask_image[ypix, xpix] = True     except Exception as e:         print(e)  plt.xlabel('x (pixels)') plt.ylabel('y (pixels)') plt.imshow(summary_images[\"correlation_image\"][0]) plt.contour(mask_image, colors=\"white\", linewidths=0.5) plt.show() In\u00a0[\u00a0]: Copied! <pre>key = dict(\n        subject=\"subject1\",\n        session_datetime=datetime.datetime(2023, 5, 11, 12, 00, 00),\n        recording_id=0,\n        paramset_id=0,\n        curation_id=0,\n        fluorescence_channel=0\n    )\n\nquery = miniscope.ProcessingQualityMetrics.Trace &amp; key\nquery\n</pre> key = dict(         subject=\"subject1\",         session_datetime=datetime.datetime(2023, 5, 11, 12, 00, 00),         recording_id=0,         paramset_id=0,         curation_id=0,         fluorescence_channel=0     )  query = miniscope.ProcessingQualityMetrics.Trace &amp; key query In\u00a0[\u00a0]: Copied! <pre>skewness, variance = query.fetch('skewness', 'variance')\n</pre> skewness, variance = query.fetch('skewness', 'variance') In\u00a0[\u00a0]: Copied! <pre>fig, axes = plt.subplots(1, 2, figsize=(9, 4))\n\naxes[0].scatter(range(len(skewness)), \n         np.sort(skewness), \n         color='black', s=0.5)\naxes[0].set_title('Temporal skewness')\naxes[0].set_xlabel('Cell')\naxes[0].set_ylabel('Sorted skewness')\n\naxes[1].scatter(range(len(variance)), \n         np.sort(variance), \n         color='black', s=0.5)\naxes[1].set_title('Temporal variance')\naxes[1].set_xlabel('Cell')\naxes[1].set_ylabel('Sorted variance')\n\nplt.show()\n</pre> fig, axes = plt.subplots(1, 2, figsize=(9, 4))  axes[0].scatter(range(len(skewness)),           np.sort(skewness),           color='black', s=0.5) axes[0].set_title('Temporal skewness') axes[0].set_xlabel('Cell') axes[0].set_ylabel('Sorted skewness')  axes[1].scatter(range(len(variance)),           np.sort(variance),           color='black', s=0.5) axes[1].set_title('Temporal variance') axes[1].set_xlabel('Cell') axes[1].set_ylabel('Sorted variance')  plt.show() In\u00a0[\u00a0]: Copied! <pre>\n</pre>"}, {"location": "tutorials/quality_metrics/#miniscope-quality-metrics", "title": "Miniscope Quality Metrics\u00b6", "text": "<p>Visualize the miniscope quality metrics for the processed images that are stored in the DataJoint pipeline (i.e. <code>element-miniscope</code>).</p> <p>If you are new to using this DataJoint pipeline for analyzing miniscope calcium imaging data, please see the tutorial notebook for an in-depth explanation to set up and run the workflow.</p> <p>This quality metrics notebook requires the data to be populated into the database using the demo_prepare notebook.</p>"}, {"location": "tutorials/quality_metrics/#populate-quality-metrics-tables", "title": "Populate quality metrics tables\u00b6", "text": ""}, {"location": "tutorials/quality_metrics/#motion-corrected-summary-images", "title": "Motion corrected summary images\u00b6", "text": ""}, {"location": "tutorials/quality_metrics/#segmentation-masks", "title": "Segmentation masks\u00b6", "text": ""}, {"location": "tutorials/quality_metrics/#trace-quality-metrics", "title": "Trace quality metrics\u00b6", "text": "<p>Temporal skewness and variance of the fluorescence activity can indicate the stability of the signal over time. Changes in this metric between imaging sessions could indicate technical issues in the experimental conditions or data processing. Additionally, changes in the animal's behavior or physiological state could also affect this metric, so it is important to interpret any changes within the context of the experimental conditions and the animal's behavior and physiology. (Stringer &amp; Pachitariu, Current Opinion in Neurobiology 2019)</p> <p>For illustrative purposes, below we will fetch and plot these metrics for a single session.</p>"}, {"location": "tutorials/tutorial/", "title": "Tutorial", "text": "In\u00a0[\u00a0]: Copied! <pre>Coming soon!\n</pre> Coming soon!"}]}